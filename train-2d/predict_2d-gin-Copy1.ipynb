{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coefficient(G, node):\n",
    "    ns = [n for n in G.neighbors(node)]\n",
    "    if len(ns) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = len(ns) * (len(ns) - 1) / 2\n",
    "    for i in range(0, len(ns)):\n",
    "        for j in range(i+1, len(ns)):\n",
    "            n1, n2 = ns[i], ns[j]\n",
    "            numerator += G.has_edge(n1, n2)\n",
    "    \n",
    "    return numerator / denominator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(G):\n",
    "    x = torch.randn(G.number_of_nodes(), 4)\n",
    "    ind = 0\n",
    "    for node in G.nodes():\n",
    "        x[ind][0] = 1 # uniform\n",
    "        x[ind][1] = G.degree[node] # node degree as a scalar \n",
    "        x[ind][2] = clustering_coefficient(G, node) # triangle counting?\n",
    "        x[ind][2] = ind # node ID features\n",
    "        ind += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        for ind, graph in enumerate(total_laman_data[0]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        for ind, graph in enumerate(total_laman_data[1]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/merged_erdos_laman.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 128], x=[30, 4], label=[1], num_nodes=30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laman_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.7, .3]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches:  91\n",
      "Number of test batches:  39\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches: \", len(train_loader))\n",
    "print(\"Number of test batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 31598], x=[7343, 4], label=[256], num_nodes=7343, batch=[7343], ptr=[257])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gin.gin import GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=4, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv2): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv3): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv4): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv5): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv6): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv7): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv8): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (lin1): Linear(in_features=28, out_features=28, bias=True)\n",
      "  (lin2): Linear(in_features=28, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  973\n"
     ]
    }
   ],
   "source": [
    "model = GIN(num_features=4, dim_h = 2)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=0.001)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', min_lr=1e-6, verbose=True, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, features_to_use):\n",
    "    ind = 0\n",
    "    for batch in data:\n",
    "        optimizer.zero_grad()\n",
    "        pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "        pred = torch.squeeze(pred)\n",
    "        loss = loss_fn(pred.float(), batch.label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ind += 1\n",
    "\n",
    "    return loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, features_to_use):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            y = batch.label\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Train loss 0.33679813146591187\n",
      "Train Accuracy 87.2706867527086 | Test Accuracy 87.30990029207373\n",
      "Epoch 1 | Train loss 0.2505302131175995\n",
      "Train Accuracy 89.26490266327103 | Test Accuracy 89.47527444858495\n",
      "Epoch 2 | Train loss 0.21181923151016235\n",
      "Train Accuracy 90.28359304182673 | Test Accuracy 90.66371235773995\n",
      "Epoch 3 | Train loss 0.16970482468605042\n",
      "Train Accuracy 92.64902663271032 | Test Accuracy 92.78880048343237\n",
      "Epoch 4 | Train loss 0.12686745822429657\n",
      "Train Accuracy 95.40294384253464 | Test Accuracy 95.47789304058819\n",
      "Epoch 5 | Train loss 0.11544802784919739\n",
      "Train Accuracy 96.46048258298443 | Test Accuracy 96.4548292879444\n",
      "Epoch 6 | Train loss 0.07025624066591263\n",
      "Train Accuracy 96.68062330038417 | Test Accuracy 96.61597341121966\n",
      "Epoch 7 | Train loss 0.060627855360507965\n",
      "Train Accuracy 96.7928519014115 | Test Accuracy 96.62604491892436\n",
      "Epoch 8 | Train loss 0.1222018375992775\n",
      "Train Accuracy 96.91371347174861 | Test Accuracy 96.78718904219961\n",
      "Epoch 9 | Train loss 0.06720427423715591\n",
      "Train Accuracy 96.88781456381923 | Test Accuracy 96.87783261154195\n",
      "Epoch 10 | Train loss 0.06194191426038742\n",
      "Train Accuracy 97.0691069193249 | Test Accuracy 96.94833316547488\n",
      "Epoch 11 | Train loss 0.086578868329525\n",
      "Train Accuracy 97.26766521345016 | Test Accuracy 96.99869070399839\n",
      "Epoch 12 | Train loss 0.09396402537822723\n",
      "Train Accuracy 96.94824534898778 | Test Accuracy 96.84761808842784\n",
      "Epoch 13 | Train loss 0.12656565010547638\n",
      "Train Accuracy 97.12953770449346 | Test Accuracy 96.96847618088428\n",
      "Epoch 14 | Train loss 0.06146867945790291\n",
      "Train Accuracy 97.45759053826563 | Test Accuracy 97.20012085809245\n",
      "Epoch 15 | Train loss 0.057609692215919495\n",
      "Train Accuracy 95.62740104458929 | Test Accuracy 95.48796454829288\n",
      "Epoch 16 | Train loss 0.05476048216223717\n",
      "Train Accuracy 97.56550265463805 | Test Accuracy 97.47205156611945\n",
      "Epoch 17 | Train loss 0.039092037826776505\n",
      "Train Accuracy 97.68204774032029 | Test Accuracy 97.43176553530063\n",
      "Epoch 18 | Train loss 0.04088025912642479\n",
      "Train Accuracy 98.00578408943757 | Test Accuracy 97.85476885889818\n",
      "Epoch 19 | Train loss 0.06465566903352737\n",
      "Train Accuracy 98.17412699097855 | Test Accuracy 97.9454124282405\n",
      "Epoch 20 | Train loss 0.07482251524925232\n",
      "Train Accuracy 97.89355548841023 | Test Accuracy 97.6533387048041\n",
      "Epoch 21 | Train loss 0.056931450963020325\n",
      "Train Accuracy 98.47628091682135 | Test Accuracy 98.44898781347567\n",
      "Epoch 22 | Train loss 0.08935872465372086\n",
      "Train Accuracy 98.5496611559546 | Test Accuracy 98.38855876724746\n",
      "Epoch 23 | Train loss 0.029903128743171692\n",
      "Train Accuracy 98.61872491043295 | Test Accuracy 98.62020344445564\n",
      "Epoch 24 | Train loss 0.04078777879476547\n",
      "Train Accuracy 98.18707644494323 | Test Accuracy 97.84469735119347\n",
      "Epoch 25 | Train loss 0.0454595610499382\n",
      "Train Accuracy 98.238874260802 | Test Accuracy 97.95548393594521\n",
      "Epoch 26 | Train loss 0.06405479460954666\n",
      "Train Accuracy 98.8215996892131 | Test Accuracy 98.63027495216033\n",
      "Epoch 27 | Train loss 0.037399981170892715\n",
      "Train Accuracy 98.90361289765615 | Test Accuracy 98.8518481216638\n",
      "Epoch 28 | Train loss 0.015126544050872326\n",
      "Train Accuracy 98.6748392109466 | Test Accuracy 98.39863027495215\n",
      "Epoch 29 | Train loss 0.04284191131591797\n",
      "Train Accuracy 98.83886562783269 | Test Accuracy 98.82163359854971\n",
      "Epoch 30 | Train loss 0.03897916153073311\n",
      "Train Accuracy 99.02015798333836 | Test Accuracy 98.86191962936851\n",
      "Epoch 31 | Train loss 0.06176077574491501\n",
      "Train Accuracy 99.05468986057755 | Test Accuracy 98.91227716789204\n",
      "Epoch 32 | Train loss 0.01903289556503296\n",
      "Train Accuracy 99.05468986057755 | Test Accuracy 99.00292073723436\n",
      "Epoch 33 | Train loss 0.020093701779842377\n",
      "Train Accuracy 98.72663702680538 | Test Accuracy 98.36841575183804\n",
      "Epoch 34 | Train loss 0.02561176009476185\n",
      "Train Accuracy 98.63599084905253 | Test Accuracy 98.32812972101924\n",
      "Epoch 35 | Train loss 0.023553362116217613\n",
      "Train Accuracy 99.17986791556956 | Test Accuracy 99.05327827575789\n",
      "Epoch 36 | Train loss 0.012343565933406353\n",
      "Train Accuracy 97.48348944619501 | Test Accuracy 97.21019236579716\n",
      "Epoch 37 | Train loss 0.021113257855176926\n",
      "Train Accuracy 99.18418440022447 | Test Accuracy 99.1036358142814\n",
      "Epoch 38 | Train loss 0.03548170626163483\n",
      "Train Accuracy 99.08058876850693 | Test Accuracy 98.94249169100614\n",
      "Epoch 39 | Train loss 0.07947006076574326\n",
      "Train Accuracy 98.74821945007986 | Test Accuracy 98.44898781347567\n",
      "Epoch 40 | Train loss 0.018982650712132454\n",
      "Train Accuracy 97.9496697889239 | Test Accuracy 97.67348172021352\n",
      "Epoch 41 | Train loss 0.006044373381882906\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m train_acc, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, check_accuracy(model, test_loader, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_acc \u001b[38;5;241m>\u001b[39m highestAcc:\n",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m, in \u001b[0;36mcheck_accuracy\u001b[0;34m(model, loader, features_to_use)\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m      8\u001b[0m         pred, embedding \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx[:, features_to_use], batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m      9\u001b[0m         pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(pred)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/data/dataset.py:258\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03mIn case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03mtuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 258\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:82\u001b[0m, in \u001b[0;36mInMemoryDataset.get\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen() \u001b[38;5;241m*\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m data \u001b[38;5;241m=\u001b[39m separate(\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m,\n\u001b[1;32m     86\u001b[0m     batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m     decrement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     90\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx] \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/copy.py:74\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Shallow copy operation on arbitrary Python objects.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mSee the module's __doc__ string for more info.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(x)\n\u001b[0;32m---> 74\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[43m_copy_dispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m copier(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, model = train(model, train_loader, [0, 1, 2, 3])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model, train_loader, [0, 1, 2, 3]), check_accuracy(model, test_loader, [0, 1, 2, 3])\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square\n",
    "import networkx as nx\n",
    "square = nx.Graph()\n",
    "square.add_edge(0, 1)\n",
    "square.add_edge(1, 3)\n",
    "square.add_edge(0, 2)\n",
    "square.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square with cross bar (rigid)\n",
    "import networkx as nx\n",
    "square_bar = nx.Graph()\n",
    "square_bar.add_edge(0, 1)\n",
    "square_bar.add_edge(1, 3)\n",
    "square_bar.add_edge(0, 2)\n",
    "square_bar.add_edge(2, 3)\n",
    "square_bar.add_edge(0, 3)\n",
    "square_bar.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle\n",
    "import networkx as nx\n",
    "triangle = nx.Graph()\n",
    "triangle.add_edge(0, 1)\n",
    "triangle.add_edge(0, 2)\n",
    "triangle.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentagon\n",
    "import networkx as nx\n",
    "pentagon = nx.Graph()\n",
    "pentagon.add_edge(0, 1)\n",
    "pentagon.add_edge(1, 3)\n",
    "pentagon.add_edge(3, 4)\n",
    "pentagon.add_edge(4, 2)\n",
    "pentagon.add_edge(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no triangle and rigid\n",
    "rigid = nx.Graph()\n",
    "rigid.add_edge(0, 1)\n",
    "rigid.add_edge(0, 2)\n",
    "rigid.add_edge(0, 4)\n",
    "rigid.add_edge(1, 2)\n",
    "rigid.add_edge(1, 5)\n",
    "rigid.add_edge(2, 3)\n",
    "rigid.add_edge(3, 4)\n",
    "rigid.add_edge(3, 5)\n",
    "rigid.add_edge(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9998]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.1290]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9930]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7583]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "toy_problems = [square, square_bar, triangle, pentagon, rigid]\n",
    "labels = [1, 0, 0, 1, 0]\n",
    "\n",
    "for index, toy_problem in enumerate(toy_problems):\n",
    "    graph_as_data = from_networkx(toy_problem)\n",
    "    graph_as_data.x = generate_feature_vector(toy_problem)\n",
    "    graph_as_data.label = labels[index]\n",
    "    validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "    for batch in validation_set:\n",
    "        pred = model(batch.x[:, [0, 1, 2, 3]], batch.edge_index, batch.batch)\n",
    "        print(pred[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pebble import lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "tensor(0.7957, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  59   57\n",
      "1\n",
      "tensor(0.7141, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  63   57\n",
      "tensor(0.4282, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "5\n",
      "tensor(0.8830, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  58   57\n",
      "tensor(0.2283, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  62   56\n",
      "tensor(0.3798, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  66   56\n",
      "11\n",
      "tensor(0.0998, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  63   56\n",
      "tensor(0.0717, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  68   56\n",
      "tensor(0.3671, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  62   56\n",
      "tensor(0.0795, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   56\n",
      "tensor(0.7457, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  64   57\n",
      "tensor(0.0244, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.4660, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.0606, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  62   56\n",
      "45\n",
      "tensor(0.8339, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  65   57\n",
      "tensor(0.3823, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.2600, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.2313, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  70   56\n",
      "tensor(0.5542, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  70   57\n",
      "tensor(0.4279, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   56\n",
      "tensor(0.8307, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  62   57\n",
      "tensor(0.2602, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   56\n",
      "tensor(0.3536, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  58   56\n",
      "tensor(0.3227, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.5342, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  62   57\n",
      "tensor(0.0879, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  73   56\n",
      "tensor(0.2462, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  61   56\n",
      "tensor(0.4923, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  72   56\n",
      "tensor(0.2451, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   55\n",
      "tensor(0.1247, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  76   56\n",
      "tensor(0.0920, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  63   56\n",
      "tensor(0.1576, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.3937, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  60   56\n",
      "tensor(0.0837, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   56\n",
      "tensor(0.0428, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  66   56\n",
      "tensor(0.5282, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  59   57\n",
      "tensor(0.1466, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  62   56\n",
      "119\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.4828, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  59   56\n",
      "tensor(0.0561, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  71   56\n",
      "tensor(0.6069, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  67   57\n",
      "tensor(0.0721, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  66   56\n",
      "tensor(0.1078, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  66   56\n",
      "tensor(0.3333, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  69   56\n",
      "tensor(0.0186, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  71   56\n",
      "tensor(0.2968, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  67   56\n",
      "tensor(0.6456, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  60   57\n",
      "tensor(0.6831, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  58   57\n",
      "tensor(0.1035, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  68   56\n",
      "tensor(0.2246, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  68   56\n",
      "tensor(0.2530, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  67   56\n",
      "tensor(0.1786, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  72   56\n",
      "tensor(0.8100, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  64   57\n",
      "tensor(0.0596, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  76   56\n",
      "tensor(0.0233, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  68   56\n",
      "tensor(0.0394, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  66   56\n",
      "tensor(0.0958, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   56\n",
      "tensor(0.1890, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  72   56\n",
      "159\n",
      "tensor(0.0144, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  68   56\n",
      "tensor(0.2121, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  73   56\n",
      "tensor(0.0317, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  85   56\n",
      "tensor(0.0307, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  80   56\n",
      "tensor(0.2356, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.2250, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  63   56\n",
      "tensor(0.5270, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  65   57\n",
      "tensor(0.1351, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  66   56\n",
      "tensor(0.4992, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   56\n",
      "tensor(0.0100, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  88   56\n",
      "tensor(0.1571, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  76   56\n",
      "tensor(0.4680, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  74   56\n",
      "tensor(0.2386, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  78   56\n",
      "tensor(0.3080, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  76   56\n",
      "tensor(0.3356, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  73   56\n",
      "tensor(0.4354, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  70   56\n",
      "tensor(0.9059, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  63   57\n",
      "tensor(0.0934, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  60   56\n",
      "tensor(0.2775, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  75   56\n",
      "tensor(0.4016, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  62   56\n",
      "tensor(0.6808, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  65   57\n",
      "tensor(0.3076, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  70   56\n",
      "tensor(0.3405, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  80   56\n",
      "tensor(0.2563, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.0228, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  80   56\n",
      "tensor(0.0121, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  68   56\n",
      "tensor(0.1215, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  73   56\n",
      "283\n",
      "tensor(0.4561, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  63   56\n",
      "tensor(0.2176, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  63   56\n",
      "tensor(0.1526, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  71   56\n",
      "tensor(0.3977, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   55\n",
      "tensor(0.1420, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  80   56\n",
      "tensor(0.5153, grad_fn=<SelectBackward0>)   0\n",
      "wrong: , with number of edges:  65   57\n",
      "tensor(0.0824, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  73   56\n",
      "tensor(0.1812, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  65   56\n",
      "tensor(0.0119, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  83   56\n",
      "tensor(0.1700, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  72   56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0049, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  69   56\n",
      "tensor(0.4197, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  69   56\n",
      "tensor(0.0097, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  75   56\n",
      "tensor(0.0232, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  68   56\n",
      "tensor(0.2131, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  70   56\n",
      "tensor(0.0087, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  66   56\n",
      "389\n",
      "tensor(0.3635, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  81   56\n",
      "tensor(0.1234, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  81   56\n",
      "tensor(0.0100, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  79   56\n",
      "tensor(0.2830, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  72   56\n",
      "tensor(0.1147, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  81   56\n",
      "tensor(0.1265, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  73   56\n",
      "tensor(0.0171, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  73   56\n",
      "tensor(0.0634, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  66   56\n",
      "487\n",
      "tensor(0.0540, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  72   56\n",
      "tensor(0.2797, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  78   56\n",
      "tensor(0.0752, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  93   56\n",
      "tensor(0.3680, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  81   56\n",
      "tensor(0.0135, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  64   56\n",
      "tensor(0.3816, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  83   56\n",
      "tensor(0.0073, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  79   56\n",
      "tensor(0.2727, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  72   56\n",
      "tensor(0.3168, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  68   56\n",
      "tensor(0.4811, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  70   56\n",
      "tensor(0.4704, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  70   56\n",
      "tensor(0.1107, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  83   56\n",
      "tensor(0.0459, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  87   56\n",
      "598\n",
      "tensor(0.0164, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  79   56\n",
      "tensor(0.2911, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  85   56\n",
      "tensor(0.1475, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  81   56\n",
      "tensor(0.0866, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  84   56\n",
      "tensor(0.3343, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  83   56\n",
      "tensor(0.3385, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  85   56\n",
      "tensor(0.0478, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  80   56\n",
      "tensor(0.1713, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  70   56\n",
      "tensor(0.0410, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  80   56\n",
      "tensor(0.0495, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  79   56\n",
      "tensor(0.0625, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  91   56\n",
      "681\n",
      "tensor(0.1727, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  76   56\n",
      "tensor(0.0223, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  81   56\n",
      "tensor(0.0409, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  75   56\n",
      "tensor(0.0898, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  78   56\n",
      "736\n",
      "tensor(0.0791, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  79   56\n",
      "840\n",
      "tensor(0.2023, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  90   56\n",
      "tensor(0.1022, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  96   56\n",
      "tensor(0.0064, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  92   56\n",
      "868\n",
      "tensor(0.0212, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  82   56\n",
      "tensor(0.3132, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  94   56\n",
      "tensor(0.0940, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  86   56\n",
      "907\n",
      "tensor(0.1050, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  91   56\n",
      "924\n",
      "tensor(0.0213, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  103   56\n",
      "943\n",
      "955\n",
      "tensor(0.1131, grad_fn=<SelectBackward0>)   1\n",
      "wrong: , with number of edges:  109   56\n",
      "967\n",
      "979\n"
     ]
    }
   ],
   "source": [
    "rigid_data, not_rigid_data = [], []\n",
    "stats = {}\n",
    "stats_considered = {}\n",
    "prev_graphs = []\n",
    "\n",
    "stats_wrong = {}\n",
    "\n",
    "num_nodes = 30\n",
    "for p in np.arange(0.01, 0.3, 0.01):\n",
    "    stats[p] = 0\n",
    "    stats_wrong[p] = 0\n",
    "    for num_graphs in range(1000):\n",
    "        G = nx.erdos_renyi_graph(num_nodes, p)        \n",
    "        l = lattice()\n",
    "        num_edges = 0\n",
    "\n",
    "        for (u, v) in G.edges():\n",
    "            if l.add_bond(u, v):\n",
    "                num_edges += 1\n",
    "\n",
    "        label = 1\n",
    "        rigid = False\n",
    "        if num_edges >= (num_nodes * 2) - 3: # rigid \n",
    "            rigid = True\n",
    "            stats[p] += 1\n",
    "            label = 0\n",
    "\n",
    "        graph_as_data = from_networkx(G)\n",
    "        graph_as_data.x = generate_feature_vector(G)\n",
    "        validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "        for batch in validation_set:\n",
    "            pred = model(batch.x[:, [0, 1, 2, 3]], batch.edge_index, batch.batch)\n",
    "            pred_label = 1\n",
    "            if (pred[0][0][0] < 0.5):\n",
    "                pred_label = 0\n",
    "                \n",
    "            if pred_label != label:\n",
    "                print(pred[0][0][0] , \" \", label)\n",
    "                stats_wrong[p] += 1\n",
    "                print(\"wrong: , with number of edges: \" , G.number_of_edges(), \" \", num_edges)\n",
    "                \n",
    "    print(stats[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(list(stats_wrong.keys()), stats_wrong.values(), color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in validation_set:\n",
    "    pred = bestModel(batch.x, batch.edge_index, batch.batch)\n",
    "    print(pred[0])\n",
    "    print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanTestDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_test.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add functionality to support a test dataset\n",
    "TEST_DATA_PATH = \"../data-2d/data/test-dataset-30loc-5std.pkl.gz\"\n",
    "laman_test_set = LamanTestDataset(\"\", TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "laman_test_loader = DataLoader(laman_test_set, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_acc = check_accuracy(bestModel, laman_test_loader, [1])\n",
    "print(f\"Accuracy {random_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the clustering coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(triangle, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square_bar, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate graph correlating clustering coefficient to rigidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_data:\n",
    "    item = to_networkx(item)\n",
    "    print(type(item))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric.utils.convert.to_networkx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work: Sahil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_laman_data = None\n",
    "with gzip.open(DATA_PATH, 'r') as f:\n",
    "    total_laman_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph = total_laman_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_data = from_networkx(sample_graph)\n",
    "from_data = to_networkx(to_data, to_undirected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_clustering_coefficient(G):\n",
    "    min_coefficient = 1\n",
    "    for node in G.nodes():\n",
    "        min_coefficient = min(min_coefficient, clustering_coefficient(G, node))\n",
    "        \n",
    "    return min_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sample_graph in enumerate(train_data):\n",
    "    label = sample_graph.label\n",
    "    networkx_sample_graph = to_networkx(sample_graph, to_undirected = True)\n",
    "    print(label, \" \", index, \" \", compute_min_clustering_coefficient(networkx_sample_graph))\n",
    "    \n",
    "    if index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_min_clustering_coefficient(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_min_clustering_coefficient(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if instead of training a gnn  you just trained on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the degrees of the nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the triangle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on the triangle features and the degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a network with just degree of the node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_just_degree = GIN(num_features=1)\n",
    "print(model_just_degree)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, h = train(train_loader, [0])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model_just_degree, train_loader), check_accuracy(model_just_degree, test_loader)\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "#     scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_feature_vector(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph.x[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try random graph topologies and consider their realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pebble import lattice\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rigid_data, not_rigid_data = [], []\n",
    "stats = {}\n",
    "prev_graphs = []\n",
    "\n",
    "\n",
    "num_nodes = 30\n",
    "for p in np.arange(0.05, 0.3, 0.01):\n",
    "    stats[p] = 0\n",
    "    for num_graphs in tqdm(range(1000)):\n",
    "        G = nx.erdos_renyi_graph(num_nodes, p)\n",
    "        \n",
    "        add = True\n",
    "        for prev_graph in prev_graphs:\n",
    "            if add:\n",
    "                if nx.is_isomorphic(G, prev_graph):\n",
    "                    add = False\n",
    "                    print(\"isomorphic graph\")\n",
    "        \n",
    "        if add:\n",
    "            # determine rigdity in two-dimensions\n",
    "            l = lattice()\n",
    "            num_edges = 0\n",
    "\n",
    "            for (u, v) in G.edges():\n",
    "                if l.add_bond(u, v):\n",
    "                    num_edges += 1\n",
    "\n",
    "            rigid = False\n",
    "            if num_edges >= (num_nodes * 2) - 3: # rigid \n",
    "                rigid_data.append(G)\n",
    "                stats[p] += 1\n",
    "            else:\n",
    "                not_rigid_data.append(G)\n",
    "            \n",
    "            prev_graphs.append(G)\n",
    "            \n",
    "\n",
    "    print(stats)\n",
    "    print(\"/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rigid_data))\n",
    "print(len(not_rigid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, rigid_graph in enumerate(rigid_data):\n",
    "    graph_as_data = from_networkx(rigid_graph)\n",
    "    graph_as_data.x = generate_feature_vector(rigid_graph)\n",
    "    graph_as_data.label = 0\n",
    "    validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "    for batch in validation_set:\n",
    "        pred = model(batch.x[:, [0, 1]], batch.edge_index, batch.batch)\n",
    "        if (pred[0][0][0]) < 0.5:\n",
    "            print(\"wrong\")\n",
    "            print(rigid_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, rigid_graph in enumerate(not_rigid_data):\n",
    "    graph_as_data = from_networkx(rigid_graph)\n",
    "    graph_as_data.x = generate_feature_vector(rigid_graph)\n",
    "    graph_as_data.label = 0\n",
    "    validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "    for batch in validation_set:\n",
    "        pred = model(batch.x[:, [0, 1]], batch.edge_index, batch.batch)\n",
    "#         print(pred[0])\n",
    "        if (pred[0][0][0]) > 0.5:\n",
    "            print(\"wrong\")\n",
    "            print(rigid_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why are you training on minimally rigid graphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on everything maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rigid and not-rigid graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(not_rigid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rigid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanErdosRenyiDataset(InMemoryDataset):\n",
    "    def __init__(self, root, rigid_data, not_rigid_data, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.rigid_data = rigid_data\n",
    "        self.not_rigid_data = not_rigid_data\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_erdos_renyi.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "\n",
    "        data_list = []\n",
    "        # convert from graph to Data object\n",
    "        for graph in self.rigid_data:\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        for graph in self.not_rigid_data:\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laman_data = LamanErdosRenyiDataset(\"\", rigid_data, not_rigid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.6, .4]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does it get minimally rigid graphs wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

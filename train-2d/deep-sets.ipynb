{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339f0e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from pebble import lattice\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c96ef360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695146a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coefficient(G, node):\n",
    "    ns = [n for n in G.neighbors(node)]\n",
    "    if len(ns) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = len(ns) * (len(ns) - 1) / 2\n",
    "    for i in range(0, len(ns)):\n",
    "        for j in range(i+1, len(ns)):\n",
    "            n1, n2 = ns[i], ns[j]\n",
    "            numerator += G.has_edge(n1, n2)\n",
    "    \n",
    "    return numerator / denominator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491d026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        for ind, graph in enumerate(total_laman_data[0]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        for ind, graph in enumerate(total_laman_data[1]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4862aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/custom-generated.pkl.gz\"\n",
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3885a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.7, .3]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec18e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsets.deepset import DeepSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27b19eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSets(\n",
      "  (lin1): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (lin2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (lin3): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  121\n"
     ]
    }
   ],
   "source": [
    "model = DeepSets(num_features=4)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f4689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

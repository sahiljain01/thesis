{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coefficient(G, node):\n",
    "    ns = [n for n in G.neighbors(node)]\n",
    "    if len(ns) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = len(ns) * (len(ns) - 1) / 2\n",
    "    for i in range(0, len(ns)):\n",
    "        for j in range(i+1, len(ns)):\n",
    "            n1, n2 = ns[i], ns[j]\n",
    "            numerator += G.has_edge(n1, n2)\n",
    "    \n",
    "    return numerator / denominator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(G):\n",
    "    x = torch.randn(G.number_of_nodes(), 2)\n",
    "    ind = 0\n",
    "    for node in G.nodes():\n",
    "        # set node degree as feature\n",
    "        x[ind][0] = G.degree[node]\n",
    "        x[ind][1] = clustering_coefficient(G, node)\n",
    "        ind += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        for ind, graph in enumerate(total_laman_data[0]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        for ind, graph in enumerate(total_laman_data[1]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data-2d/data/4096-20-4-entries-med.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 122], x=[32, 2], label=[1], num_nodes=32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laman_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.6, .4]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches:  10\n",
      "Number of test batches:  7\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches: \", len(train_loader))\n",
    "print(\"Number of test batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 18776], x=[5034, 2], label=[256], num_nodes=5034, batch=[5034], ptr=[257])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gin.gin import GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv2): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv3): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv4): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv5): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv6): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv7): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv8): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (lin1): Linear(in_features=28, out_features=28, bias=True)\n",
      "  (lin2): Linear(in_features=28, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  969\n"
     ]
    }
   ],
   "source": [
    "model = GIN(num_features=2)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=0.001)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', min_lr=1e-6, verbose=True, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, features_to_use):\n",
    "    ind = 0\n",
    "    for batch in data:\n",
    "        optimizer.zero_grad()\n",
    "        pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "        pred = torch.squeeze(pred)\n",
    "        loss = loss_fn(pred.float(), batch.label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ind += 1\n",
    "\n",
    "    return loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, features_to_use):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            y = batch.label\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Train loss 0.6044948101043701\n",
      "Train Accuracy 65.77126577126577 | Test Accuracy 65.95485051860891\n",
      "Epoch 1 | Train loss 0.6098939180374146\n",
      "Train Accuracy 65.77126577126577 | Test Accuracy 65.95485051860891\n",
      "Epoch 2 | Train loss 0.6249003410339355\n",
      "Train Accuracy 65.77126577126577 | Test Accuracy 65.95485051860891\n",
      "Epoch 3 | Train loss 0.6085838675498962\n",
      "Train Accuracy 65.77126577126577 | Test Accuracy 65.95485051860891\n",
      "Epoch 4 | Train loss 0.6361799240112305\n",
      "Train Accuracy 65.77126577126577 | Test Accuracy 65.95485051860891\n",
      "Epoch 5 | Train loss 0.618030846118927\n",
      "Train Accuracy 65.8933658933659 | Test Accuracy 66.01586333129957\n",
      "Epoch 6 | Train loss 0.5934194922447205\n",
      "Train Accuracy 66.0968660968661 | Test Accuracy 65.95485051860891\n",
      "Epoch 7 | Train loss 0.5735112428665161\n",
      "Train Accuracy 66.95156695156696 | Test Accuracy 67.41915802318486\n",
      "Epoch 8 | Train loss 0.6135768294334412\n",
      "Train Accuracy 67.43996743996745 | Test Accuracy 68.33435021354485\n",
      "Epoch 9 | Train loss 0.5661918520927429\n",
      "Train Accuracy 68.70166870166871 | Test Accuracy 69.43258084197682\n",
      "Epoch 10 | Train loss 0.5115947723388672\n",
      "Train Accuracy 71.75417175417176 | Test Accuracy 73.76449054301403\n",
      "Epoch 11 | Train loss 0.5258948802947998\n",
      "Train Accuracy 72.77167277167277 | Test Accuracy 74.0085417937767\n",
      "Epoch 12 | Train loss 0.4595990777015686\n",
      "Train Accuracy 71.22507122507122 | Test Accuracy 73.21537522879805\n",
      "Epoch 13 | Train loss 0.5157791972160339\n",
      "Train Accuracy 73.82987382987383 | Test Accuracy 75.10677242220866\n",
      "Epoch 14 | Train loss 0.4763919711112976\n",
      "Train Accuracy 73.13797313797313 | Test Accuracy 73.94752898108604\n",
      "Epoch 15 | Train loss 0.5496569871902466\n",
      "Train Accuracy 74.8066748066748 | Test Accuracy 75.83892617449665\n",
      "Epoch 16 | Train loss 0.42472511529922485\n",
      "Train Accuracy 76.06837606837607 | Test Accuracy 76.93715680292861\n",
      "Epoch 17 | Train loss 0.465122252702713\n",
      "Train Accuracy 77.004477004477 | Test Accuracy 77.73032336790726\n",
      "Epoch 18 | Train loss 0.4569656252861023\n",
      "Train Accuracy 77.81847781847782 | Test Accuracy 78.15741305674192\n",
      "Epoch 19 | Train loss 0.4462817907333374\n",
      "Train Accuracy 77.77777777777779 | Test Accuracy 78.52348993288591\n",
      "Epoch 20 | Train loss 0.4237927198410034\n",
      "Train Accuracy 76.63817663817663 | Test Accuracy 77.79133618059792\n",
      "Epoch 21 | Train loss 0.5291298031806946\n",
      "Train Accuracy 78.95807895807896 | Test Accuracy 79.98779743746186\n",
      "Epoch 22 | Train loss 0.4240621030330658\n",
      "Train Accuracy 79.03947903947905 | Test Accuracy 78.64551555826723\n",
      "Epoch 23 | Train loss 0.4582308530807495\n",
      "Train Accuracy 80.42328042328042 | Test Accuracy 81.5131177547285\n",
      "Epoch 24 | Train loss 0.41489773988723755\n",
      "Train Accuracy 80.95238095238095 | Test Accuracy 81.87919463087249\n",
      "Epoch 25 | Train loss 0.42399322986602783\n",
      "Train Accuracy 83.10948310948311 | Test Accuracy 83.5875533862111\n",
      "Epoch 26 | Train loss 0.37332528829574585\n",
      "Train Accuracy 82.78388278388277 | Test Accuracy 83.46552776082977\n",
      "Epoch 27 | Train loss 0.39579063653945923\n",
      "Train Accuracy 84.04558404558404 | Test Accuracy 83.64856619890178\n",
      "Epoch 28 | Train loss 0.37022268772125244\n",
      "Train Accuracy 84.004884004884 | Test Accuracy 84.19768151311774\n",
      "Epoch 29 | Train loss 0.37610068917274475\n",
      "Train Accuracy 84.20838420838422 | Test Accuracy 84.50274557657109\n",
      "Epoch 30 | Train loss 0.3532620966434479\n",
      "Train Accuracy 83.43508343508344 | Test Accuracy 83.70957901159244\n",
      "Epoch 31 | Train loss 0.3363907039165497\n",
      "Train Accuracy 80.0976800976801 | Test Accuracy 81.94020744356315\n",
      "Epoch 32 | Train loss 0.32504788041114807\n",
      "Train Accuracy 83.55718355718355 | Test Accuracy 83.70957901159244\n",
      "Epoch 33 | Train loss 0.34071433544158936\n",
      "Train Accuracy 85.83638583638583 | Test Accuracy 85.29591214154972\n",
      "Epoch 34 | Train loss 0.31514400243759155\n",
      "Train Accuracy 83.67928367928369 | Test Accuracy 84.9908480780964\n",
      "Epoch 35 | Train loss 0.3086678683757782\n",
      "Train Accuracy 86.56898656898657 | Test Accuracy 86.08907870652837\n",
      "Epoch 36 | Train loss 0.34703800082206726\n",
      "Train Accuracy 86.48758648758648 | Test Accuracy 86.27211714460037\n",
      "Epoch 37 | Train loss 0.2865464389324188\n",
      "Train Accuracy 86.85388685388685 | Test Accuracy 86.45515558267236\n",
      "Epoch 38 | Train loss 0.33106595277786255\n",
      "Train Accuracy 86.77248677248677 | Test Accuracy 86.88224527150702\n",
      "Epoch 39 | Train loss 0.34976059198379517\n",
      "Train Accuracy 86.40618640618641 | Test Accuracy 85.60097620500305\n",
      "Epoch 40 | Train loss 0.27109017968177795\n",
      "Train Accuracy 86.85388685388685 | Test Accuracy 86.51616839536302\n",
      "Epoch 41 | Train loss 0.3583965301513672\n",
      "Train Accuracy 84.9002849002849 | Test Accuracy 84.62477120195241\n",
      "Epoch 42 | Train loss 0.2687380313873291\n",
      "Train Accuracy 87.46438746438746 | Test Accuracy 87.24832214765101\n",
      "Epoch 43 | Train loss 0.2940230667591095\n",
      "Train Accuracy 84.16768416768417 | Test Accuracy 85.72300183038438\n",
      "Epoch 44 | Train loss 0.2734488248825073\n",
      "Train Accuracy 87.13878713878714 | Test Accuracy 86.45515558267236\n",
      "Epoch 45 | Train loss 0.2925296127796173\n",
      "Train Accuracy 89.09238909238908 | Test Accuracy 87.79743746186699\n",
      "Epoch 46 | Train loss 0.276291161775589\n",
      "Train Accuracy 88.35978835978835 | Test Accuracy 87.73642464917633\n",
      "Epoch 47 | Train loss 0.33044883608818054\n",
      "Train Accuracy 88.23768823768823 | Test Accuracy 87.980475899939\n",
      "Epoch 48 | Train loss 0.2552131116390228\n",
      "Train Accuracy 90.10989010989012 | Test Accuracy 88.95668090298963\n",
      "Epoch 49 | Train loss 0.25422924757003784\n",
      "Train Accuracy 86.44688644688645 | Test Accuracy 87.67541183648567\n",
      "Epoch 50 | Train loss 0.24088741838932037\n",
      "Train Accuracy 88.07488807488808 | Test Accuracy 87.55338621110434\n",
      "Epoch 51 | Train loss 0.31839072704315186\n",
      "Train Accuracy 87.38298738298738 | Test Accuracy 88.22452715070165\n",
      "Epoch 52 | Train loss 0.2356850653886795\n",
      "Train Accuracy 88.92958892958893 | Test Accuracy 88.40756558877364\n",
      "Epoch 53 | Train loss 0.24949583411216736\n",
      "Train Accuracy 90.76109076109076 | Test Accuracy 89.93288590604027\n",
      "Epoch 54 | Train loss 0.29792022705078125\n",
      "Train Accuracy 89.86568986568987 | Test Accuracy 88.71262965222697\n",
      "Epoch 55 | Train loss 0.24797910451889038\n",
      "Train Accuracy 90.35409035409036 | Test Accuracy 90.66503965832825\n",
      "Epoch 56 | Train loss 0.2713564336299896\n",
      "Train Accuracy 90.76109076109076 | Test Accuracy 89.38377059182429\n",
      "Epoch 57 | Train loss 0.22681748867034912\n",
      "Train Accuracy 90.35409035409036 | Test Accuracy 90.84807809640024\n",
      "Epoch 58 | Train loss 0.253801167011261\n",
      "Train Accuracy 91.4936914936915 | Test Accuracy 90.48200122025627\n",
      "Epoch 59 | Train loss 0.2806624472141266\n",
      "Train Accuracy 91.29019129019129 | Test Accuracy 90.48200122025627\n",
      "Epoch 60 | Train loss 0.267659068107605\n",
      "Train Accuracy 90.06919006919006 | Test Accuracy 90.78706528370958\n",
      "Epoch 61 | Train loss 0.21256814897060394\n",
      "Train Accuracy 91.4936914936915 | Test Accuracy 90.60402684563759\n",
      "Epoch 62 | Train loss 0.26151925325393677\n",
      "Train Accuracy 92.18559218559218 | Test Accuracy 91.64124466137889\n",
      "Epoch 63 | Train loss 0.22232066094875336\n",
      "Train Accuracy 90.92389092389092 | Test Accuracy 90.48200122025627\n",
      "Epoch 64 | Train loss 0.22554230690002441\n",
      "Train Accuracy 91.45299145299145 | Test Accuracy 92.06833435021355\n",
      "Epoch 65 | Train loss 0.24545347690582275\n",
      "Train Accuracy 91.85999185999187 | Test Accuracy 92.19035997559487\n",
      "Epoch 66 | Train loss 0.2437165230512619\n",
      "Train Accuracy 92.5925925925926 | Test Accuracy 92.73947528981085\n",
      "Epoch 67 | Train loss 0.23675818741321564\n",
      "Train Accuracy 92.10419210419211 | Test Accuracy 91.58023184868821\n",
      "Epoch 68 | Train loss 0.2064623087644577\n",
      "Train Accuracy 93.52869352869352 | Test Accuracy 92.4954240390482\n",
      "Epoch 69 | Train loss 0.2055303156375885\n",
      "Train Accuracy 92.34839234839235 | Test Accuracy 92.4954240390482\n",
      "Epoch 70 | Train loss 0.18448506295681\n",
      "Train Accuracy 92.87749287749287 | Test Accuracy 92.00732153752288\n",
      "Epoch 71 | Train loss 0.21767370402812958\n",
      "Train Accuracy 92.18559218559218 | Test Accuracy 92.67846247712019\n",
      "Epoch 72 | Train loss 0.2013643980026245\n",
      "Train Accuracy 93.85429385429386 | Test Accuracy 93.8987187309335\n",
      "Epoch 73 | Train loss 0.2190043330192566\n",
      "Train Accuracy 93.77289377289377 | Test Accuracy 93.77669310555217\n",
      "Epoch 74 | Train loss 0.21439406275749207\n",
      "Train Accuracy 93.81359381359381 | Test Accuracy 93.47162904209884\n",
      "Epoch 75 | Train loss 0.19263000786304474\n",
      "Train Accuracy 94.42409442409443 | Test Accuracy 94.20378279438683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train loss 0.18575449287891388\n",
      "Train Accuracy 94.0984940984941 | Test Accuracy 93.95973154362416\n",
      "Epoch 77 | Train loss 0.19238246977329254\n",
      "Train Accuracy 93.48799348799349 | Test Accuracy 93.34960341671751\n",
      "Epoch 78 | Train loss 0.2147490531206131\n",
      "Train Accuracy 94.46479446479447 | Test Accuracy 94.14276998169616\n",
      "Epoch 79 | Train loss 0.17558468878269196\n",
      "Train Accuracy 92.38909238909238 | Test Accuracy 92.67846247712019\n",
      "Epoch 80 | Train loss 0.1756524294614792\n",
      "Train Accuracy 93.52869352869352 | Test Accuracy 93.47162904209884\n",
      "Epoch 81 | Train loss 0.1841973513364792\n",
      "Train Accuracy 94.46479446479447 | Test Accuracy 94.08175716900548\n",
      "Epoch 82 | Train loss 0.1860804259777069\n",
      "Train Accuracy 94.26129426129425 | Test Accuracy 94.5698596705308\n",
      "Epoch 83 | Train loss 0.17216694355010986\n",
      "Train Accuracy 95.23809523809523 | Test Accuracy 94.69188529591214\n",
      "Epoch 84 | Train loss 0.15657725930213928\n",
      "Train Accuracy 94.42409442409443 | Test Accuracy 94.26479560707749\n",
      "Epoch 85 | Train loss 0.23420964181423187\n",
      "Train Accuracy 93.61009361009361 | Test Accuracy 93.34960341671751\n",
      "Epoch 86 | Train loss 0.15080192685127258\n",
      "Train Accuracy 95.68579568579568 | Test Accuracy 95.36302623550945\n",
      "Epoch 87 | Train loss 0.2212645560503006\n",
      "Train Accuracy 95.44159544159544 | Test Accuracy 95.17998779743746\n",
      "Epoch 88 | Train loss 0.18740476667881012\n",
      "Train Accuracy 95.15669515669516 | Test Accuracy 95.24100061012813\n",
      "Epoch 89 | Train loss 0.1922912746667862\n",
      "Train Accuracy 95.8078958078958 | Test Accuracy 95.54606467358145\n",
      "Epoch 90 | Train loss 0.1818726360797882\n",
      "Train Accuracy 93.4065934065934 | Test Accuracy 93.47162904209884\n",
      "Epoch 91 | Train loss 0.17214904725551605\n",
      "Train Accuracy 95.8892958892959 | Test Accuracy 95.91214154972543\n",
      "Epoch 92 | Train loss 0.17929883301258087\n",
      "Train Accuracy 95.36019536019536 | Test Accuracy 95.24100061012813\n",
      "Epoch 93 | Train loss 0.17536389827728271\n",
      "Train Accuracy 96.01139601139602 | Test Accuracy 95.91214154972543\n",
      "Epoch 94 | Train loss 0.18446387350559235\n",
      "Train Accuracy 95.8078958078958 | Test Accuracy 96.09517998779744\n",
      "Epoch 95 | Train loss 0.16666090488433838\n",
      "Train Accuracy 96.29629629629629 | Test Accuracy 95.85112873703477\n",
      "Epoch 96 | Train loss 0.18162527680397034\n",
      "Train Accuracy 95.31949531949532 | Test Accuracy 95.17998779743746\n",
      "Epoch 97 | Train loss 0.1624702662229538\n",
      "Train Accuracy 95.1159951159951 | Test Accuracy 94.81391092129347\n",
      "Epoch 98 | Train loss 0.10886000096797943\n",
      "Train Accuracy 96.21489621489621 | Test Accuracy 95.9731543624161\n",
      "Epoch 99 | Train loss 0.1497674137353897\n",
      "Train Accuracy 95.64509564509565 | Test Accuracy 94.93593654667481\n",
      "Epoch 100 | Train loss 0.15159261226654053\n",
      "Train Accuracy 96.45909645909646 | Test Accuracy 96.46125686394143\n",
      "Epoch 101 | Train loss 0.17578883469104767\n",
      "Train Accuracy 96.58119658119658 | Test Accuracy 96.40024405125077\n",
      "Epoch 102 | Train loss 0.16812863945960999\n",
      "Train Accuracy 96.33699633699634 | Test Accuracy 96.27821842586943\n",
      "Epoch 103 | Train loss 0.11623841524124146\n",
      "Train Accuracy 96.82539682539682 | Test Accuracy 96.40024405125077\n",
      "Epoch 104 | Train loss 0.1472262144088745\n",
      "Train Accuracy 96.90679690679691 | Test Accuracy 96.64429530201343\n",
      "Epoch 105 | Train loss 0.16283008456230164\n",
      "Train Accuracy 95.03459503459504 | Test Accuracy 95.36302623550945\n",
      "Epoch 106 | Train loss 0.11872697621583939\n",
      "Train Accuracy 97.27309727309728 | Test Accuracy 96.76632092739476\n",
      "Epoch 107 | Train loss 0.12934941053390503\n",
      "Train Accuracy 97.27309727309728 | Test Accuracy 96.76632092739476\n",
      "Epoch 108 | Train loss 0.1473681926727295\n",
      "Train Accuracy 96.86609686609687 | Test Accuracy 96.76632092739476\n",
      "Epoch 109 | Train loss 0.10240944474935532\n",
      "Train Accuracy 95.1973951973952 | Test Accuracy 94.5698596705308\n",
      "Epoch 110 | Train loss 0.10858742892742157\n",
      "Train Accuracy 96.21489621489621 | Test Accuracy 95.91214154972543\n",
      "Epoch 111 | Train loss 0.10454535484313965\n",
      "Train Accuracy 95.8892958892959 | Test Accuracy 95.30201342281879\n",
      "Epoch 112 | Train loss 0.11744333058595657\n",
      "Train Accuracy 97.51729751729752 | Test Accuracy 97.43746186699207\n",
      "Epoch 113 | Train loss 0.11892140656709671\n",
      "Train Accuracy 97.31379731379731 | Test Accuracy 97.1934106162294\n",
      "Epoch 114 | Train loss 0.09384021908044815\n",
      "Train Accuracy 95.68579568579568 | Test Accuracy 95.30201342281879\n",
      "Epoch 115 | Train loss 0.10435449331998825\n",
      "Train Accuracy 94.87179487179486 | Test Accuracy 94.99694935936547\n",
      "Epoch 116 | Train loss 0.1720626801252365\n",
      "Train Accuracy 97.88359788359789 | Test Accuracy 97.55948749237339\n",
      "Epoch 117 | Train loss 0.16561970114707947\n",
      "Train Accuracy 97.8021978021978 | Test Accuracy 97.55948749237339\n",
      "Epoch 118 | Train loss 0.1416947841644287\n",
      "Train Accuracy 97.72079772079772 | Test Accuracy 97.3764490543014\n",
      "Epoch 119 | Train loss 0.11804506927728653\n",
      "Train Accuracy 98.16849816849816 | Test Accuracy 97.86455155582672\n",
      "Epoch 120 | Train loss 0.08200124651193619\n",
      "Train Accuracy 97.8021978021978 | Test Accuracy 97.62050030506406\n",
      "Epoch 121 | Train loss 0.17543154954910278\n",
      "Train Accuracy 96.58119658119658 | Test Accuracy 96.46125686394143\n",
      "Epoch 122 | Train loss 0.1011810377240181\n",
      "Train Accuracy 97.23239723239723 | Test Accuracy 96.94935936546675\n",
      "Epoch 123 | Train loss 0.14030806720256805\n",
      "Train Accuracy 96.29629629629629 | Test Accuracy 96.09517998779744\n",
      "Epoch 124 | Train loss 0.1305699199438095\n",
      "Train Accuracy 97.63939763939764 | Test Accuracy 97.43746186699207\n",
      "Epoch 125 | Train loss 0.08457616716623306\n",
      "Train Accuracy 98.16849816849816 | Test Accuracy 97.86455155582672\n",
      "Epoch 126 | Train loss 0.09597308188676834\n",
      "Train Accuracy 98.2091982091982 | Test Accuracy 98.29164124466138\n",
      "Epoch 127 | Train loss 0.08210628479719162\n",
      "Train Accuracy 97.51729751729752 | Test Accuracy 97.55948749237339\n",
      "Epoch 128 | Train loss 0.10096851736307144\n",
      "Train Accuracy 98.29059829059828 | Test Accuracy 98.10860280658939\n",
      "Epoch 129 | Train loss 0.13610133528709412\n",
      "Train Accuracy 98.37199837199837 | Test Accuracy 98.10860280658939\n",
      "Epoch 130 | Train loss 0.0990188717842102\n",
      "Train Accuracy 98.16849816849816 | Test Accuracy 97.86455155582672\n",
      "Epoch 131 | Train loss 0.15353812277317047\n",
      "Train Accuracy 98.29059829059828 | Test Accuracy 98.10860280658939\n",
      "Epoch 132 | Train loss 0.16341553628444672\n",
      "Train Accuracy 98.4126984126984 | Test Accuracy 98.10860280658939\n",
      "Epoch 133 | Train loss 0.07625623792409897\n",
      "Train Accuracy 98.45339845339845 | Test Accuracy 98.4136668700427\n",
      "Epoch 134 | Train loss 0.08212442696094513\n",
      "Train Accuracy 98.57549857549857 | Test Accuracy 98.53569249542404\n",
      "Epoch 135 | Train loss 0.11605685204267502\n",
      "Train Accuracy 98.61619861619862 | Test Accuracy 98.53569249542404\n",
      "Epoch 136 | Train loss 0.09681462496519089\n",
      "Train Accuracy 98.4126984126984 | Test Accuracy 98.16961561928005\n",
      "Epoch 137 | Train loss 0.07357680797576904\n",
      "Train Accuracy 98.53479853479854 | Test Accuracy 98.35265405735204\n",
      "Epoch 138 | Train loss 0.09261863678693771\n",
      "Train Accuracy 98.45339845339845 | Test Accuracy 98.16961561928005\n",
      "Epoch 139 | Train loss 0.08355607092380524\n",
      "Train Accuracy 98.61619861619862 | Test Accuracy 98.35265405735204\n",
      "Epoch 140 | Train loss 0.07380859553813934\n",
      "Train Accuracy 98.86039886039886 | Test Accuracy 98.47467968273338\n",
      "Epoch 141 | Train loss 0.08600623160600662\n",
      "Train Accuracy 98.57549857549857 | Test Accuracy 98.59670530811471\n",
      "Epoch 142 | Train loss 0.08652486652135849\n",
      "Train Accuracy 97.63939763939764 | Test Accuracy 97.9255643685174\n",
      "Epoch 143 | Train loss 0.10842480510473251\n",
      "Train Accuracy 97.15099715099716 | Test Accuracy 97.55948749237339\n",
      "Epoch 144 | Train loss 0.1235310435295105\n",
      "Train Accuracy 96.94749694749694 | Test Accuracy 97.31543624161074\n",
      "Epoch 145 | Train loss 0.07486604154109955\n",
      "Train Accuracy 97.35449735449735 | Test Accuracy 97.55948749237339\n",
      "Epoch 146 | Train loss 0.07599823921918869\n",
      "Train Accuracy 98.57549857549857 | Test Accuracy 98.53569249542404\n",
      "Epoch 147 | Train loss 0.07189809530973434\n",
      "Train Accuracy 98.81969881969881 | Test Accuracy 99.02379499694935\n",
      "Epoch 148 | Train loss 0.05884109437465668\n",
      "Train Accuracy 98.2091982091982 | Test Accuracy 98.23062843197071\n",
      "Epoch 149 | Train loss 0.07758370041847229\n",
      "Train Accuracy 98.9010989010989 | Test Accuracy 98.90176937156802\n",
      "Epoch 150 | Train loss 0.06853533536195755\n",
      "Train Accuracy 97.8021978021978 | Test Accuracy 97.86455155582672\n",
      "Epoch 151 | Train loss 0.062256600707769394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 98.61619861619862 | Test Accuracy 98.7797437461867\n",
      "Epoch 152 | Train loss 0.0882212221622467\n",
      "Train Accuracy 98.9010989010989 | Test Accuracy 99.08480780964003\n",
      "Epoch 153 | Train loss 0.07309981435537338\n",
      "Train Accuracy 98.2091982091982 | Test Accuracy 98.23062843197071\n",
      "Epoch 154 | Train loss 0.06353852897882462\n",
      "Train Accuracy 98.94179894179894 | Test Accuracy 99.20683343502135\n",
      "Epoch 155 | Train loss 0.0583437941968441\n",
      "Train Accuracy 99.3080993080993 | Test Accuracy 98.84075655887736\n",
      "Epoch 156 | Train loss 0.05433236062526703\n",
      "Train Accuracy 98.98249898249898 | Test Accuracy 99.08480780964003\n",
      "Epoch 157 | Train loss 0.07300922274589539\n",
      "Train Accuracy 98.53479853479854 | Test Accuracy 98.65771812080537\n",
      "Epoch 158 | Train loss 0.08992498368024826\n",
      "Train Accuracy 98.4940984940985 | Test Accuracy 98.53569249542404\n",
      "Epoch 159 | Train loss 0.10562876611948013\n",
      "Train Accuracy 99.14529914529915 | Test Accuracy 98.59670530811471\n",
      "Epoch 160 | Train loss 0.06627199053764343\n",
      "Train Accuracy 98.61619861619862 | Test Accuracy 98.7797437461867\n",
      "Epoch 161 | Train loss 0.0582905188202858\n",
      "Train Accuracy 98.98249898249898 | Test Accuracy 99.08480780964003\n",
      "Epoch 162 | Train loss 0.10602360218763351\n",
      "Train Accuracy 99.43019943019942 | Test Accuracy 98.96278218425869\n",
      "Epoch 163 | Train loss 0.057900361716747284\n",
      "Train Accuracy 98.24989824989825 | Test Accuracy 98.35265405735204\n",
      "Epoch 164 | Train loss 0.07252853363752365\n",
      "Train Accuracy 98.57549857549857 | Test Accuracy 98.7797437461867\n",
      "Epoch 165 | Train loss 0.057143423706293106\n",
      "Train Accuracy 99.06389906389906 | Test Accuracy 99.14582062233069\n",
      "Epoch 166 | Train loss 0.06130358576774597\n",
      "Train Accuracy 98.94179894179894 | Test Accuracy 98.90176937156802\n",
      "Epoch 167 | Train loss 0.061080384999513626\n",
      "Train Accuracy 99.06389906389906 | Test Accuracy 99.14582062233069\n",
      "Epoch 168 | Train loss 0.06785812228918076\n",
      "Train Accuracy 99.22669922669922 | Test Accuracy 99.26784624771201\n",
      "Epoch 169 | Train loss 0.08316438645124435\n",
      "Train Accuracy 99.18599918599918 | Test Accuracy 99.26784624771201\n",
      "Epoch 170 | Train loss 0.07080420106649399\n",
      "Train Accuracy 98.57549857549857 | Test Accuracy 98.65771812080537\n",
      "Epoch 171 | Train loss 0.06296484172344208\n",
      "Train Accuracy 99.55229955229954 | Test Accuracy 99.20683343502135\n",
      "Epoch 172 | Train loss 0.040342241525650024\n",
      "Train Accuracy 99.51159951159951 | Test Accuracy 99.26784624771201\n",
      "Epoch 173 | Train loss 0.1215469241142273\n",
      "Train Accuracy 99.5929995929996 | Test Accuracy 99.14582062233069\n",
      "Epoch 174 | Train loss 0.04174549877643585\n",
      "Train Accuracy 99.22669922669922 | Test Accuracy 99.32885906040269\n",
      "Epoch 175 | Train loss 0.04839066043496132\n",
      "Train Accuracy 98.73829873829874 | Test Accuracy 98.84075655887736\n",
      "Epoch 176 | Train loss 0.05697939172387123\n",
      "Train Accuracy 99.22669922669922 | Test Accuracy 99.32885906040269\n",
      "Epoch 177 | Train loss 0.06682541221380234\n",
      "Train Accuracy 99.51159951159951 | Test Accuracy 99.20683343502135\n",
      "Epoch 178 | Train loss 0.059513602405786514\n",
      "Train Accuracy 98.86039886039886 | Test Accuracy 98.59670530811471\n",
      "Epoch 179 | Train loss 0.07235059887170792\n",
      "Train Accuracy 99.63369963369964 | Test Accuracy 99.14582062233069\n",
      "Epoch 180 | Train loss 0.16116949915885925\n",
      "Train Accuracy 98.45339845339845 | Test Accuracy 98.65771812080537\n",
      "Epoch 181 | Train loss 0.09742871671915054\n",
      "Train Accuracy 97.31379731379731 | Test Accuracy 97.43746186699207\n",
      "Epoch 182 | Train loss 0.04854493960738182\n",
      "Train Accuracy 98.00569800569801 | Test Accuracy 98.10860280658939\n",
      "Epoch 183 | Train loss 0.05501318350434303\n",
      "Train Accuracy 99.5929995929996 | Test Accuracy 99.20683343502135\n",
      "Epoch 184 | Train loss 0.08770958334207535\n",
      "Train Accuracy 99.38949938949939 | Test Accuracy 99.32885906040269\n",
      "Epoch 185 | Train loss 0.06197347119450569\n",
      "Train Accuracy 99.51159951159951 | Test Accuracy 99.38987187309336\n",
      "Epoch 186 | Train loss 0.05406605824828148\n",
      "Train Accuracy 99.5929995929996 | Test Accuracy 99.32885906040269\n",
      "Epoch 187 | Train loss 0.036559849977493286\n",
      "Train Accuracy 99.51159951159951 | Test Accuracy 99.38987187309336\n",
      "Epoch 188 | Train loss 0.051537007093429565\n",
      "Train Accuracy 99.5929995929996 | Test Accuracy 99.38987187309336\n",
      "Epoch 189 | Train loss 0.059959061443805695\n",
      "Train Accuracy 99.02319902319903 | Test Accuracy 99.02379499694935\n",
      "Epoch 190 | Train loss 0.05127815157175064\n",
      "Train Accuracy 99.18599918599918 | Test Accuracy 99.20683343502135\n",
      "Epoch 191 | Train loss 0.06840173155069351\n",
      "Train Accuracy 99.18599918599918 | Test Accuracy 98.90176937156802\n",
      "Epoch 192 | Train loss 0.04506392776966095\n",
      "Train Accuracy 99.55229955229954 | Test Accuracy 99.08480780964003\n",
      "Epoch 193 | Train loss 0.03997892513871193\n",
      "Train Accuracy 99.43019943019942 | Test Accuracy 99.32885906040269\n",
      "Epoch 194 | Train loss 0.03844369947910309\n",
      "Train Accuracy 98.86039886039886 | Test Accuracy 98.90176937156802\n",
      "Epoch 195 | Train loss 0.09097433090209961\n",
      "Train Accuracy 99.1045991045991 | Test Accuracy 99.08480780964003\n",
      "Epoch 196 | Train loss 0.044530339539051056\n",
      "Train Accuracy 99.67439967439967 | Test Accuracy 99.20683343502135\n",
      "Epoch 197 | Train loss 0.04582587629556656\n",
      "Train Accuracy 99.02319902319903 | Test Accuracy 99.02379499694935\n",
      "Epoch 198 | Train loss 0.044997282326221466\n",
      "Train Accuracy 99.55229955229954 | Test Accuracy 99.38987187309336\n",
      "Epoch 199 | Train loss 0.04115422070026398\n",
      "Train Accuracy 99.67439967439967 | Test Accuracy 99.38987187309336\n",
      "Epoch 200 | Train loss 0.06648021191358566\n",
      "Train Accuracy 99.55229955229954 | Test Accuracy 99.45088468578402\n",
      "Epoch 201 | Train loss 0.039522744715213776\n",
      "Train Accuracy 99.47089947089947 | Test Accuracy 99.38987187309336\n",
      "Epoch 202 | Train loss 0.04398409649729729\n",
      "Train Accuracy 99.63369963369964 | Test Accuracy 99.26784624771201\n",
      "Epoch 203 | Train loss 0.03995431214570999\n",
      "Train Accuracy 99.38949938949939 | Test Accuracy 99.26784624771201\n",
      "Epoch 204 | Train loss 0.03211209177970886\n",
      "Train Accuracy 99.67439967439967 | Test Accuracy 99.32885906040269\n",
      "Epoch 205 | Train loss 0.029221080243587494\n",
      "Train Accuracy 99.38949938949939 | Test Accuracy 99.26784624771201\n",
      "Epoch 206 | Train loss 0.03743792325258255\n",
      "Train Accuracy 99.47089947089947 | Test Accuracy 99.45088468578402\n",
      "Epoch 207 | Train loss 0.03532649204134941\n",
      "Train Accuracy 99.71509971509973 | Test Accuracy 99.38987187309336\n",
      "Epoch 208 | Train loss 0.03648583963513374\n",
      "Train Accuracy 99.22669922669922 | Test Accuracy 99.08480780964003\n",
      "Epoch 209 | Train loss 0.05336974561214447\n",
      "Train Accuracy 99.75579975579976 | Test Accuracy 99.38987187309336\n",
      "Epoch 210 | Train loss 0.03366934880614281\n",
      "Train Accuracy 99.38949938949939 | Test Accuracy 99.26784624771201\n",
      "Epoch 211 | Train loss 0.048633936792612076\n",
      "Train Accuracy 99.34879934879935 | Test Accuracy 99.26784624771201\n",
      "Epoch 212 | Train loss 0.03441452234983444\n",
      "Train Accuracy 99.75579975579976 | Test Accuracy 99.38987187309336\n",
      "Epoch 213 | Train loss 0.02783634513616562\n",
      "Train Accuracy 99.71509971509973 | Test Accuracy 99.45088468578402\n",
      "Epoch 214 | Train loss 0.04318336397409439\n",
      "Train Accuracy 99.22669922669922 | Test Accuracy 99.14582062233069\n",
      "Epoch 215 | Train loss 0.032068319618701935\n",
      "Train Accuracy 99.67439967439967 | Test Accuracy 99.38987187309336\n",
      "Epoch 216 | Train loss 0.02880817838013172\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.38987187309336\n",
      "Epoch 217 | Train loss 0.05391408130526543\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.38987187309336\n",
      "Epoch 218 | Train loss 0.06834923475980759\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.51189749847468\n",
      "Epoch 219 | Train loss 0.031140953302383423\n",
      "Train Accuracy 99.34879934879935 | Test Accuracy 99.45088468578402\n",
      "Epoch 220 | Train loss 0.0345596969127655\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.57291031116534\n",
      "Epoch 221 | Train loss 0.03704077750444412\n",
      "Train Accuracy 99.22669922669922 | Test Accuracy 99.14582062233069\n",
      "Epoch 222 | Train loss 0.029990622773766518\n",
      "Train Accuracy 99.67439967439967 | Test Accuracy 99.45088468578402\n",
      "Epoch 223 | Train loss 0.0344729945063591\n",
      "Train Accuracy 99.67439967439967 | Test Accuracy 99.38987187309336\n",
      "Epoch 224 | Train loss 0.02486833557486534\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.45088468578402\n",
      "Epoch 225 | Train loss 0.054742999374866486\n",
      "Train Accuracy 99.43019943019942 | Test Accuracy 99.51189749847468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226 | Train loss 0.021558355540037155\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.45088468578402\n",
      "Epoch 227 | Train loss 0.03497352451086044\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.51189749847468\n",
      "Epoch 228 | Train loss 0.029473721981048584\n",
      "Train Accuracy 99.63369963369964 | Test Accuracy 99.51189749847468\n",
      "Epoch 229 | Train loss 0.026982827112078667\n",
      "Train Accuracy 99.34879934879935 | Test Accuracy 99.38987187309336\n",
      "Epoch 230 | Train loss 0.03535410016775131\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.57291031116534\n",
      "Epoch 231 | Train loss 0.0234312042593956\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.57291031116534\n",
      "Epoch 232 | Train loss 0.026615804061293602\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.51189749847468\n",
      "Epoch 233 | Train loss 0.05049692839384079\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.63392312385601\n",
      "Epoch 234 | Train loss 0.022268274798989296\n",
      "Train Accuracy 99.1045991045991 | Test Accuracy 99.02379499694935\n",
      "Epoch 235 | Train loss 0.04838879406452179\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.63392312385601\n",
      "Epoch 236 | Train loss 0.03141853213310242\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.57291031116534\n",
      "Epoch 237 | Train loss 0.03118431568145752\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.51189749847468\n",
      "Epoch 238 | Train loss 0.022482695057988167\n",
      "Train Accuracy 99.34879934879935 | Test Accuracy 99.38987187309336\n",
      "Epoch 239 | Train loss 0.023264605551958084\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.57291031116534\n",
      "Epoch 240 | Train loss 0.019738592207431793\n",
      "Train Accuracy 99.75579975579976 | Test Accuracy 99.51189749847468\n",
      "Epoch 241 | Train loss 0.016701921820640564\n",
      "Train Accuracy 99.38949938949939 | Test Accuracy 99.38987187309336\n",
      "Epoch 242 | Train loss 0.024496188387274742\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.57291031116534\n",
      "Epoch 243 | Train loss 0.0367630310356617\n",
      "Train Accuracy 99.71509971509973 | Test Accuracy 99.45088468578402\n",
      "Epoch 244 | Train loss 0.02685544081032276\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.57291031116534\n",
      "Epoch 245 | Train loss 0.025712616741657257\n",
      "Train Accuracy 99.55229955229954 | Test Accuracy 99.51189749847468\n",
      "Epoch 246 | Train loss 0.02424710802733898\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.63392312385601\n",
      "Epoch 247 | Train loss 0.022355202585458755\n",
      "Train Accuracy 99.38949938949939 | Test Accuracy 99.38987187309336\n",
      "Epoch 248 | Train loss 0.02198990061879158\n",
      "Train Accuracy 99.06389906389906 | Test Accuracy 99.20683343502135\n",
      "Epoch 249 | Train loss 0.02505786158144474\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.63392312385601\n",
      "Epoch 250 | Train loss 0.015808865427970886\n",
      "Train Accuracy 99.3080993080993 | Test Accuracy 99.51189749847468\n",
      "Epoch 251 | Train loss 0.016501648351550102\n",
      "Train Accuracy 99.47089947089947 | Test Accuracy 99.51189749847468\n",
      "Epoch 252 | Train loss 0.024240605533123016\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.75594874923735\n",
      "Epoch 253 | Train loss 0.016674872487783432\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.63392312385601\n",
      "Epoch 254 | Train loss 0.03023509494960308\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.51189749847468\n",
      "Epoch 255 | Train loss 0.04661572724580765\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.69493593654668\n",
      "Epoch 256 | Train loss 0.022056065499782562\n",
      "Train Accuracy 99.71509971509973 | Test Accuracy 99.51189749847468\n",
      "Epoch 257 | Train loss 0.021279914304614067\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.69493593654668\n",
      "Epoch 258 | Train loss 0.02357492968440056\n",
      "Train Accuracy 99.75579975579976 | Test Accuracy 99.51189749847468\n",
      "Epoch 259 | Train loss 0.02401251159608364\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.69493593654668\n",
      "Epoch 260 | Train loss 0.016706077381968498\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.75594874923735\n",
      "Epoch 261 | Train loss 0.017308516427874565\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.75594874923735\n",
      "Epoch 262 | Train loss 0.01760980673134327\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     train_acc, test_acc \u001b[38;5;241m=\u001b[39m check_accuracy(model, train_loader, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]), \u001b[43mcheck_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     scheduler.step(test_acc)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m, in \u001b[0;36mcheck_accuracy\u001b[0;34m(model, loader, features_to_use)\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m      8\u001b[0m         pred, embedding \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx[:, features_to_use], batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m      9\u001b[0m         pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(pred)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/loader/dataloader.py:20\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/data/batch.py:76\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_list: List[BaseData],\n\u001b[1;32m     66\u001b[0m                    follow_batch: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m                    exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)\n\u001b[1;32m     86\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/data/collate.py:84\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[1;32m     88\u001b[0m     device \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/data/collate.py:155\u001b[0m, in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value, slices, incs\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, SparseTensor) \u001b[38;5;129;01mand\u001b[39;00m increment:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Concatenate a list of `SparseTensor` along the `cat_dim`.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# NOTE: `cat_dim` may return a tuple to allow for diagonal stacking.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, model = train(model, train_loader, [0, 1])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model, train_loader, [0, 1]), check_accuracy(model, test_loader, [0, 1])\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "#     scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square\n",
    "import networkx as nx\n",
    "square = nx.Graph()\n",
    "square.add_edge(0, 1)\n",
    "square.add_edge(1, 3)\n",
    "square.add_edge(0, 2)\n",
    "square.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square with cross bar (rigid)\n",
    "import networkx as nx\n",
    "square_bar = nx.Graph()\n",
    "square_bar.add_edge(0, 1)\n",
    "square_bar.add_edge(1, 3)\n",
    "square_bar.add_edge(0, 2)\n",
    "square_bar.add_edge(2, 3)\n",
    "square_bar.add_edge(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle\n",
    "import networkx as nx\n",
    "triangle = nx.Graph()\n",
    "triangle.add_edge(0, 1)\n",
    "triangle.add_edge(0, 2)\n",
    "triangle.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentagon\n",
    "import networkx as nx\n",
    "pentagon = nx.Graph()\n",
    "pentagon.add_edge(0, 1)\n",
    "pentagon.add_edge(1, 3)\n",
    "pentagon.add_edge(3, 4)\n",
    "pentagon.add_edge(4, 2)\n",
    "pentagon.add_edge(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no triangle and rigid\n",
    "rigid = nx.Graph()\n",
    "rigid.add_edge(0, 1)\n",
    "rigid.add_edge(0, 2)\n",
    "rigid.add_edge(0, 4)\n",
    "rigid.add_edge(1, 2)\n",
    "rigid.add_edge(1, 5)\n",
    "rigid.add_edge(2, 3)\n",
    "rigid.add_edge(3, 4)\n",
    "rigid.add_edge(3, 5)\n",
    "rigid.add_edge(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9944]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0513]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6229]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9998]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0747]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "toy_problems = [square, square_bar, triangle, pentagon, rigid]\n",
    "labels = [1, 0, 0, 1, 0]\n",
    "\n",
    "for index, toy_problem in enumerate(toy_problems):\n",
    "    graph_as_data = from_networkx(toy_problem)\n",
    "    graph_as_data.x = generate_feature_vector(toy_problem)\n",
    "    graph_as_data.label = labels[index]\n",
    "    validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "    for batch in validation_set:\n",
    "        pred = model(batch.x[:, [0, 1]], batch.edge_index, batch.batch)\n",
    "        print(pred[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 18], num_nodes=6, x=[6, 2], label=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_as_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in validation_set:\n",
    "    pred = bestModel(batch.x, batch.edge_index, batch.batch)\n",
    "    print(pred[0])\n",
    "    print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanTestDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_test.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# add functionality to support a test dataset\n",
    "TEST_DATA_PATH = \"../data-2d/data/test-dataset-30loc-5std.pkl.gz\"\n",
    "laman_test_set = LamanTestDataset(\"\", TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "laman_test_loader = DataLoader(laman_test_set, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 96.09375\n"
     ]
    }
   ],
   "source": [
    "random_test_acc = check_accuracy(model, laman_test_loader, [0, 1])\n",
    "print(f\"Accuracy {random_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the clustering coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(triangle, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square_bar, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate graph correlating clustering coefficient to rigidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_data:\n",
    "    item = to_networkx(item)\n",
    "    print(type(item))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric.utils.convert.to_networkx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work: Sahil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_laman_data = None\n",
    "with gzip.open(DATA_PATH, 'r') as f:\n",
    "    total_laman_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph = total_laman_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_data = from_networkx(sample_graph)\n",
    "from_data = to_networkx(to_data, to_undirected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_clustering_coefficient(G):\n",
    "    min_coefficient = 1\n",
    "    for node in G.nodes():\n",
    "        min_coefficient = min(min_coefficient, clustering_coefficient(G, node))\n",
    "        \n",
    "    return min_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sample_graph in enumerate(train_data):\n",
    "    label = sample_graph.label\n",
    "    networkx_sample_graph = to_networkx(sample_graph, to_undirected = True)\n",
    "    print(label, \" \", index, \" \", compute_min_clustering_coefficient(networkx_sample_graph))\n",
    "    \n",
    "    if index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_min_clustering_coefficient(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_min_clustering_coefficient(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if instead of training a gnn – you just trained on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the degrees of the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the triangle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on the triangle features and the degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a network with just degree of the node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_just_degree = GIN(num_features=1)\n",
    "print(model_just_degree)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, h = train(train_loader, [0, 1])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model_just_degree, train_loader), check_accuracy(model_just_degree, test_loader)\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "#     scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_feature_vector(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph.x[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(G):\n",
    "    x = torch.randn(G.number_of_nodes(), 1)\n",
    "    ind = 0\n",
    "    for node in G.nodes():\n",
    "        x[ind] = G.degree[node]\n",
    "        ind += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data-2d/data/low_decomp_sahil_dataset.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.8, .2]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 512, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches:  32\n",
      "Number of train batches:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches: \", len(train_loader))\n",
    "print(\"Number of train batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 76834], x=[21017, 1], label=[512], num_nodes=21017, batch=[21017], ptr=[513])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_gcn.gcn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (initial_conv): GCNConv(1, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  12737\n"
     ]
    }
   ],
   "source": [
    "model = GCN(1)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    ind = 0\n",
    "    for batch in data:\n",
    "        optimizer.zero_grad()\n",
    "        pred, embedding = model(batch.x, batch.edge_index, batch.batch)\n",
    "        pred = torch.squeeze(pred)\n",
    "        loss = loss_fn(pred.float(), batch.label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ind += 1\n",
    "\n",
    "    return loss, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            pred, embedding = model(batch.x, batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            y = batch.label\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Train loss 0.4671815037727356\n",
      "Train Accuracy 49.6375 | Test Accuracy 49.75\n",
      "Epoch 1 | Train loss 0.2666562795639038\n",
      "Train Accuracy 87.5625 | Test Accuracy 87.8\n",
      "Epoch 2 | Train loss 0.2470957338809967\n",
      "Train Accuracy 90.20625 | Test Accuracy 90.325\n",
      "Epoch 3 | Train loss 0.222549170255661\n",
      "Train Accuracy 89.49375 | Test Accuracy 89.97500000000001\n",
      "Epoch 4 | Train loss 0.1858639419078827\n",
      "Train Accuracy 90.69375 | Test Accuracy 90.9\n",
      "Epoch 5 | Train loss 0.2059520184993744\n",
      "Train Accuracy 91.19375 | Test Accuracy 91.27499999999999\n",
      "Epoch 6 | Train loss 0.17264482378959656\n",
      "Train Accuracy 91.23125 | Test Accuracy 91.625\n",
      "Epoch 7 | Train loss 0.1342594027519226\n",
      "Train Accuracy 92.0625 | Test Accuracy 92.2\n",
      "Epoch 8 | Train loss 0.3715443015098572\n",
      "Train Accuracy 84.20625000000001 | Test Accuracy 83.75\n",
      "Epoch 9 | Train loss 0.23607076704502106\n",
      "Train Accuracy 91.77499999999999 | Test Accuracy 91.875\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss, h = train(train_loader)\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model, train_loader), check_accuracy(model, test_loader)\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square\n",
    "import networkx as nx\n",
    "square = nx.Graph()\n",
    "square.add_edge(0, 1)\n",
    "square.add_edge(1, 3)\n",
    "square.add_edge(0, 2)\n",
    "square.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle\n",
    "import networkx as nx\n",
    "triangle = nx.Graph()\n",
    "triangle.add_edge(0, 1)\n",
    "triangle.add_edge(0, 2)\n",
    "triangle.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentagon\n",
    "import networkx as nx\n",
    "pentagon = nx.Graph()\n",
    "pentagon.add_edge(0, 1)\n",
    "pentagon.add_edge(1, 3)\n",
    "pentagon.add_edge(3, 4)\n",
    "pentagon.add_edge(4, 2)\n",
    "pentagon.add_edge(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_as_data = from_networkx(square)\n",
    "graph_as_data.x = generate_feature_vector(square)\n",
    "graph_as_data.label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 8], num_nodes=4, x=[4, 1], label=1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_as_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3664]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[-0.0810, -0.0530,  0.0640,  0.0714,  0.3386,  0.0830,  0.2225,  0.0301,\n",
      "          0.2901,  0.1743, -0.1755,  0.5706, -0.3748, -0.0577, -0.1254, -0.1634,\n",
      "         -0.1954,  0.3294,  0.6957, -0.3543,  0.0617, -0.5722,  0.1475, -0.6627,\n",
      "         -0.0863,  0.4758,  0.2110, -0.5136, -0.1718, -0.1396, -0.6790,  0.0805,\n",
      "         -0.1189,  0.3113,  0.2414,  0.4347, -0.1025, -0.3450, -0.1707,  0.3018,\n",
      "         -0.0838,  0.0625, -0.5034, -0.2126, -0.0278,  0.3532,  0.1729,  0.1823,\n",
      "         -0.1498,  0.6166, -0.3159,  0.2840,  0.3516, -0.2224, -0.4679, -0.8201,\n",
      "         -0.2863,  0.0591, -0.1729,  0.1267, -0.3737, -0.1431,  0.2923,  0.2112,\n",
      "         -0.0810, -0.0530,  0.0640,  0.0714,  0.3386,  0.0830,  0.2225,  0.0301,\n",
      "          0.2901,  0.1743, -0.1755,  0.5706, -0.3748, -0.0577, -0.1254, -0.1634,\n",
      "         -0.1954,  0.3294,  0.6957, -0.3543,  0.0617, -0.5722,  0.1475, -0.6627,\n",
      "         -0.0863,  0.4758,  0.2110, -0.5136, -0.1718, -0.1396, -0.6790,  0.0805,\n",
      "         -0.1189,  0.3113,  0.2414,  0.4347, -0.1025, -0.3450, -0.1707,  0.3018,\n",
      "         -0.0838,  0.0625, -0.5034, -0.2126, -0.0278,  0.3532,  0.1729,  0.1823,\n",
      "         -0.1498,  0.6166, -0.3159,  0.2840,  0.3516, -0.2224, -0.4679, -0.8201,\n",
      "         -0.2863,  0.0591, -0.1729,  0.1267, -0.3737, -0.1431,  0.2923,  0.2112]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in validation_set:\n",
    "    pred = model(batch.x, batch.edge_index, batch.batch)\n",
    "    print(pred[0])\n",
    "    print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 25 2022, 14:13:24) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

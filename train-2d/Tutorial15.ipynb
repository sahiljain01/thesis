{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a46b4c",
   "metadata": {
    "id": "69a46b4c"
   },
   "source": [
    "## Tutorial #15: Data Handling in PyG (part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a6bfa0",
   "metadata": {
    "id": "e7a6bfa0"
   },
   "source": [
    "### Custom PyG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5560f4f",
   "metadata": {
    "id": "b5560f4f"
   },
   "source": [
    "In the first part of the notebook we will see how to create a custom dataset in PyG. \n",
    "\n",
    "The dataset we'll load is called FRANKENSTEIN, the files can be downloaded from the \n",
    "[networkrepository](http://networkrepository.com/FRANKENSTEIN.php) site. The dataset was originally presented in the paper titled [Graph Invariant Kernels](https://www.ijcai.org/Proceedings/15/Papers/528.pdf).\n",
    "\n",
    "The dataset is a collection of graphs representing molecules, but the atom symbols of the vertices are substituted with MNIST digits. Each graph is associated with a label, indicating the mutagenicity of the molecule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339e866",
   "metadata": {
    "id": "b339e866"
   },
   "source": [
    "The following is the README of the dataset:\n",
    "\n",
    ">FRANKENSTEIN contains the following comma separated text files:\n",
    ">\n",
    ">n: total number of nodes\n",
    ">m: total number of edges\n",
    ">N: number of graphs\n",
    ">\n",
    ">\n",
    ">*.node_attrs (n lines) \n",
    "\tmatrix of node attributes,\n",
    "\tthe comma seperated values in the i-th line is the attribute vector of the node with node_id i\n",
    ">\n",
    ">*.edges (m lines) \n",
    "\tsparse (block diagonal) adjacency matrix for all graphs,\n",
    "\teach line corresponds to (row, col) resp. (node_id, node_id)\n",
    ">\n",
    ">*.graph_labels (N lines)\n",
    "\tclass labels for all graphs in the dataset,\n",
    "\tthe value in the i-th line is the class label of the graph with graph_id i\n",
    ">\n",
    ">*.graph_idx (n lines)\n",
    "\tcolumn vector of graph identifiers for all nodes of all graphs,\n",
    "\tthe value in the i-th line is the graph_id of the node with node_id i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39106a1",
   "metadata": {
    "id": "d39106a1"
   },
   "source": [
    "The dataset is composed as follows:\n",
    "\n",
    "    Nr. of graphs:         4337\n",
    "    Total nr. of nodes:    73283 x 780 (weird, we'll change it later to 784)\n",
    "    Total nr. of edges:    155068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9ea054",
   "metadata": {
    "id": "7a9ea054"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch_geometric.data import InMemoryDataset, Data, download_url, extract_zip\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92abcf",
   "metadata": {
    "id": "7d92abcf"
   },
   "source": [
    "To create the dataset we need to convert the raw information into a ```Data``` object (a graph) in PyG.\n",
    "\n",
    "The first step is to load the csv files, this can be done manually or using some data library as Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671effcc",
   "metadata": {
    "id": "671effcc"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmp/raw/FRANKENSTEIN.node_attrs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m raw_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp/raw/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(raw_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFRANKENSTEIN.node_attrs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m node_attrs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m node_attrs\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(raw_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFRANKENSTEIN.edges\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/raw/FRANKENSTEIN.node_attrs'"
     ]
    }
   ],
   "source": [
    "raw_dir = \"tmp/raw/\"\n",
    "\n",
    "path = os.path.join(raw_dir, 'FRANKENSTEIN.node_attrs')\n",
    "node_attrs = pd.read_csv(path, sep=',', header=None)\n",
    "node_attrs.index += 1\n",
    "\n",
    "path = os.path.join(raw_dir, 'FRANKENSTEIN.edges')\n",
    "edge_index = pd.read_csv(path, sep=',', names=['source', 'target'])\n",
    "edge_index.index += 1\n",
    "\n",
    "path = os.path.join(raw_dir, 'FRANKENSTEIN.graph_idx')\n",
    "graph_idx = pd.read_csv(path, sep=',', names=['idx'])\n",
    "graph_idx.index += 1\n",
    "\n",
    "path = os.path.join(raw_dir, 'FRANKENSTEIN.graph_labels')\n",
    "graph_labels = pd.read_csv(path, sep=',', names=['label'])\n",
    "graph_labels.index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c78ee6",
   "metadata": {
    "id": "12c78ee6"
   },
   "source": [
    "Graph ids go from 1 to 4337, let's extract the information for a single graph (id: 2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cfff64",
   "metadata": {
    "id": "09cfff64"
   },
   "outputs": [],
   "source": [
    "g_idx=2345\n",
    "\n",
    "node_ids = graph_idx.loc[graph_idx['idx']==g_idx].index\n",
    "            \n",
    "# Node features\n",
    "attributes = node_attrs.loc[node_ids, :]\n",
    "\n",
    "# Edges info\n",
    "edges = edge_index.loc[edge_index['source'].isin(node_ids)]\n",
    "edges_ids = edges.index\n",
    "\n",
    "# Graph label\n",
    "label = graph_labels.loc[g_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7078b",
   "metadata": {
    "id": "f8b7078b"
   },
   "outputs": [],
   "source": [
    "print(\"Nodes:\", node_ids.shape)\n",
    "print(\"Attributes:\", attributes.shape)\n",
    "print(\"Edges:\", edges.shape)\n",
    "print(\"Label:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123c56e",
   "metadata": {
    "id": "4123c56e"
   },
   "outputs": [],
   "source": [
    "print(\"Nodes:\", node_ids)\n",
    "print(\"Attributes:\", attributes)\n",
    "print(\"Edges:\", edges)\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0804e7",
   "metadata": {
    "id": "1d0804e7"
   },
   "source": [
    "At this stage the indices in the ```edges``` variable are not normalized for the single graph, e.g. they do not start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01003f31",
   "metadata": {
    "id": "01003f31"
   },
   "outputs": [],
   "source": [
    "edge_idx = torch.tensor(edges.to_numpy().transpose(), dtype=torch.long)\n",
    "map_dict = {v.item():i for i,v in enumerate(torch.unique(edge_idx))}\n",
    "map_edge = torch.zeros_like(edge_idx)\n",
    "for k,v in map_dict.items():\n",
    "    map_edge[edge_idx==k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa0faf",
   "metadata": {
    "id": "12aa0faf"
   },
   "outputs": [],
   "source": [
    "map_dict, map_edge, map_edge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71d186",
   "metadata": {
    "id": "0d71d186"
   },
   "source": [
    "As final step we convert the ```DataFrames``` to torch tensors. The node features are basically MNIST images, therefore their size should be 784 (28x28), but for some reason the files provide vectors of length 780. To adjust this, we simply add a padding of 4 zeros at the end of the vector (it will not affect the digits representation, as we'll see later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba9bf9",
   "metadata": {
    "id": "62ba9bf9"
   },
   "outputs": [],
   "source": [
    "attrs = torch.tensor(attributes.to_numpy(), dtype=torch.float)\n",
    "pad = torch.zeros((attrs.shape[0], 4), dtype=torch.float)\n",
    "x = torch.cat((attrs, pad), dim=-1)\n",
    "\n",
    "edge_idx = map_edge.long()\n",
    "\n",
    "np_lab = label.to_numpy()\n",
    "y = torch.tensor(np_lab if np_lab[0] == 1 else [0], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8e317",
   "metadata": {
    "id": "9ec8e317"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a27ae1",
   "metadata": {
    "id": "71a27ae1"
   },
   "source": [
    "Then we create the ```Data``` object representing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc06f18",
   "metadata": {
    "id": "2cc06f18"
   },
   "outputs": [],
   "source": [
    "graph = Data(x=x, edge_index=edge_idx,  y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57338892",
   "metadata": {
    "id": "57338892"
   },
   "source": [
    "Let's visualize the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b040996",
   "metadata": {
    "id": "1b040996"
   },
   "outputs": [],
   "source": [
    "vis = to_networkx(graph)\n",
    "plt.figure(1,figsize=(8,8)) \n",
    "nx.draw(vis, cmap=plt.get_cmap('Set3'),node_size=70,linewidths=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6221b4cc",
   "metadata": {
    "id": "6221b4cc"
   },
   "source": [
    "We can also plot the vertices attributes (a.k.a. the digits):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e114906",
   "metadata": {
    "id": "1e114906"
   },
   "outputs": [],
   "source": [
    "digit = x[5].reshape(28,28)\n",
    "plt.matshow(digit, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e184ce0",
   "metadata": {
    "id": "1e184ce0"
   },
   "source": [
    "Let's now put the process above into the ```Dataset``` class of PyG. Specifically, we are going to create an ```InMemoryDataset```. From the official PyG documentation we see that some methods need to be override:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467a5a8",
   "metadata": {
    "id": "a467a5a8"
   },
   "source": [
    "    torch_geometric.data.InMemoryDataset.raw_file_names(): A list of files in the raw_dir which needs to be found in order to skip the download.\n",
    "\n",
    "    torch_geometric.data.InMemoryDataset.processed_file_names(): A list of files in the processed_dir which needs to be found in order to skip the processing.\n",
    "\n",
    "    torch_geometric.data.InMemoryDataset.download(): Downloads raw data into raw_dir.\n",
    "\n",
    "    torch_geometric.data.InMemoryDataset.process(): Processes raw data and saves it into the processed_dir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb29f522",
   "metadata": {
    "id": "eb29f522"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch_geometric.data import InMemoryDataset, Data, download_url, extract_zip\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Frankenstein(InMemoryDataset):\n",
    "    \n",
    "    # Base url to download the files\n",
    "    url = 'http://nrvis.com/download/data/labeled/FRANKENSTEIN.zip'\n",
    "    \n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Frankenstein, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # List of the raw files\n",
    "        return ['FRANKENSTEIN.edges', 'FRANKENSTEIN.graph_idx',\n",
    "                'FRANKENSTEIN.graph_labels', 'FRANKENSTEIN.node_attrs']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        # Download the file specified in self.url and store\n",
    "        # it in self.raw_dir\n",
    "        path = download_url(self.url, self.raw_dir)\n",
    "        extract_zip(path, self.raw_dir)\n",
    "        # The zip file is removed\n",
    "        os.unlink(path)\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "        # Read the files' content as Pandas DataFrame. Nodes and graphs ids\n",
    "        # are based on the file row-index, we adjust the DataFrames indices\n",
    "        # by starting from 1 instead of 0.\n",
    "        \n",
    "        path = os.path.join(self.raw_dir, 'FRANKENSTEIN.node_attrs')\n",
    "        node_attrs = pd.read_csv(path, sep=',', header=None)\n",
    "        node_attrs.index += 1\n",
    "        \n",
    "        path = os.path.join(self.raw_dir, 'FRANKENSTEIN.edges')\n",
    "        edge_index = pd.read_csv(path, sep=',', names=['source', 'target'])\n",
    "        edge_index.index += 1\n",
    "        \n",
    "        path = os.path.join(self.raw_dir, 'FRANKENSTEIN.graph_idx')\n",
    "        graph_idx = pd.read_csv(path, sep=',', names=['idx'])\n",
    "        graph_idx.index += 1\n",
    "        \n",
    "        path = os.path.join(self.raw_dir, 'FRANKENSTEIN.graph_labels')\n",
    "        graph_labels = pd.read_csv(path, sep=',', names=['label'])\n",
    "        graph_labels.index += 1\n",
    "        \n",
    "        \n",
    "        # In the loop we extract the nodes' embeddings, edges connectivity for \n",
    "        # and label for a graph, process the information and put it in a Data\n",
    "        # object, then we add the object to a list\n",
    "        data_list = []\n",
    "        ids_list = graph_idx['idx'].unique()\n",
    "        for g_idx in tqdm(ids_list):\n",
    "            node_ids = graph_idx.loc[graph_idx['idx']==g_idx].index\n",
    "            \n",
    "            # Node features\n",
    "            attributes = node_attrs.loc[node_ids, :]\n",
    "            \n",
    "            # Edges info\n",
    "            edges = edge_index.loc[edge_index['source'].isin(node_ids)]\n",
    "            edges_ids = edges.index\n",
    "            \n",
    "            # Graph label\n",
    "            label = graph_labels.loc[g_idx]\n",
    "            \n",
    "            # Normalize the edges indices\n",
    "            edge_idx = torch.tensor(edges.to_numpy().transpose(), dtype=torch.long)\n",
    "            map_dict = {v.item():i for i,v in enumerate(torch.unique(edge_idx))}\n",
    "            map_edge = torch.zeros_like(edge_idx)\n",
    "            for k,v in map_dict.items():\n",
    "                map_edge[edge_idx==k] = v\n",
    "            \n",
    "            # Convert the DataFrames into tensors \n",
    "            attrs = torch.tensor(attributes.to_numpy(), dtype=torch.float)\n",
    "            pad = torch.zeros((attrs.shape[0], 4), dtype=torch.float)\n",
    "            x = torch.cat((attrs, pad), dim=-1)\n",
    "\n",
    "            edge_idx = map_edge.long()\n",
    "\n",
    "            np_lab = label.to_numpy()\n",
    "            y = torch.tensor(np_lab if np_lab[0] == 1 else [0], dtype=torch.long)\n",
    "            \n",
    "            graph = Data(x=x, edge_index=edge_idx,  y=y)\n",
    "            \n",
    "            data_list.append(graph)\n",
    "            \n",
    "        # Apply the functions specified in pre_filter and pre_transform\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        # Store the processed data\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d079a9",
   "metadata": {
    "id": "07d079a9"
   },
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a1d072",
   "metadata": {
    "id": "98a1d072"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading http://nrvis.com/download/data/labeled/FRANKENSTEIN.zip\n",
      "Extracting data/raw/FRANKENSTEIN.zip\n",
      "Processing...\n",
      "100%|███████████████████████████████████████████████████████████████| 4337/4337 [00:18<00:00, 238.96it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Frankenstein(root='data', pre_transform=T.GCNNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2fd5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "loader = DataLoader(dataset, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f200ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc95e99",
   "metadata": {
    "id": "2fc95e99"
   },
   "source": [
    "### Open Graph Benchmark datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c18fa1",
   "metadata": {
    "id": "99c18fa1"
   },
   "source": [
    "Open Graph Benchmark is available as a python library, to install it just run\n",
    "\n",
    "```pip install ogb```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f5eab0",
   "metadata": {
    "id": "86f5eab0"
   },
   "source": [
    "OGB allows to load a dataset in three ways: for PyG applications, for DGL (Deep Graph Library, another widely used tool for GNNs in python) and in an 'agnostic' manner. There is a naming convention to load a dataset, depending on the task an the dataset name:\n",
    "\n",
    "    ogbn-[name]: for node tasks\n",
    "    ogbg-[name]: for graph tasks\n",
    "    ogbl-[name]: for link tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a3931",
   "metadata": {
    "id": "1c2a3931"
   },
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "#from ogb.graphproppred import PygGraphPropPredDataset\n",
    "#from ogb.linkproppred import PygLinkPropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec243ea",
   "metadata": {
    "id": "1ec243ea"
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ogbn-arxiv'\n",
    "dataset = PygNodePropPredDataset(name = dataset_name, root='data') \n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "graph = dataset[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1d992",
   "metadata": {
    "id": "9bc1d992"
   },
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac064ad9",
   "metadata": {
    "id": "ac064ad9"
   },
   "source": [
    "### Benchmarking Graph Neural Networks Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209977d0",
   "metadata": {
    "id": "209977d0"
   },
   "outputs": [],
   "source": [
    "import torch_geometric.datasets as datasets\n",
    "\n",
    "datasets.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fda25",
   "metadata": {
    "id": "5a8fda25"
   },
   "outputs": [],
   "source": [
    "datasets.GNNBenchmarkDataset.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cf962",
   "metadata": {
    "id": "070cf962"
   },
   "outputs": [],
   "source": [
    "dataset = datasets.GNNBenchmarkDataset(name='MNIST', root='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0137546",
   "metadata": {
    "id": "c0137546"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

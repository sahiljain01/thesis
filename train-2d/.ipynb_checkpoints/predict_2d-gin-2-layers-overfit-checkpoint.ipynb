{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coefficient(G, node):\n",
    "    ns = [n for n in G.neighbors(node)]\n",
    "    if len(ns) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = len(ns) * (len(ns) - 1) / 2\n",
    "    for i in range(0, len(ns)):\n",
    "        for j in range(i+1, len(ns)):\n",
    "            n1, n2 = ns[i], ns[j]\n",
    "            numerator += G.has_edge(n1, n2)\n",
    "    \n",
    "    return numerator / denominator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(G):\n",
    "    x = torch.randn(G.number_of_nodes(), 4)\n",
    "    ind = 0\n",
    "    for node in G.nodes():\n",
    "        x[ind][0] = 1 # uniform\n",
    "        x[ind][1] = G.degree[node] # node degree as a scalar \n",
    "        x[ind][2] = clustering_coefficient(G, node) # triangle counting?\n",
    "        x[ind][3] = ind # node ID features\n",
    "        ind += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        for ind, graph in enumerate(total_laman_data[0]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        for ind, graph in enumerate(total_laman_data[1]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/custom-generated.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 64], x=[15, 4], label=[1], num_nodes=15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laman_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.7, .3]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches:  27\n",
      "Number of test batches:  12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches: \", len(train_loader))\n",
    "print(\"Number of test batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 15082], x=[3840, 4], label=[256], num_nodes=3840, batch=[3840], ptr=[257])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gin.gin_k_layers import GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): GINConv(nn=Sequential(\n",
      "      (0): Linear(in_features=4, out_features=5, bias=True)\n",
      "      (1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (4): ReLU()\n",
      "    ))\n",
      "    (1): GINConv(nn=Sequential(\n",
      "      (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (4): ReLU()\n",
      "    ))\n",
      "  )\n",
      "  (lin1): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (lin2): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  1096\n"
     ]
    }
   ],
   "source": [
    "model = GIN(layers = 2, num_features=4, dim_h=5)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=0.001)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', min_lr=1e-6, verbose=True, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, features_to_use):\n",
    "    ind = 0\n",
    "    for batch in data:\n",
    "        optimizer.zero_grad()\n",
    "        pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "        pred = torch.squeeze(pred)\n",
    "        loss = loss_fn(pred.float(), batch.label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ind += 1\n",
    "\n",
    "    return loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, features_to_use):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            y = batch.label\n",
    "            batch.label = 0\n",
    "            pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Train loss 0.6849928498268127\n",
      "Train Accuracy 55.693950177935946 | Test Accuracy 55.482531995849186\n",
      "Epoch 1 | Train loss 0.6633871793746948\n",
      "Train Accuracy 55.693950177935946 | Test Accuracy 55.482531995849186\n",
      "Epoch 2 | Train loss 0.6894745826721191\n",
      "Train Accuracy 55.63463819691577 | Test Accuracy 55.55171221030785\n",
      "Epoch 3 | Train loss 0.6548170447349548\n",
      "Train Accuracy 57.23606168446026 | Test Accuracy 56.62400553441715\n",
      "Epoch 4 | Train loss 0.6661596894264221\n",
      "Train Accuracy 56.86536180308423 | Test Accuracy 57.6271186440678\n",
      "Epoch 5 | Train loss 0.676677942276001\n",
      "Train Accuracy 57.725385527876625 | Test Accuracy 57.59252853683846\n",
      "Epoch 6 | Train loss 0.6616142392158508\n",
      "Train Accuracy 57.87366548042705 | Test Accuracy 57.6271186440678\n",
      "Epoch 7 | Train loss 0.7219956517219543\n",
      "Train Accuracy 58.377817319098455 | Test Accuracy 58.42269111034244\n",
      "Epoch 8 | Train loss 0.6362115144729614\n",
      "Train Accuracy 59.14887307236062 | Test Accuracy 59.25285368384642\n",
      "Epoch 9 | Train loss 0.6748813986778259\n",
      "Train Accuracy 59.386120996441285 | Test Accuracy 59.28744379107576\n",
      "Epoch 10 | Train loss 0.6685258746147156\n",
      "Train Accuracy 61.95136417556346 | Test Accuracy 61.25907990314769\n",
      "Epoch 11 | Train loss 0.6401136517524719\n",
      "Train Accuracy 65.48042704626334 | Test Accuracy 65.61743341404357\n",
      "Epoch 12 | Train loss 0.5520475506782532\n",
      "Train Accuracy 72.07888493475683 | Test Accuracy 72.18955378761675\n",
      "Epoch 13 | Train loss 0.5011911392211914\n",
      "Train Accuracy 76.17141162514828 | Test Accuracy 76.34036665513662\n",
      "Epoch 14 | Train loss 0.47234079241752625\n",
      "Train Accuracy 79.0332147093713 | Test Accuracy 78.55413351781391\n",
      "Epoch 15 | Train loss 0.40020596981048584\n",
      "Train Accuracy 80.53084223013049 | Test Accuracy 79.48806641300588\n",
      "Epoch 16 | Train loss 0.44572046399116516\n",
      "Train Accuracy 81.88018979833926 | Test Accuracy 80.87167070217917\n",
      "Epoch 17 | Train loss 0.43661510944366455\n",
      "Train Accuracy 82.39916963226572 | Test Accuracy 81.63265306122449\n",
      "Epoch 18 | Train loss 0.4032532870769501\n",
      "Train Accuracy 82.7846975088968 | Test Accuracy 81.80560359737116\n",
      "Epoch 19 | Train loss 0.3161773681640625\n",
      "Train Accuracy 83.18505338078292 | Test Accuracy 82.3936354202698\n",
      "Epoch 20 | Train loss 0.37562692165374756\n",
      "Train Accuracy 83.19988137603796 | Test Accuracy 82.46281563472847\n",
      "Epoch 21 | Train loss 0.32622623443603516\n",
      "Train Accuracy 83.76334519572953 | Test Accuracy 82.84330681425112\n",
      "Epoch 22 | Train loss 0.28256461024284363\n",
      "Train Accuracy 83.926453143535 | Test Accuracy 82.98166724316846\n",
      "Epoch 23 | Train loss 0.3227125108242035\n",
      "Train Accuracy 84.1785290628707 | Test Accuracy 82.87789692148046\n",
      "Epoch 24 | Train loss 0.34390899538993835\n",
      "Train Accuracy 83.98576512455516 | Test Accuracy 82.87789692148046\n",
      "Epoch 25 | Train loss 0.3324829936027527\n",
      "Train Accuracy 84.4306049822064 | Test Accuracy 83.15461777931512\n",
      "Epoch 26 | Train loss 0.25960612297058105\n",
      "Train Accuracy 84.13404507710558 | Test Accuracy 83.39674852992044\n",
      "Epoch 27 | Train loss 0.28144967555999756\n",
      "Train Accuracy 84.47508896797153 | Test Accuracy 83.84641992390176\n",
      "Epoch 28 | Train loss 0.295877069234848\n",
      "Train Accuracy 84.31198102016607 | Test Accuracy 83.36215842269111\n",
      "Epoch 29 | Train loss 0.3163001835346222\n",
      "Train Accuracy 84.54922894424674 | Test Accuracy 83.50051885160845\n",
      "Epoch 30 | Train loss 0.38660457730293274\n",
      "Train Accuracy 85.14234875444839 | Test Accuracy 84.08855067450709\n",
      "Epoch 31 | Train loss 0.33548304438591003\n",
      "Train Accuracy 83.70403321470937 | Test Accuracy 82.94707713593911\n",
      "Epoch 32 | Train loss 0.39094850420951843\n",
      "Train Accuracy 84.38612099644128 | Test Accuracy 83.91560013836042\n",
      "Epoch 33 | Train loss 0.39839038252830505\n",
      "Train Accuracy 85.37959667852907 | Test Accuracy 84.36527153234175\n",
      "Epoch 34 | Train loss 0.38461560010910034\n",
      "Train Accuracy 84.77164887307237 | Test Accuracy 84.53822206848841\n",
      "Epoch 35 | Train loss 0.3405216932296753\n",
      "Train Accuracy 85.48339264531435 | Test Accuracy 84.46904185402974\n",
      "Epoch 36 | Train loss 0.42171356081962585\n",
      "Train Accuracy 85.61684460260973 | Test Accuracy 84.57281217571774\n",
      "Epoch 37 | Train loss 0.2910974621772766\n",
      "Train Accuracy 85.20166073546856 | Test Accuracy 84.08855067450709\n",
      "Epoch 38 | Train loss 0.37639138102531433\n",
      "Train Accuracy 85.00889679715303 | Test Accuracy 84.22691110342441\n",
      "Epoch 39 | Train loss 0.35281240940093994\n",
      "Train Accuracy 85.67615658362989 | Test Accuracy 84.57281217571774\n",
      "Epoch 40 | Train loss 0.3609669506549835\n",
      "Train Accuracy 85.80960854092527 | Test Accuracy 84.4344517468004\n",
      "Epoch 41 | Train loss 0.39647939801216125\n",
      "Train Accuracy 85.70581257413997 | Test Accuracy 84.46904185402974\n",
      "Epoch 42 | Train loss 0.3728874921798706\n",
      "Train Accuracy 85.95788849347569 | Test Accuracy 84.71117260463508\n",
      "Epoch 43 | Train loss 0.3239721953868866\n",
      "Train Accuracy 85.98754448398577 | Test Accuracy 85.4721549636804\n",
      "Epoch 44 | Train loss 0.3378868103027344\n",
      "Train Accuracy 86.07651245551602 | Test Accuracy 85.09166378415773\n",
      "Epoch 45 | Train loss 0.39880484342575073\n",
      "Train Accuracy 86.19513641755636 | Test Accuracy 85.12625389138707\n",
      "Epoch 46 | Train loss 0.3263256251811981\n",
      "Train Accuracy 86.1061684460261 | Test Accuracy 85.0570736769284\n",
      "Epoch 47 | Train loss 0.27489587664604187\n",
      "Train Accuracy 86.32858837485172 | Test Accuracy 85.61051539259772\n",
      "Epoch 48 | Train loss 0.30565783381462097\n",
      "Train Accuracy 86.06168446026096 | Test Accuracy 85.50674507090972\n",
      "Epoch 49 | Train loss 0.35734397172927856\n",
      "Train Accuracy 85.80960854092527 | Test Accuracy 84.36527153234175\n",
      "Epoch 50 | Train loss 0.21545912325382233\n",
      "Train Accuracy 86.43238434163702 | Test Accuracy 85.57592528536838\n",
      "Epoch 51 | Train loss 0.34517520666122437\n",
      "Train Accuracy 86.38790035587188 | Test Accuracy 85.54133517813905\n",
      "Epoch 52 | Train loss 0.2850815951824188\n",
      "Train Accuracy 86.52135231316726 | Test Accuracy 85.81805603597371\n",
      "Epoch 53 | Train loss 0.3991617262363434\n",
      "Train Accuracy 86.4620403321471 | Test Accuracy 85.85264614320305\n",
      "Epoch 54 | Train loss 0.2568340599536896\n",
      "Train Accuracy 85.89857651245552 | Test Accuracy 84.8495330335524\n",
      "Epoch 55 | Train loss 0.3879012167453766\n",
      "Train Accuracy 86.87722419928826 | Test Accuracy 85.57592528536838\n",
      "Epoch 56 | Train loss 0.3229958713054657\n",
      "Train Accuracy 86.56583629893238 | Test Accuracy 85.85264614320305\n",
      "Epoch 57 | Train loss 0.3019838035106659\n",
      "Train Accuracy 86.31376037959669 | Test Accuracy 85.29920442753372\n",
      "Epoch 58 | Train loss 0.4052610397338867\n",
      "Train Accuracy 86.81791221826809 | Test Accuracy 85.4721549636804\n",
      "Epoch 59 | Train loss 0.3194887638092041\n",
      "Train Accuracy 86.65480427046263 | Test Accuracy 85.74887582151504\n",
      "Epoch 60 | Train loss 0.20244917273521423\n",
      "Train Accuracy 86.72894424673784 | Test Accuracy 85.85264614320305\n",
      "Epoch 61 | Train loss 0.3167661726474762\n",
      "Train Accuracy 87.06998813760379 | Test Accuracy 86.1293670010377\n",
      "Epoch 62 | Train loss 0.20128512382507324\n",
      "Train Accuracy 86.92170818505338 | Test Accuracy 86.23313732272571\n",
      "Epoch 63 | Train loss 0.27327463030815125\n",
      "Train Accuracy 87.06998813760379 | Test Accuracy 86.26772742995503\n",
      "Epoch 64 | Train loss 0.2650033235549927\n",
      "Train Accuracy 87.21826809015421 | Test Accuracy 86.37149775164303\n",
      "Epoch 65 | Train loss 0.26866957545280457\n",
      "Train Accuracy 87.01067615658363 | Test Accuracy 85.95641646489103\n",
      "Epoch 66 | Train loss 0.31770628690719604\n",
      "Train Accuracy 86.98102016607353 | Test Accuracy 86.3369076444137\n",
      "Epoch 67 | Train loss 0.22878007590770721\n",
      "Train Accuracy 87.44068801897983 | Test Accuracy 86.6482186094777\n",
      "Epoch 68 | Train loss 0.2872190475463867\n",
      "Train Accuracy 86.09134045077106 | Test Accuracy 85.12625389138707\n",
      "Epoch 69 | Train loss 0.27810800075531006\n",
      "Train Accuracy 87.5 | Test Accuracy 86.71739882393635\n",
      "Epoch 70 | Train loss 0.30871036648750305\n",
      "Train Accuracy 87.144128113879 | Test Accuracy 85.85264614320305\n",
      "Epoch 71 | Train loss 0.21155604720115662\n",
      "Train Accuracy 87.6779359430605 | Test Accuracy 86.50985818056036\n",
      "Epoch 72 | Train loss 0.3830888867378235\n",
      "Train Accuracy 87.4258600237248 | Test Accuracy 86.50985818056036\n",
      "Epoch 73 | Train loss 0.27385562658309937\n",
      "Train Accuracy 87.44068801897983 | Test Accuracy 86.61362850224835\n",
      "Epoch 74 | Train loss 0.21176601946353912\n",
      "Train Accuracy 87.69276393831554 | Test Accuracy 87.23625043237634\n",
      "Epoch 75 | Train loss 0.395679771900177\n",
      "Train Accuracy 87.5 | Test Accuracy 87.06329989622968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train loss 0.2874738574028015\n",
      "Train Accuracy 87.5741399762752 | Test Accuracy 86.40608785887235\n",
      "Epoch 77 | Train loss 0.31146079301834106\n",
      "Train Accuracy 87.76690391459074 | Test Accuracy 87.23625043237634\n",
      "Epoch 78 | Train loss 0.30428311228752136\n",
      "Train Accuracy 87.79655990510084 | Test Accuracy 87.44379107575233\n",
      "Epoch 79 | Train loss 0.22341381013393402\n",
      "Train Accuracy 87.97449584816133 | Test Accuracy 86.99411968177101\n",
      "Epoch 80 | Train loss 0.30001357197761536\n",
      "Train Accuracy 87.95966785290629 | Test Accuracy 87.37461086129366\n",
      "Epoch 81 | Train loss 0.3173699378967285\n",
      "Train Accuracy 87.90035587188612 | Test Accuracy 87.40920096852301\n",
      "Epoch 82 | Train loss 0.2565793991088867\n",
      "Train Accuracy 88.1376037959668 | Test Accuracy 87.23625043237634\n",
      "Epoch 83 | Train loss 0.24362696707248688\n",
      "Train Accuracy 88.22657176749703 | Test Accuracy 87.47838118298166\n",
      "Epoch 84 | Train loss 0.2315070778131485\n",
      "Train Accuracy 88.5379596678529 | Test Accuracy 87.96264268419232\n",
      "Epoch 85 | Train loss 0.28670480847358704\n",
      "Train Accuracy 88.38967971530249 | Test Accuracy 87.65133171912834\n",
      "Epoch 86 | Train loss 0.22070366144180298\n",
      "Train Accuracy 88.07829181494662 | Test Accuracy 86.99411968177101\n",
      "Epoch 87 | Train loss 0.444886714220047\n",
      "Train Accuracy 88.43416370106762 | Test Accuracy 88.03182289865099\n",
      "Epoch 88 | Train loss 0.13575290143489838\n",
      "Train Accuracy 88.87900355871886 | Test Accuracy 88.20477343479764\n",
      "Epoch 89 | Train loss 0.25937649607658386\n",
      "Train Accuracy 88.41933570581257 | Test Accuracy 87.96264268419232\n",
      "Epoch 90 | Train loss 0.20533710718154907\n",
      "Train Accuracy 89.1755634638197 | Test Accuracy 88.86198547215496\n",
      "Epoch 91 | Train loss 0.31802311539649963\n",
      "Train Accuracy 89.10142348754448 | Test Accuracy 89.0003459010723\n",
      "Epoch 92 | Train loss 0.3755708634853363\n",
      "Train Accuracy 89.32384341637011 | Test Accuracy 88.72362504323763\n",
      "Epoch 93 | Train loss 0.28667882084846497\n",
      "Train Accuracy 89.24970344009489 | Test Accuracy 89.0003459010723\n",
      "Epoch 94 | Train loss 0.22894386947155\n",
      "Train Accuracy 89.47212336892052 | Test Accuracy 88.86198547215496\n",
      "Epoch 95 | Train loss 0.2656302750110626\n",
      "Train Accuracy 89.22004744958481 | Test Accuracy 89.17329643721895\n",
      "Epoch 96 | Train loss 0.35414615273475647\n",
      "Train Accuracy 89.4276393831554 | Test Accuracy 88.86198547215496\n",
      "Epoch 97 | Train loss 0.3258523941040039\n",
      "Train Accuracy 88.5379596678529 | Test Accuracy 88.75821515046697\n",
      "Epoch 98 | Train loss 0.2424541413784027\n",
      "Train Accuracy 89.36832740213522 | Test Accuracy 89.0003459010723\n",
      "Epoch 99 | Train loss 0.14219367504119873\n",
      "Train Accuracy 90.24317912218268 | Test Accuracy 89.72673815288827\n",
      "Epoch 100 | Train loss 0.2763103246688843\n",
      "Train Accuracy 90.1097271648873 | Test Accuracy 89.72673815288827\n",
      "Epoch 101 | Train loss 0.3345133662223816\n",
      "Train Accuracy 90.34697508896798 | Test Accuracy 90.00345901072293\n",
      "Epoch 102 | Train loss 0.21055841445922852\n",
      "Train Accuracy 90.30249110320284 | Test Accuracy 89.69214804565894\n",
      "Epoch 103 | Train loss 0.2130204141139984\n",
      "Train Accuracy 89.81316725978647 | Test Accuracy 89.72673815288827\n",
      "Epoch 104 | Train loss 0.2390052229166031\n",
      "Train Accuracy 90.40628706998814 | Test Accuracy 90.31476997578693\n",
      "Epoch 105 | Train loss 0.32012316584587097\n",
      "Train Accuracy 90.27283511269276 | Test Accuracy 89.58837772397095\n",
      "Epoch 106 | Train loss 0.29704028367996216\n",
      "Train Accuracy 90.58422301304864 | Test Accuracy 90.34936008301626\n",
      "Epoch 107 | Train loss 0.2450922131538391\n",
      "Train Accuracy 89.59074733096085 | Test Accuracy 89.17329643721895\n",
      "Epoch 108 | Train loss 0.1434425264596939\n",
      "Train Accuracy 90.49525504151839 | Test Accuracy 90.41854029747492\n",
      "Epoch 109 | Train loss 0.26874738931655884\n",
      "Train Accuracy 90.717674970344 | Test Accuracy 90.24558976132826\n",
      "Epoch 110 | Train loss 0.2223616987466812\n",
      "Train Accuracy 90.68801897983393 | Test Accuracy 89.89968868903495\n",
      "Epoch 111 | Train loss 0.27522507309913635\n",
      "Train Accuracy 90.73250296559905 | Test Accuracy 90.52231061916291\n",
      "Epoch 112 | Train loss 0.13205689191818237\n",
      "Train Accuracy 90.95492289442467 | Test Accuracy 90.59149083362158\n",
      "Epoch 113 | Train loss 0.14430660009384155\n",
      "Train Accuracy 90.5693950177936 | Test Accuracy 90.21099965409893\n",
      "Epoch 114 | Train loss 0.22517342865467072\n",
      "Train Accuracy 90.55456702253856 | Test Accuracy 89.51919750951228\n",
      "Epoch 115 | Train loss 0.13490094244480133\n",
      "Train Accuracy 90.25800711743773 | Test Accuracy 89.51919750951228\n",
      "Epoch 116 | Train loss 0.16397947072982788\n",
      "Train Accuracy 90.62870699881375 | Test Accuracy 89.9688689034936\n",
      "Epoch 117 | Train loss 0.23630648851394653\n",
      "Train Accuracy 90.55456702253856 | Test Accuracy 90.72985126253892\n",
      "Epoch 118 | Train loss 0.17636539041996002\n",
      "Train Accuracy 90.76215895610913 | Test Accuracy 90.38395019024559\n",
      "Epoch 119 | Train loss 0.18335680663585663\n",
      "Train Accuracy 90.91043890865956 | Test Accuracy 90.34936008301626\n",
      "Epoch 120 | Train loss 0.2267926186323166\n",
      "Train Accuracy 91.14768683274022 | Test Accuracy 90.34936008301626\n",
      "Epoch 121 | Train loss 0.21640676259994507\n",
      "Train Accuracy 90.89561091340451 | Test Accuracy 90.38395019024559\n",
      "Epoch 122 | Train loss 0.2186960130929947\n",
      "Train Accuracy 90.45077105575326 | Test Accuracy 89.93427879626427\n",
      "Epoch 123 | Train loss 0.18232010304927826\n",
      "Train Accuracy 91.19217081850533 | Test Accuracy 90.48772051193359\n",
      "Epoch 124 | Train loss 0.21897143125534058\n",
      "Train Accuracy 90.36180308422301 | Test Accuracy 89.27706675890695\n",
      "Epoch 125 | Train loss 0.2932586967945099\n",
      "Train Accuracy 91.29596678529063 | Test Accuracy 90.76444136976825\n",
      "Epoch 126 | Train loss 0.15903246402740479\n",
      "Train Accuracy 91.16251482799525 | Test Accuracy 90.72985126253892\n",
      "Epoch 127 | Train loss 0.25572827458381653\n",
      "Train Accuracy 90.98457888493475 | Test Accuracy 90.76444136976825\n",
      "Epoch 128 | Train loss 0.19122084975242615\n",
      "Train Accuracy 91.28113879003558 | Test Accuracy 90.66067104808025\n",
      "Epoch 129 | Train loss 0.1851729303598404\n",
      "Train Accuracy 90.83629893238434 | Test Accuracy 90.31476997578693\n",
      "Epoch 130 | Train loss 0.1281876415014267\n",
      "Train Accuracy 90.88078291814946 | Test Accuracy 90.2801798685576\n",
      "Epoch 131 | Train loss 0.24713096022605896\n",
      "Train Accuracy 91.34045077105574 | Test Accuracy 90.93739190591491\n",
      "Epoch 132 | Train loss 0.14484061300754547\n",
      "Train Accuracy 91.2514827995255 | Test Accuracy 90.86821169145625\n",
      "Epoch 133 | Train loss 0.24372531473636627\n",
      "Train Accuracy 91.2514827995255 | Test Accuracy 90.66067104808025\n",
      "Epoch 134 | Train loss 0.3127773106098175\n",
      "Train Accuracy 91.02906287069989 | Test Accuracy 90.66067104808025\n",
      "Epoch 135 | Train loss 0.20034241676330566\n",
      "Train Accuracy 90.73250296559905 | Test Accuracy 90.07263922518159\n",
      "Epoch 136 | Train loss 0.2152673751115799\n",
      "Train Accuracy 90.96975088967972 | Test Accuracy 90.10722933241094\n",
      "Epoch 137 | Train loss 0.20616202056407928\n",
      "Train Accuracy 91.02906287069989 | Test Accuracy 90.69526115530958\n",
      "Epoch 138 | Train loss 0.2456119954586029\n",
      "Train Accuracy 90.6435349940688 | Test Accuracy 89.93427879626427\n",
      "Epoch 139 | Train loss 0.23736706376075745\n",
      "Train Accuracy 91.3552787663108 | Test Accuracy 90.52231061916291\n",
      "Epoch 140 | Train loss 0.17867180705070496\n",
      "Train Accuracy 90.77698695136418 | Test Accuracy 90.17640954686959\n",
      "Epoch 141 | Train loss 0.1617899090051651\n",
      "Train Accuracy 91.66666666666666 | Test Accuracy 90.31476997578693\n",
      "Epoch 142 | Train loss 0.34415656328201294\n",
      "Train Accuracy 91.48873072360617 | Test Accuracy 90.8336215842269\n",
      "Epoch 143 | Train loss 0.2049865573644638\n",
      "Train Accuracy 91.39976275207592 | Test Accuracy 90.69526115530958\n",
      "Epoch 144 | Train loss 0.18780498206615448\n",
      "Train Accuracy 91.11803084223014 | Test Accuracy 90.48772051193359\n",
      "Epoch 145 | Train loss 0.20361541211605072\n",
      "Train Accuracy 91.44424673784104 | Test Accuracy 90.76444136976825\n",
      "Epoch 146 | Train loss 0.20427441596984863\n",
      "Train Accuracy 91.72597864768683 | Test Accuracy 90.76444136976825\n",
      "Epoch 147 | Train loss 0.23570193350315094\n",
      "Train Accuracy 91.38493475682088 | Test Accuracy 90.62608094085091\n",
      "Epoch 148 | Train loss 0.22349166870117188\n",
      "Train Accuracy 91.54804270462633 | Test Accuracy 90.93739190591491\n",
      "Epoch 149 | Train loss 0.2393394410610199\n",
      "Train Accuracy 91.45907473309609 | Test Accuracy 90.69526115530958\n",
      "Epoch 150 | Train loss 0.22980274260044098\n",
      "Train Accuracy 91.56287069988137 | Test Accuracy 91.0411622276029\n",
      "Epoch 151 | Train loss 0.22678838670253754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 91.51838671411625 | Test Accuracy 90.66067104808025\n",
      "Epoch 152 | Train loss 0.20587629079818726\n",
      "Train Accuracy 91.65183867141162 | Test Accuracy 90.52231061916291\n",
      "Epoch 153 | Train loss 0.28129324316978455\n",
      "Train Accuracy 91.57769869513642 | Test Accuracy 90.38395019024559\n",
      "Epoch 154 | Train loss 0.22043509781360626\n",
      "Train Accuracy 91.31079478054566 | Test Accuracy 90.2801798685576\n",
      "Epoch 155 | Train loss 0.1489722579717636\n",
      "Train Accuracy 91.1773428232503 | Test Accuracy 90.38395019024559\n",
      "Epoch 156 | Train loss 0.1918436884880066\n",
      "Train Accuracy 91.50355871886121 | Test Accuracy 90.48772051193359\n",
      "Epoch 157 | Train loss 0.1510874629020691\n",
      "Train Accuracy 91.34045077105574 | Test Accuracy 90.41854029747492\n",
      "Epoch 158 | Train loss 0.24050162732601166\n",
      "Train Accuracy 91.59252669039147 | Test Accuracy 90.62608094085091\n",
      "Epoch 159 | Train loss 0.14495502412319183\n",
      "Train Accuracy 91.32562277580071 | Test Accuracy 90.72985126253892\n",
      "Epoch 160 | Train loss 0.15313830971717834\n",
      "Train Accuracy 91.59252669039147 | Test Accuracy 90.72985126253892\n",
      "Epoch 161 | Train loss 0.18593277037143707\n",
      "Train Accuracy 91.50355871886121 | Test Accuracy 90.45313040470425\n",
      "Epoch 162 | Train loss 0.3139519691467285\n",
      "Train Accuracy 91.41459074733096 | Test Accuracy 90.45313040470425\n",
      "Epoch 163 | Train loss 0.1480719894170761\n",
      "Train Accuracy 91.41459074733096 | Test Accuracy 90.48772051193359\n",
      "Epoch 164 | Train loss 0.15675760805606842\n",
      "Train Accuracy 91.56287069988137 | Test Accuracy 90.45313040470425\n",
      "Epoch 165 | Train loss 0.25649863481521606\n",
      "Train Accuracy 91.56287069988137 | Test Accuracy 90.55690072639226\n",
      "Epoch 166 | Train loss 0.15602082014083862\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 90.8336215842269\n",
      "Epoch 167 | Train loss 0.21375399827957153\n",
      "Train Accuracy 91.66666666666666 | Test Accuracy 90.48772051193359\n",
      "Epoch 168 | Train loss 0.13172435760498047\n",
      "Train Accuracy 91.59252669039147 | Test Accuracy 90.66067104808025\n",
      "Epoch 169 | Train loss 0.1704566329717636\n",
      "Train Accuracy 91.65183867141162 | Test Accuracy 90.93739190591491\n",
      "Epoch 170 | Train loss 0.19208864867687225\n",
      "Train Accuracy 91.47390272835113 | Test Accuracy 90.72985126253892\n",
      "Epoch 171 | Train loss 0.2177615612745285\n",
      "Train Accuracy 91.69632265717675 | Test Accuracy 90.59149083362158\n",
      "Epoch 172 | Train loss 0.23892074823379517\n",
      "Train Accuracy 91.50355871886121 | Test Accuracy 90.62608094085091\n",
      "Epoch 173 | Train loss 0.1550755351781845\n",
      "Train Accuracy 91.57769869513642 | Test Accuracy 90.52231061916291\n",
      "Epoch 174 | Train loss 0.17531052231788635\n",
      "Train Accuracy 90.83629893238434 | Test Accuracy 90.34936008301626\n",
      "Epoch 175 | Train loss 0.24282997846603394\n",
      "Train Accuracy 91.69632265717675 | Test Accuracy 90.79903147699758\n",
      "Epoch 176 | Train loss 0.1492539495229721\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 90.41854029747492\n",
      "Epoch 177 | Train loss 0.16560877859592438\n",
      "Train Accuracy 91.26631079478055 | Test Accuracy 90.59149083362158\n",
      "Epoch 178 | Train loss 0.22398562729358673\n",
      "Train Accuracy 90.89561091340451 | Test Accuracy 90.48772051193359\n",
      "Epoch 179 | Train loss 0.19130147993564606\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 90.79903147699758\n",
      "Epoch 180 | Train loss 0.2367236465215683\n",
      "Train Accuracy 90.49525504151839 | Test Accuracy 89.72673815288827\n",
      "Epoch 181 | Train loss 0.22479277849197388\n",
      "Train Accuracy 91.87425860023724 | Test Accuracy 90.41854029747492\n",
      "Epoch 182 | Train loss 0.279281347990036\n",
      "Train Accuracy 91.82977461447213 | Test Accuracy 90.55690072639226\n",
      "Epoch 183 | Train loss 0.2790314853191376\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 90.38395019024559\n",
      "Epoch 184 | Train loss 0.1852404922246933\n",
      "Train Accuracy 91.05871886120997 | Test Accuracy 89.89968868903495\n",
      "Epoch 185 | Train loss 0.25139322876930237\n",
      "Train Accuracy 91.91874258600238 | Test Accuracy 90.62608094085091\n",
      "Epoch 186 | Train loss 0.21798205375671387\n",
      "Train Accuracy 91.34045077105574 | Test Accuracy 90.34936008301626\n",
      "Epoch 187 | Train loss 0.16325044631958008\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 91.07575233483225\n",
      "Epoch 188 | Train loss 0.36100059747695923\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.55690072639226\n",
      "Epoch 189 | Train loss 0.12402966618537903\n",
      "Train Accuracy 91.5332147093713 | Test Accuracy 90.21099965409893\n",
      "Epoch 190 | Train loss 0.21252727508544922\n",
      "Train Accuracy 91.19217081850533 | Test Accuracy 90.48772051193359\n",
      "Epoch 191 | Train loss 0.26681268215179443\n",
      "Train Accuracy 91.073546856465 | Test Accuracy 90.24558976132826\n",
      "Epoch 192 | Train loss 0.19237588346004486\n",
      "Train Accuracy 91.75563463819691 | Test Accuracy 90.55690072639226\n",
      "Epoch 193 | Train loss 0.1683024764060974\n",
      "Train Accuracy 91.47390272835113 | Test Accuracy 90.34936008301626\n",
      "Epoch 194 | Train loss 0.19588802754878998\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 90.93739190591491\n",
      "Epoch 195 | Train loss 0.24650068581104279\n",
      "Train Accuracy 91.82977461447213 | Test Accuracy 90.62608094085091\n",
      "Epoch 196 | Train loss 0.13697832822799683\n",
      "Train Accuracy 91.63701067615658 | Test Accuracy 90.69526115530958\n",
      "Epoch 197 | Train loss 0.1631729006767273\n",
      "Train Accuracy 91.74080664294188 | Test Accuracy 90.86821169145625\n",
      "Epoch 198 | Train loss 0.22510476410388947\n",
      "Train Accuracy 91.77046263345196 | Test Accuracy 90.38395019024559\n",
      "Epoch 199 | Train loss 0.20623038709163666\n",
      "Train Accuracy 91.87425860023724 | Test Accuracy 90.59149083362158\n",
      "Epoch 200 | Train loss 0.21044497191905975\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 90.41854029747492\n",
      "Epoch 201 | Train loss 0.25121772289276123\n",
      "Train Accuracy 90.5693950177936 | Test Accuracy 90.21099965409893\n",
      "Epoch 202 | Train loss 0.24259771406650543\n",
      "Train Accuracy 91.6814946619217 | Test Accuracy 90.2801798685576\n",
      "Epoch 203 | Train loss 0.22021354734897614\n",
      "Train Accuracy 91.39976275207592 | Test Accuracy 90.76444136976825\n",
      "Epoch 204 | Train loss 0.18991822004318237\n",
      "Train Accuracy 91.3552787663108 | Test Accuracy 90.2801798685576\n",
      "Epoch 205 | Train loss 0.2868758738040924\n",
      "Train Accuracy 91.75563463819691 | Test Accuracy 90.69526115530958\n",
      "Epoch 206 | Train loss 0.16554656624794006\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 90.69526115530958\n",
      "Epoch 207 | Train loss 0.22381223738193512\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.66067104808025\n",
      "Epoch 208 | Train loss 0.14610791206359863\n",
      "Train Accuracy 91.88908659549229 | Test Accuracy 90.79903147699758\n",
      "Epoch 209 | Train loss 0.0925331637263298\n",
      "Train Accuracy 91.82977461447213 | Test Accuracy 91.00657212037358\n",
      "Epoch 210 | Train loss 0.1447264701128006\n",
      "Train Accuracy 91.84460260972716 | Test Accuracy 90.41854029747492\n",
      "Epoch 211 | Train loss 0.15878871083259583\n",
      "Train Accuracy 91.51838671411625 | Test Accuracy 90.24558976132826\n",
      "Epoch 212 | Train loss 0.24120455980300903\n",
      "Train Accuracy 91.23665480427047 | Test Accuracy 90.8336215842269\n",
      "Epoch 213 | Train loss 0.18776574730873108\n",
      "Train Accuracy 91.6073546856465 | Test Accuracy 90.34936008301626\n",
      "Epoch 214 | Train loss 0.18422077596187592\n",
      "Train Accuracy 91.32562277580071 | Test Accuracy 89.93427879626427\n",
      "Epoch 215 | Train loss 0.2161739468574524\n",
      "Train Accuracy 91.48873072360617 | Test Accuracy 90.97198201314424\n",
      "Epoch 216 | Train loss 0.25735902786254883\n",
      "Train Accuracy 91.91874258600238 | Test Accuracy 90.45313040470425\n",
      "Epoch 217 | Train loss 0.23443573713302612\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 90.52231061916291\n",
      "Epoch 218 | Train loss 0.23392972350120544\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.72985126253892\n",
      "Epoch 219 | Train loss 0.16151593625545502\n",
      "Train Accuracy 92.00771055753262 | Test Accuracy 90.86821169145625\n",
      "Epoch 220 | Train loss 0.17044484615325928\n",
      "Train Accuracy 91.65183867141162 | Test Accuracy 90.90280179868557\n",
      "Epoch 221 | Train loss 0.17234764993190765\n",
      "Train Accuracy 91.94839857651246 | Test Accuracy 90.59149083362158\n",
      "Epoch 222 | Train loss 0.13599775731563568\n",
      "Train Accuracy 91.37010676156584 | Test Accuracy 90.10722933241094\n",
      "Epoch 223 | Train loss 0.26460030674934387\n",
      "Train Accuracy 91.51838671411625 | Test Accuracy 90.90280179868557\n",
      "Epoch 224 | Train loss 0.15656305849552155\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.66067104808025\n",
      "Epoch 225 | Train loss 0.21434515714645386\n",
      "Train Accuracy 91.74080664294188 | Test Accuracy 90.48772051193359\n",
      "Epoch 226 | Train loss 0.1543191820383072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.55690072639226\n",
      "Epoch 227 | Train loss 0.16418956220149994\n",
      "Train Accuracy 91.63701067615658 | Test Accuracy 90.93739190591491\n",
      "Epoch 228 | Train loss 0.22120310366153717\n",
      "Train Accuracy 92.12633451957295 | Test Accuracy 90.97198201314424\n",
      "Epoch 229 | Train loss 0.20863653719425201\n",
      "Train Accuracy 91.77046263345196 | Test Accuracy 90.52231061916291\n",
      "Epoch 230 | Train loss 0.16627417504787445\n",
      "Train Accuracy 91.94839857651246 | Test Accuracy 90.76444136976825\n",
      "Epoch 231 | Train loss 0.19830092787742615\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 90.55690072639226\n",
      "Epoch 232 | Train loss 0.1661868691444397\n",
      "Train Accuracy 91.45907473309609 | Test Accuracy 90.97198201314424\n",
      "Epoch 233 | Train loss 0.1576758474111557\n",
      "Train Accuracy 91.85943060498221 | Test Accuracy 90.55690072639226\n",
      "Epoch 234 | Train loss 0.16058875620365143\n",
      "Train Accuracy 91.63701067615658 | Test Accuracy 90.79903147699758\n",
      "Epoch 235 | Train loss 0.17483459413051605\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 90.59149083362158\n",
      "Epoch 236 | Train loss 0.29156187176704407\n",
      "Train Accuracy 91.81494661921708 | Test Accuracy 90.41854029747492\n",
      "Epoch 237 | Train loss 0.1664305031299591\n",
      "Train Accuracy 92.06702253855279 | Test Accuracy 90.66067104808025\n",
      "Epoch 238 | Train loss 0.2027990221977234\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 90.52231061916291\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(600):\n",
    "    loss, model = train(model, train_loader, [0, 1, 2, 3])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model, train_loader, [0, 1, 2, 3]), check_accuracy(model, test_loader, [0, 1, 2, 3])\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a twenty node graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fully connected 11-node graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an 20-node graph\n",
    "n = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 30):\n",
    "    j = (np.random.randint(0, 30))\n",
    "    while j == i:\n",
    "        j = (np.random.randint(0, 30))\n",
    "        \n",
    "    print(j == i)\n",
    "    g.add_edge(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_edges = set()\n",
    "for i in range(0, 30):\n",
    "    for j in range(i+1, 30):\n",
    "        if not g.has_edge(i, j):\n",
    "            all_possible_edges.add((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_possible_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "non_edges_sample_order = random.sample(all_possible_edges, 57 - 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (u,v) in non_edges_sample_order:\n",
    "    g.add_edge(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    graph_as_data = from_networkx(g)\n",
    "    graph_as_data.x = generate_feature_vector(g)\n",
    "    validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "    for batch in validation_set:\n",
    "        pred = model(batch.x[:, [0]], batch.edge_index, batch.batch)\n",
    "        print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(model, test_loader, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(model, train_loader, [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square\n",
    "import networkx as nx\n",
    "square = nx.Graph()\n",
    "square.add_edge(0, 1)\n",
    "square.add_edge(1, 3)\n",
    "square.add_edge(0, 2)\n",
    "square.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square with cross bar (rigid)\n",
    "import networkx as nx\n",
    "square_bar = nx.Graph()\n",
    "square_bar.add_edge(0, 1)\n",
    "square_bar.add_edge(1, 3)\n",
    "square_bar.add_edge(0, 2)\n",
    "square_bar.add_edge(2, 3)\n",
    "square_bar.add_edge(0, 3)\n",
    "square_bar.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle\n",
    "import networkx as nx\n",
    "triangle = nx.Graph()\n",
    "triangle.add_edge(0, 1)\n",
    "triangle.add_edge(0, 2)\n",
    "triangle.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentagon\n",
    "import networkx as nx\n",
    "pentagon = nx.Graph()\n",
    "pentagon.add_edge(0, 1)\n",
    "pentagon.add_edge(1, 3)\n",
    "pentagon.add_edge(3, 4)\n",
    "pentagon.add_edge(4, 2)\n",
    "pentagon.add_edge(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_problems = [square, square_bar, triangle, pentagon]\n",
    "labels = [1, 0, 0, 1]\n",
    "\n",
    "for index, toy_problem in enumerate(toy_problems):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        graph_as_data = from_networkx(toy_problem)\n",
    "        graph_as_data.x = generate_feature_vector(toy_problem)\n",
    "#         graph_as_data.label = labels[index]\n",
    "        validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "        for batch in validation_set:\n",
    "            pred = model(batch.x[:, [0, 1, 2, 3]], batch.edge_index, batch.batch)\n",
    "            print(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_as_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in validation_set:\n",
    "    pred = bestModel(batch.x, batch.edge_index, batch.batch)\n",
    "    print(pred[0])\n",
    "    print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanTestDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_test.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add functionality to support a test dataset\n",
    "TEST_DATA_PATH = \"../data-2d/data/test-dataset-30loc-5std.pkl.gz\"\n",
    "laman_test_set = LamanTestDataset(\"\", TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "laman_test_loader = DataLoader(laman_test_set, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_acc = check_accuracy(bestModel, laman_test_loader)\n",
    "print(f\"Accuracy {random_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the clustering coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(triangle, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square_bar, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate graph correlating clustering coefficient to rigidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_data:\n",
    "    item = to_networkx(item)\n",
    "    print(type(item))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric.utils.convert.to_networkx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work: Sahil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_laman_data = None\n",
    "with gzip.open(DATA_PATH, 'r') as f:\n",
    "    total_laman_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph = total_laman_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_data = from_networkx(sample_graph)\n",
    "from_data = to_networkx(to_data, to_undirected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_clustering_coefficient(G):\n",
    "    min_coefficient = 1\n",
    "    for node in G.nodes():\n",
    "        min_coefficient = min(min_coefficient, clustering_coefficient(G, node))\n",
    "        \n",
    "    return min_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sample_graph in enumerate(train_data):\n",
    "    label = sample_graph.label\n",
    "    networkx_sample_graph = to_networkx(sample_graph, to_undirected = True)\n",
    "    print(label, \" \", index, \" \", compute_min_clustering_coefficient(networkx_sample_graph))\n",
    "    \n",
    "    if index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_min_clustering_coefficient(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_min_clustering_coefficient(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if instead of training a gnn  you just trained on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the degrees of the nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the triangle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on the triangle features and the degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a network with just degree of the node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_just_degree = GIN(num_features=1)\n",
    "print(model_just_degree)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, h = train(train_loader, [0])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model_just_degree, train_loader), check_accuracy(model_just_degree, test_loader)\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "#     scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_feature_vector(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph.x[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

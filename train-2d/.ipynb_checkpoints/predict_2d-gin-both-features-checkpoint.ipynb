{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coefficient(G, node):\n",
    "    ns = [n for n in G.neighbors(node)]\n",
    "    if len(ns) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = len(ns) * (len(ns) - 1) / 2\n",
    "    for i in range(0, len(ns)):\n",
    "        for j in range(i+1, len(ns)):\n",
    "            n1, n2 = ns[i], ns[j]\n",
    "            numerator += G.has_edge(n1, n2)\n",
    "    \n",
    "    return numerator / denominator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(G):\n",
    "    x = torch.randn(G.number_of_nodes(), 2)\n",
    "    ind = 0\n",
    "    for node in G.nodes():\n",
    "        # set node degree as feature\n",
    "        x[ind][0] = G.degree[node]\n",
    "        x[ind][1] = clustering_coefficient(G, node)\n",
    "        ind += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        for ind, graph in enumerate(total_laman_data[0]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        for ind, graph in enumerate(total_laman_data[1]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data-2d/data/4096-20-4-entries-med.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 122], x=[32, 2], label=[1], num_nodes=32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laman_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.6, .4]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches:  10\n",
      "Number of test batches:  7\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches: \", len(train_loader))\n",
    "print(\"Number of test batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 19174], x=[5146, 2], label=[256], num_nodes=5146, batch=[5146], ptr=[257])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gin.gin import GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv2): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv3): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv4): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv5): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv6): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv7): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (lin1): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (lin2): Linear(in_features=14, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  335\n"
     ]
    }
   ],
   "source": [
    "model = GIN(num_features=1)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=0.001)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', min_lr=1e-6, verbose=True, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, features_to_use):\n",
    "    ind = 0\n",
    "    for batch in data:\n",
    "        optimizer.zero_grad()\n",
    "        pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "        pred = torch.squeeze(pred)\n",
    "        loss = loss_fn(pred.float(), batch.label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ind += 1\n",
    "\n",
    "    return loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, features_to_use):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            y = batch.label\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Train loss 0.013843224383890629\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.81696156192801\n",
      "Epoch 1 | Train loss 0.014698607847094536\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.81696156192801\n",
      "Epoch 2 | Train loss 0.02366672269999981\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 3 | Train loss 0.013320577330887318\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 4 | Train loss 0.022057760506868362\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.81696156192801\n",
      "Epoch 5 | Train loss 0.021687457337975502\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 6 | Train loss 0.017188064754009247\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 7 | Train loss 0.01362987607717514\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.75594874923735\n",
      "Epoch 8 | Train loss 0.011929955333471298\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 9 | Train loss 0.026714444160461426\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 10 | Train loss 0.01659383252263069\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 11 | Train loss 0.016783172264695168\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.81696156192801\n",
      "Epoch 12 | Train loss 0.021467871963977814\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 13 | Train loss 0.018092025071382523\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 14 | Train loss 0.01598396711051464\n",
      "Train Accuracy 99.79649979649979 | Test Accuracy 99.38987187309336\n",
      "Epoch 15 | Train loss 0.015370428562164307\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 16 | Train loss 0.01319385040551424\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 17 | Train loss 0.013594552874565125\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.87797437461867\n",
      "Epoch 18 | Train loss 0.019028976559638977\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 19 | Train loss 0.012358037754893303\n",
      "Train Accuracy 99.63369963369964 | Test Accuracy 99.32885906040269\n",
      "Epoch 20 | Train loss 0.014439782127737999\n",
      "Train Accuracy 99.47089947089947 | Test Accuracy 99.14582062233069\n",
      "Epoch 21 | Train loss 0.019034527242183685\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.75594874923735\n",
      "Epoch 22 | Train loss 0.012396000325679779\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 23 | Train loss 0.014353745616972446\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.87797437461867\n",
      "Epoch 24 | Train loss 0.011856673285365105\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.87797437461867\n",
      "Epoch 25 | Train loss 0.013078276999294758\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.57291031116534\n",
      "Epoch 26 | Train loss 0.016080575063824654\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 27 | Train loss 0.03014119155704975\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 28 | Train loss 0.01908174902200699\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.87797437461867\n",
      "Epoch 29 | Train loss 0.01017487607896328\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.57291031116534\n",
      "Epoch 30 | Train loss 0.011608676984906197\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 31 | Train loss 0.01025961060076952\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 32 | Train loss 0.009376895613968372\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 33 | Train loss 0.024295439943671227\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 34 | Train loss 0.013991094194352627\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 35 | Train loss 0.012827148661017418\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.81696156192801\n",
      "Epoch 36 | Train loss 0.01907038502395153\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 37 | Train loss 0.012268375605344772\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 38 | Train loss 0.01254272274672985\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 39 | Train loss 0.024221763014793396\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 40 | Train loss 0.009942810982465744\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 41 | Train loss 0.0233235452324152\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 42 | Train loss 0.02581566944718361\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.63392312385601\n",
      "Epoch 43 | Train loss 0.01649048924446106\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 44 | Train loss 0.009141666814684868\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 45 | Train loss 0.010675684548914433\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 46 | Train loss 0.011681439355015755\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 47 | Train loss 0.012239870615303516\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 48 | Train loss 0.01264176145195961\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 49 | Train loss 0.01193581335246563\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 50 | Train loss 0.01855877786874771\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 51 | Train loss 0.014117435552179813\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 52 | Train loss 0.027551747858524323\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 53 | Train loss 0.00814387109130621\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.93898718730934\n",
      "Epoch 54 | Train loss 0.009943797253072262\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.81696156192801\n",
      "Epoch 55 | Train loss 0.015031076036393642\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 56 | Train loss 0.012920229695737362\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 57 | Train loss 0.009344527497887611\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 58 | Train loss 0.008974570780992508\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 59 | Train loss 0.011894595809280872\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 60 | Train loss 0.011101271025836468\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 61 | Train loss 0.0102712856605649\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 62 | Train loss 0.010516464710235596\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 63 | Train loss 0.014299665577709675\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 64 | Train loss 0.011941078118979931\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.93898718730934\n",
      "Epoch 65 | Train loss 0.009808957576751709\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 66 | Train loss 0.010251185856759548\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 67 | Train loss 0.010047257877886295\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 68 | Train loss 0.00942262914031744\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 69 | Train loss 0.013808979652822018\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 70 | Train loss 0.010538600385189056\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 71 | Train loss 0.00627675699070096\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.81696156192801\n",
      "Epoch 72 | Train loss 0.009898625314235687\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 73 | Train loss 0.03805795684456825\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 74 | Train loss 0.009849023073911667\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train loss 0.009025071747601032\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 76 | Train loss 0.012245881371200085\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 77 | Train loss 0.021105889230966568\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.93898718730934\n",
      "Epoch 78 | Train loss 0.01676791161298752\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 79 | Train loss 0.009663908742368221\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 80 | Train loss 0.008794955909252167\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 81 | Train loss 0.010799761861562729\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 82 | Train loss 0.014085688628256321\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 83 | Train loss 0.006791853345930576\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.75594874923735\n",
      "Epoch 84 | Train loss 0.011731481179594994\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 85 | Train loss 0.009461765177547932\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 86 | Train loss 0.01185652520507574\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 87 | Train loss 0.009869475848972797\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 88 | Train loss 0.008852353319525719\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.81696156192801\n",
      "Epoch 89 | Train loss 0.012061698362231255\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 90 | Train loss 0.007283866871148348\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 91 | Train loss 0.009308109059929848\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.75594874923735\n",
      "Epoch 92 | Train loss 0.009807712398469448\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 93 | Train loss 0.006971551105380058\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 94 | Train loss 0.007577152922749519\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 95 | Train loss 0.00767483888193965\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 96 | Train loss 0.007460743188858032\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 97 | Train loss 0.006201211363077164\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 98 | Train loss 0.00936411414295435\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 99 | Train loss 0.014838028699159622\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 100 | Train loss 0.00800818670541048\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.87797437461867\n",
      "Epoch 101 | Train loss 0.007364108692854643\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 102 | Train loss 0.010077654384076595\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 103 | Train loss 0.006860253866761923\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 104 | Train loss 0.007867398671805859\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 105 | Train loss 0.011105491779744625\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 106 | Train loss 0.007257008925080299\n",
      "Train Accuracy 99.83719983719985 | Test Accuracy 99.57291031116534\n",
      "Epoch 107 | Train loss 0.006100764032453299\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.81696156192801\n",
      "Epoch 108 | Train loss 0.007634140085428953\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 109 | Train loss 0.016192074865102768\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 110 | Train loss 0.015283146873116493\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.87797437461867\n",
      "Epoch 111 | Train loss 0.012431077659130096\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 112 | Train loss 0.013730145990848541\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 113 | Train loss 0.016330847516655922\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.93898718730934\n",
      "Epoch 114 | Train loss 0.012445555068552494\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 115 | Train loss 0.006475397385656834\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 116 | Train loss 0.01510559767484665\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 117 | Train loss 0.006676700431853533\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 118 | Train loss 0.010892064310610294\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 119 | Train loss 0.006601084489375353\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.69493593654668\n",
      "Epoch 120 | Train loss 0.00965516921132803\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 121 | Train loss 0.010803470388054848\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 122 | Train loss 0.005207367707043886\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.63392312385601\n",
      "Epoch 123 | Train loss 0.011431531049311161\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 124 | Train loss 0.007151310797780752\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.93898718730934\n",
      "Epoch 125 | Train loss 0.011871187016367912\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 126 | Train loss 0.005811275914311409\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 127 | Train loss 0.00646358635276556\n",
      "Train Accuracy 99.87789987789988 | Test Accuracy 99.87797437461867\n",
      "Epoch 128 | Train loss 0.011885277926921844\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 129 | Train loss 0.007091449107974768\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 130 | Train loss 0.007984204217791557\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 131 | Train loss 0.009082806296646595\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 132 | Train loss 0.00887853093445301\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 133 | Train loss 0.01708189770579338\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 134 | Train loss 0.007194908801466227\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 135 | Train loss 0.005977951921522617\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 136 | Train loss 0.01226136926561594\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 137 | Train loss 0.09394840896129608\n",
      "Train Accuracy 97.88359788359789 | Test Accuracy 97.43746186699207\n",
      "Epoch 138 | Train loss 0.021194975823163986\n",
      "Train Accuracy 78.02197802197803 | Test Accuracy 77.60829774252593\n",
      "Epoch 139 | Train loss 0.8018788695335388\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.75594874923735\n",
      "Epoch 140 | Train loss 0.03897319361567497\n",
      "Train Accuracy 99.51159951159951 | Test Accuracy 99.57291031116534\n",
      "Epoch 141 | Train loss 0.038150571286678314\n",
      "Train Accuracy 99.67439967439967 | Test Accuracy 99.57291031116534\n",
      "Epoch 142 | Train loss 0.016576731577515602\n",
      "Train Accuracy 99.5929995929996 | Test Accuracy 99.38987187309336\n",
      "Epoch 143 | Train loss 0.006386134773492813\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.81696156192801\n",
      "Epoch 144 | Train loss 0.009338156320154667\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 145 | Train loss 0.007202116306871176\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 146 | Train loss 0.016328901052474976\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 147 | Train loss 0.00818296242505312\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 148 | Train loss 0.006016227416694164\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 149 | Train loss 0.006077949423342943\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 150 | Train loss 0.005242855288088322\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151 | Train loss 0.006718936376273632\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 152 | Train loss 0.016012176871299744\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 153 | Train loss 0.0064912838861346245\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 154 | Train loss 0.009169233031570911\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 155 | Train loss 0.005564508959650993\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 156 | Train loss 0.005278186872601509\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 157 | Train loss 0.004960260353982449\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 158 | Train loss 0.006078795064240694\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 159 | Train loss 0.005702472757548094\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 160 | Train loss 0.005913288798183203\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 161 | Train loss 0.005937875248491764\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 162 | Train loss 0.006859952118247747\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 163 | Train loss 0.00553544657304883\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 164 | Train loss 0.0075658950954675674\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 165 | Train loss 0.012345235794782639\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 166 | Train loss 0.0056226360611617565\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 167 | Train loss 0.008667081594467163\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 168 | Train loss 0.006604641210287809\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 169 | Train loss 0.006190980318933725\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 170 | Train loss 0.00797613337635994\n",
      "Train Accuracy 100.0 | Test Accuracy 99.93898718730934\n",
      "Epoch 171 | Train loss 0.0062477015890181065\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 172 | Train loss 0.00594029575586319\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 173 | Train loss 0.005734387785196304\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 174 | Train loss 0.006442504934966564\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 175 | Train loss 0.01131085492670536\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 176 | Train loss 0.005705385468900204\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n",
      "Epoch 177 | Train loss 0.006796370726078749\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 178 | Train loss 0.00627357792109251\n",
      "Train Accuracy 99.95929995929997 | Test Accuracy 99.93898718730934\n",
      "Epoch 179 | Train loss 0.006769272964447737\n",
      "Train Accuracy 99.91859991859991 | Test Accuracy 99.93898718730934\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m bestModel, highestAcc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     loss, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, features_to_use)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, data, features_to_use):\n\u001b[1;32m      2\u001b[0m     ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m      4\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      5\u001b[0m         pred, embedding \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx[:, features_to_use], batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39mbatch)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/data/dataset.py:258\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03mIn case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03mtuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 258\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[idx])\n\u001b[1;32m    259\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/data/dataset.py:100\u001b[0m, in \u001b[0;36mDataset.indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindices\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, model = train(model, train_loader, [1])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model, train_loader, [1]), check_accuracy(model, test_loader, [1])\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "#     scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square\n",
    "import networkx as nx\n",
    "square = nx.Graph()\n",
    "square.add_edge(0, 1)\n",
    "square.add_edge(1, 3)\n",
    "square.add_edge(0, 2)\n",
    "square.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square with cross bar (rigid)\n",
    "import networkx as nx\n",
    "square_bar = nx.Graph()\n",
    "square_bar.add_edge(0, 1)\n",
    "square_bar.add_edge(1, 3)\n",
    "square_bar.add_edge(0, 2)\n",
    "square_bar.add_edge(2, 3)\n",
    "square_bar.add_edge(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle\n",
    "import networkx as nx\n",
    "triangle = nx.Graph()\n",
    "triangle.add_edge(0, 1)\n",
    "triangle.add_edge(0, 2)\n",
    "triangle.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentagon\n",
    "import networkx as nx\n",
    "pentagon = nx.Graph()\n",
    "pentagon.add_edge(0, 1)\n",
    "pentagon.add_edge(1, 3)\n",
    "pentagon.add_edge(3, 4)\n",
    "pentagon.add_edge(4, 2)\n",
    "pentagon.add_edge(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no triangle and rigid\n",
    "rigid = nx.Graph()\n",
    "rigid.add_edge(0, 1)\n",
    "rigid.add_edge(0, 2)\n",
    "rigid.add_edge(0, 4)\n",
    "rigid.add_edge(1, 2)\n",
    "rigid.add_edge(1, 5)\n",
    "rigid.add_edge(2, 3)\n",
    "rigid.add_edge(3, 4)\n",
    "rigid.add_edge(3, 5)\n",
    "rigid.add_edge(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9991]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9509]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3056]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9999]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8327]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "toy_problems = [square, square_bar, triangle, pentagon, rigid]\n",
    "labels = [1, 0, 0, 1, 0]\n",
    "\n",
    "for index, toy_problem in enumerate(toy_problems):\n",
    "    graph_as_data = from_networkx(toy_problem)\n",
    "    graph_as_data.x = generate_feature_vector(toy_problem)\n",
    "    graph_as_data.label = labels[index]\n",
    "    validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "    for batch in validation_set:\n",
    "        pred = model(batch.x[:, [1]], batch.edge_index, batch.batch)\n",
    "        print(pred[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10], num_nodes=5, x=[5, 2], label=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_as_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[41.9681]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in validation_set:\n",
    "    pred = bestModel(batch.x, batch.edge_index, batch.batch)\n",
    "    print(pred[0])\n",
    "    print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanTestDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_test.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add functionality to support a test dataset\n",
    "TEST_DATA_PATH = \"../data-2d/data/test-dataset-30loc-5std.pkl.gz\"\n",
    "laman_test_set = LamanTestDataset(\"\", TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "laman_test_loader = DataLoader(laman_test_set, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 99.21875\n"
     ]
    }
   ],
   "source": [
    "random_test_acc = check_accuracy(bestModel, laman_test_loader, [1])\n",
    "print(f\"Accuracy {random_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the clustering coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_coefficient(square, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_coefficient(triangle, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_coefficient(square_bar, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate graph correlating clustering coefficient to rigidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'networkx.classes.digraph.DiGraph'>\n"
     ]
    }
   ],
   "source": [
    "for item in train_data:\n",
    "    item = to_networkx(item)\n",
    "    print(type(item))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric.utils.convert.to_networkx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work: Sahil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_laman_data = None\n",
    "with gzip.open(DATA_PATH, 'r') as f:\n",
    "    total_laman_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph = total_laman_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'networkx.classes.graph.Graph'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_data = from_networkx(sample_graph)\n",
    "from_data = to_networkx(to_data, to_undirected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'networkx.classes.graph.Graph'>\n"
     ]
    }
   ],
   "source": [
    "print(type(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_clustering_coefficient(G):\n",
    "    min_coefficient = 1\n",
    "    for node in G.nodes():\n",
    "        min_coefficient = min(min_coefficient, clustering_coefficient(G, node))\n",
    "        \n",
    "    return min_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])   0   0.0\n",
      "tensor([1])   1   0.0\n",
      "tensor([0])   2   0.0\n",
      "tensor([0])   3   0.0\n",
      "tensor([0])   4   0.0\n",
      "tensor([0])   5   0.0\n",
      "tensor([1])   6   0.0\n",
      "tensor([0])   7   0.0\n",
      "tensor([0])   8   0.0\n",
      "tensor([1])   9   0.0\n",
      "tensor([0])   10   0.0\n"
     ]
    }
   ],
   "source": [
    "for index, sample_graph in enumerate(train_data):\n",
    "    label = sample_graph.label\n",
    "    networkx_sample_graph = to_networkx(sample_graph, to_undirected = True)\n",
    "    print(label, \" \", index, \" \", compute_min_clustering_coefficient(networkx_sample_graph))\n",
    "    \n",
    "    if index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_min_clustering_coefficient(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_min_clustering_coefficient(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if instead of training a gnn – you just trained on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the degrees of the nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the triangle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on the triangle features and the degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a network with just degree of the node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv2): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv3): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv4): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv5): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv6): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv7): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (lin1): Linear(in_features=112, out_features=112, bias=True)\n",
      "  (lin2): Linear(in_features=112, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  16577\n"
     ]
    }
   ],
   "source": [
    "model_just_degree = GIN(num_features=1)\n",
    "print(model_just_degree)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 0] (got interval [0, 5138])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:272\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    271\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m bestModel, highestAcc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     loss, h \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[94], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data, features_to_use)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m      4\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 5\u001b[0m     pred, embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures_to_use\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(pred)\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred\u001b[38;5;241m.\u001b[39mfloat(), batch\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Fall 2022/Independent Work/thesis/train-2d/gin/gin.py:43\u001b[0m, in \u001b[0;36mGIN.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, batch):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Node embeddings \u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     h2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(h1, edge_index)\n\u001b[1;32m     45\u001b[0m     h3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(h2, edge_index)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/nn/conv/gin_conv.py:80\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     77\u001b[0m     x: OptPairTensor \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:459\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    457\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 459\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:336\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, dim, data)\n\u001b[0;32m--> 336\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:275\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n\u001b[0;32m--> 275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered an index error. Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got interval \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mIndexError\u001b[0m: Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 0] (got interval [0, 5138])"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, h = train(train_loader, [0])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model_just_degree, train_loader), check_accuracy(model_just_degree, test_loader)\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "#     scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_feature_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_feature_vector\u001b[49m(sample_graph)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_feature_vector' is not defined"
     ]
    }
   ],
   "source": [
    "generate_feature_vector(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 0.3000],\n",
       "        [7.0000, 0.1429],\n",
       "        [3.0000, 0.0000],\n",
       "        [5.0000, 0.0000],\n",
       "        [6.0000, 0.1333],\n",
       "        [3.0000, 0.0000],\n",
       "        [5.0000, 0.3000],\n",
       "        [6.0000, 0.1333],\n",
       "        [3.0000, 0.3333],\n",
       "        [2.0000, 0.0000],\n",
       "        [3.0000, 0.3333],\n",
       "        [5.0000, 0.2000],\n",
       "        [3.0000, 0.0000],\n",
       "        [2.0000, 0.0000],\n",
       "        [2.0000, 1.0000],\n",
       "        [3.0000, 0.6667],\n",
       "        [3.0000, 0.3333]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_graph.x[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

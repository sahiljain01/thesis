{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from pebble import lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coefficient(G, node):\n",
    "    ns = [n for n in G.neighbors(node)]\n",
    "    if len(ns) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = len(ns) * (len(ns) - 1) / 2\n",
    "    for i in range(0, len(ns)):\n",
    "        for j in range(i+1, len(ns)):\n",
    "            n1, n2 = ns[i], ns[j]\n",
    "            numerator += G.has_edge(n1, n2)\n",
    "    \n",
    "    return numerator / denominator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(G):\n",
    "    x = torch.randn(G.number_of_nodes(), 4)\n",
    "    ind = 0\n",
    "    for node in G.nodes():\n",
    "        x[ind][0] = 1 # uniform\n",
    "        x[ind][1] = G.degree[node] # node degree as a scalar \n",
    "        x[ind][2] = clustering_coefficient(G, node) # triangle counting?\n",
    "        x[ind][3] = ind # node ID features\n",
    "        ind += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        for ind, graph in enumerate(total_laman_data[0]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        for ind, graph in enumerate(total_laman_data[1]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/custom-generated.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 58], x=[15, 4], label=[1], num_nodes=15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laman_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.7, .3]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches:  244\n",
      "Number of test batches:  105\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches: \", len(train_loader))\n",
    "print(\"Number of test batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 15466], x=[3840, 4], label=[256], num_nodes=3840, batch=[3840], ptr=[257])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_gcn.gcn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (initial_conv): GCNConv(4, 10)\n",
      "  (out): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out2): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  491\n"
     ]
    }
   ],
   "source": [
    "model = GCN(num_features=4)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=0.001)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', min_lr=1e-6, verbose=True, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, features_to_use):\n",
    "    ind = 0\n",
    "    model.train()\n",
    "    for batch in data:\n",
    "        optimizer.zero_grad()\n",
    "        pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "        pred = torch.squeeze(pred)\n",
    "        loss = loss_fn(pred.float(), batch.label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ind += 1\n",
    "\n",
    "    return loss, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, features_to_use):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            y = batch.label\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Train loss 0.5980435013771057\n",
      "Train Accuracy 72.9021091095583 | Test Accuracy 73.00127140827163\n",
      "Epoch 1 | Train loss 0.4411201775074005\n",
      "Train Accuracy 82.3578434515033 | Test Accuracy 82.13671378356145\n",
      "Epoch 2 | Train loss 0.4325883388519287\n",
      "Train Accuracy 83.96852362330918 | Test Accuracy 83.9241642360332\n",
      "Epoch 3 | Train loss 0.34170225262641907\n",
      "Train Accuracy 84.29867299185845 | Test Accuracy 84.2158402512901\n",
      "Epoch 4 | Train loss 0.3407120108604431\n",
      "Train Accuracy 84.66408103083532 | Test Accuracy 84.36915713110463\n",
      "Epoch 5 | Train loss 0.29925134778022766\n",
      "Train Accuracy 84.73940637220335 | Test Accuracy 84.74684017650138\n",
      "Epoch 6 | Train loss 0.3032626211643219\n",
      "Train Accuracy 84.94935572793128 | Test Accuracy 84.76927679305962\n",
      "Epoch 7 | Train loss 0.32959598302841187\n",
      "Train Accuracy 85.05673440605167 | Test Accuracy 84.90389649240895\n",
      "Epoch 8 | Train loss 0.34215569496154785\n",
      "Train Accuracy 85.15449708314635 | Test Accuracy 85.03851619175829\n",
      "Epoch 9 | Train loss 0.36789801716804504\n",
      "Train Accuracy 84.7890890441695 | Test Accuracy 84.54865006357042\n",
      "Epoch 10 | Train loss 0.4097265601158142\n",
      "Train Accuracy 85.29713443169435 | Test Accuracy 85.19557250766584\n",
      "Epoch 11 | Train loss 0.2905718684196472\n",
      "Train Accuracy 85.25867042759151 | Test Accuracy 85.0609528083165\n",
      "Epoch 12 | Train loss 0.27115747332572937\n",
      "Train Accuracy 85.44618244759279 | Test Accuracy 85.33767107920126\n",
      "Epoch 13 | Train loss 0.3337841331958771\n",
      "Train Accuracy 85.49746778639657 | Test Accuracy 85.34514995138733\n",
      "Epoch 14 | Train loss 0.3343217372894287\n",
      "Train Accuracy 85.22501442400154 | Test Accuracy 85.1020866053399\n",
      "Epoch 15 | Train loss 0.32779252529144287\n",
      "Train Accuracy 85.74107314571447 | Test Accuracy 85.68543863585371\n",
      "Epoch 16 | Train loss 0.28837838768959045\n",
      "Train Accuracy 85.86608115904866 | Test Accuracy 85.81257946301697\n",
      "Epoch 17 | Train loss 0.3297361433506012\n",
      "Train Accuracy 85.90133982947626 | Test Accuracy 85.84997382394735\n",
      "Epoch 18 | Train loss 0.30348697304725647\n",
      "Train Accuracy 86.09846785050324 | Test Accuracy 86.05938224515744\n",
      "Epoch 19 | Train loss 0.26117512583732605\n",
      "Train Accuracy 86.4638758894801 | Test Accuracy 86.41088923790292\n",
      "Epoch 20 | Train loss 0.32345858216285706\n",
      "Train Accuracy 86.27315853580357 | Test Accuracy 86.23513574153017\n",
      "Epoch 21 | Train loss 0.3750282824039459\n",
      "Train Accuracy 86.62414257324187 | Test Accuracy 86.54176950115922\n",
      "Epoch 22 | Train loss 0.2990012764930725\n",
      "Train Accuracy 86.44784922110391 | Test Accuracy 86.51559344850797\n",
      "Epoch 23 | Train loss 0.2656203806400299\n",
      "Train Accuracy 86.49753189307006 | Test Accuracy 86.56794555381049\n",
      "Epoch 24 | Train loss 0.3570007085800171\n",
      "Train Accuracy 87.10975062504008 | Test Accuracy 87.00545957669583\n",
      "Epoch 25 | Train loss 0.33787035942077637\n",
      "Train Accuracy 86.99275594589396 | Test Accuracy 86.93067085483509\n",
      "Epoch 26 | Train loss 0.23783889412879944\n",
      "Train Accuracy 86.98313994486826 | Test Accuracy 86.87831874953257\n",
      "Epoch 27 | Train loss 0.29816439747810364\n",
      "Train Accuracy 87.28283864350279 | Test Accuracy 87.21860743399895\n",
      "Epoch 28 | Train loss 0.2312033623456955\n",
      "Train Accuracy 87.47836399769216 | Test Accuracy 87.30835390023185\n",
      "Epoch 29 | Train loss 0.31219732761383057\n",
      "Train Accuracy 87.0953266235015 | Test Accuracy 86.93441029092813\n",
      "Epoch 30 | Train loss 0.32230108976364136\n",
      "Train Accuracy 87.47515866401693 | Test Accuracy 87.51402288534888\n",
      "Epoch 31 | Train loss 0.2689071595668793\n",
      "Train Accuracy 87.1754599653824 | Test Accuracy 87.05407224590532\n",
      "Epoch 32 | Train loss 0.31434860825538635\n",
      "Train Accuracy 87.43348932623887 | Test Accuracy 87.34948769725526\n",
      "Epoch 33 | Train loss 0.3334954082965851\n",
      "Train Accuracy 87.83095070196808 | Test Accuracy 87.727170742652\n",
      "Epoch 34 | Train loss 0.20804303884506226\n",
      "Train Accuracy 87.80050003205334 | Test Accuracy 87.62994540423304\n",
      "Epoch 35 | Train loss 0.24813231825828552\n",
      "Train Accuracy 87.680300019232 | Test Accuracy 87.49158626879067\n",
      "Epoch 36 | Train loss 0.27192410826683044\n",
      "Train Accuracy 87.9239053785499 | Test Accuracy 87.7757834118615\n",
      "Epoch 37 | Train loss 0.24816176295280457\n",
      "Train Accuracy 88.0665427270979 | Test Accuracy 87.98145239697853\n",
      "Epoch 38 | Train loss 0.32296353578567505\n",
      "Train Accuracy 87.60657734470159 | Test Accuracy 87.26722010320843\n",
      "Epoch 39 | Train loss 0.2782897651195526\n",
      "Train Accuracy 88.11782806590166 | Test Accuracy 87.94031859995512\n",
      "Epoch 40 | Train loss 0.2665139138698578\n",
      "Train Accuracy 88.37585742675813 | Test Accuracy 88.11233266023484\n",
      "Epoch 41 | Train loss 0.26409003138542175\n",
      "Train Accuracy 87.47035066350406 | Test Accuracy 87.03537506544014\n",
      "Epoch 42 | Train loss 0.2822537422180176\n",
      "Train Accuracy 87.8597987050452 | Test Accuracy 87.53645950190712\n",
      "Epoch 43 | Train loss 0.1854628026485443\n",
      "Train Accuracy 88.5265081094942 | Test Accuracy 88.2394734873981\n",
      "Epoch 44 | Train loss 0.2382573038339615\n",
      "Train Accuracy 88.58580678248606 | Test Accuracy 88.20581856256076\n",
      "Epoch 45 | Train loss 0.25073105096817017\n",
      "Train Accuracy 88.66754279120457 | Test Accuracy 88.3703537506544\n",
      "Epoch 46 | Train loss 0.20629490911960602\n",
      "Train Accuracy 88.67715879223027 | Test Accuracy 88.40400867549174\n",
      "Epoch 47 | Train loss 0.35231560468673706\n",
      "Train Accuracy 88.14988140265402 | Test Accuracy 87.82065664497793\n",
      "Epoch 48 | Train loss 0.25999772548675537\n",
      "Train Accuracy 88.6707481248798 | Test Accuracy 88.34791713409618\n",
      "Epoch 49 | Train loss 0.30852144956588745\n",
      "Train Accuracy 88.7156227963331 | Test Accuracy 88.41148754767781\n",
      "Epoch 50 | Train loss 0.1711435317993164\n",
      "Train Accuracy 88.74927879992308 | Test Accuracy 88.5012340139107\n",
      "Epoch 51 | Train loss 0.2549074590206146\n",
      "Train Accuracy 88.7524841335983 | Test Accuracy 88.56854386358538\n",
      "Epoch 52 | Train loss 0.32938677072525024\n",
      "Train Accuracy 88.74767613308545 | Test Accuracy 88.44514247251514\n",
      "Epoch 53 | Train loss 0.26745545864105225\n",
      "Train Accuracy 88.72684146419643 | Test Accuracy 88.43018472814299\n",
      "Epoch 54 | Train loss 0.20136192440986633\n",
      "Train Accuracy 88.79255080453875 | Test Accuracy 88.52741006656196\n",
      "Epoch 55 | Train loss 0.3088092803955078\n",
      "Train Accuracy 88.72844413103405 | Test Accuracy 88.42644529204996\n",
      "Epoch 56 | Train loss 0.26848533749580383\n",
      "Train Accuracy 88.33258542214244 | Test Accuracy 87.9964101413507\n",
      "Epoch 57 | Train loss 0.28052642941474915\n",
      "Train Accuracy 88.81819347394064 | Test Accuracy 88.55358611921322\n",
      "Epoch 58 | Train loss 0.25304335355758667\n",
      "Train Accuracy 88.86787614590679 | Test Accuracy 88.6021987884227\n",
      "Epoch 59 | Train loss 0.22211170196533203\n",
      "Train Accuracy 88.75408680043593 | Test Accuracy 88.43766360032907\n",
      "Epoch 60 | Train loss 0.2675402760505676\n",
      "Train Accuracy 88.75729213411117 | Test Accuracy 88.45262134470121\n",
      "Epoch 61 | Train loss 0.22715657949447632\n",
      "Train Accuracy 88.66433745752933 | Test Accuracy 88.34043826191011\n",
      "Epoch 62 | Train loss 0.23905602097511292\n",
      "Train Accuracy 88.8246041412911 | Test Accuracy 88.59845935232967\n",
      "Epoch 63 | Train loss 0.2633669972419739\n",
      "Train Accuracy 87.62100134624015 | Test Accuracy 87.2447834866502\n",
      "Epoch 64 | Train loss 0.19830815494060516\n",
      "Train Accuracy 88.87268414641964 | Test Accuracy 88.59845935232967\n",
      "Epoch 65 | Train loss 0.2815828025341034\n",
      "Train Accuracy 88.32777742162959 | Test Accuracy 87.9777129608855\n",
      "Epoch 66 | Train loss 0.2157973200082779\n",
      "Train Accuracy 88.90313481633439 | Test Accuracy 88.6208959688879\n",
      "Epoch 67 | Train loss 0.2603628635406494\n",
      "Train Accuracy 88.83902814282966 | Test Accuracy 88.54610724702715\n",
      "Epoch 68 | Train loss 0.2450271099805832\n",
      "Train Accuracy 88.91275081736009 | Test Accuracy 88.7517762321442\n",
      "Epoch 69 | Train loss 0.22869077324867249\n",
      "Train Accuracy 88.8951214821463 | Test Accuracy 88.60967766060878\n",
      "Epoch 70 | Train loss 0.23101043701171875\n",
      "Train Accuracy 88.75568946727354 | Test Accuracy 88.47131852516641\n",
      "Epoch 71 | Train loss 0.22106951475143433\n",
      "Train Accuracy 88.96083082248862 | Test Accuracy 88.73681848777204\n",
      "Epoch 72 | Train loss 0.2515750527381897\n",
      "Train Accuracy 88.96243348932624 | Test Accuracy 88.71438187121382\n",
      "Epoch 73 | Train loss 0.281135618686676\n",
      "Train Accuracy 88.76530546829925 | Test Accuracy 88.44514247251514\n",
      "Epoch 74 | Train loss 0.27299806475639343\n",
      "Train Accuracy 88.98967882556575 | Test Accuracy 88.71438187121382\n",
      "Epoch 75 | Train loss 0.2579808831214905\n",
      "Train Accuracy 88.86306814539392 | Test Accuracy 88.6021987884227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train loss 0.31625425815582275\n",
      "Train Accuracy 88.98647349189051 | Test Accuracy 88.82656495400494\n",
      "Epoch 77 | Train loss 0.25126975774765015\n",
      "Train Accuracy 88.71882813000833 | Test Accuracy 88.41522698377085\n",
      "Epoch 78 | Train loss 0.16792063415050507\n",
      "Train Accuracy 88.64670812231553 | Test Accuracy 88.29556502879366\n",
      "Epoch 79 | Train loss 0.20350387692451477\n",
      "Train Accuracy 89.03936149753189 | Test Accuracy 88.86769875102834\n",
      "Epoch 80 | Train loss 0.27415233850479126\n",
      "Train Accuracy 88.72203346368357 | Test Accuracy 88.40774811158477\n",
      "Epoch 81 | Train loss 0.2759786546230316\n",
      "Train Accuracy 88.87108147958203 | Test Accuracy 88.57602273577145\n",
      "Epoch 82 | Train loss 0.27774858474731445\n",
      "Train Accuracy 89.04256683120713 | Test Accuracy 88.87517762321441\n",
      "Epoch 83 | Train loss 0.26944464445114136\n",
      "Train Accuracy 89.04737483171998 | Test Accuracy 88.77421284870242\n",
      "Epoch 84 | Train loss 0.24679717421531677\n",
      "Train Accuracy 88.64350278864029 | Test Accuracy 88.35165657018922\n",
      "Epoch 85 | Train loss 0.25144174695014954\n",
      "Train Accuracy 88.60183345086223 | Test Accuracy 88.29182559270062\n",
      "Epoch 86 | Train loss 0.1980682760477066\n",
      "Train Accuracy 88.82780947496634 | Test Accuracy 88.54236781093411\n",
      "Epoch 87 | Train loss 0.32854968309402466\n",
      "Train Accuracy 89.04096416436951 | Test Accuracy 88.84152269837709\n",
      "Epoch 88 | Train loss 0.2754368782043457\n",
      "Train Accuracy 89.04256683120713 | Test Accuracy 88.9537057811682\n",
      "Epoch 89 | Train loss 0.32946455478668213\n",
      "Train Accuracy 89.07782550163472 | Test Accuracy 88.93874803679606\n",
      "Epoch 90 | Train loss 0.23990271985530853\n",
      "Train Accuracy 88.92877748573626 | Test Accuracy 88.64333258544612\n",
      "Epoch 91 | Train loss 0.24114660918712616\n",
      "Train Accuracy 88.89351881530867 | Test Accuracy 88.69568469074864\n",
      "Epoch 92 | Train loss 0.29385048151016235\n",
      "Train Accuracy 88.69959612795692 | Test Accuracy 88.4002692393987\n",
      "Epoch 93 | Train loss 0.2919892966747284\n",
      "Train Accuracy 88.48323610487851 | Test Accuracy 88.17590307381647\n",
      "Epoch 94 | Train loss 0.2482750415802002\n",
      "Train Accuracy 89.07141483428424 | Test Accuracy 88.93126916460997\n",
      "Epoch 95 | Train loss 0.24085526168346405\n",
      "Train Accuracy 88.88069748060772 | Test Accuracy 88.59471991623663\n",
      "Epoch 96 | Train loss 0.188639298081398\n",
      "Train Accuracy 89.09705750368614 | Test Accuracy 88.93126916460997\n",
      "Epoch 97 | Train loss 0.23754675686359406\n",
      "Train Accuracy 89.02493749599333 | Test Accuracy 88.80412833744671\n",
      "Epoch 98 | Train loss 0.1593293994665146\n",
      "Train Accuracy 89.07462016795948 | Test Accuracy 88.93126916460997\n",
      "Epoch 99 | Train loss 0.2570761740207672\n",
      "Train Accuracy 89.04416949804474 | Test Accuracy 88.81908608181887\n",
      "Epoch 100 | Train loss 0.2462068647146225\n",
      "Train Accuracy 88.36784409257004 | Test Accuracy 88.02258619400195\n",
      "Epoch 101 | Train loss 0.2761176526546478\n",
      "Train Accuracy 88.94480415411245 | Test Accuracy 88.61715653279485\n",
      "Epoch 102 | Train loss 0.3356774151325226\n",
      "Train Accuracy 89.05058016539522 | Test Accuracy 88.78917059307456\n",
      "Epoch 103 | Train loss 0.20164203643798828\n",
      "Train Accuracy 89.09224950317328 | Test Accuracy 88.9537057811682\n",
      "Epoch 104 | Train loss 0.31160464882850647\n",
      "Train Accuracy 89.11628950573754 | Test Accuracy 88.94622690898213\n",
      "Epoch 105 | Train loss 0.2813655436038971\n",
      "Train Accuracy 89.12430283992563 | Test Accuracy 88.8826564954005\n",
      "Epoch 106 | Train loss 0.32587453722953796\n",
      "Train Accuracy 89.03455349701905 | Test Accuracy 88.78169172088849\n",
      "Epoch 107 | Train loss 0.2738421559333801\n",
      "Train Accuracy 89.02493749599333 | Test Accuracy 88.86021987884227\n",
      "Epoch 108 | Train loss 0.25994521379470825\n",
      "Train Accuracy 88.78934547086351 | Test Accuracy 88.45636078079426\n",
      "Epoch 109 | Train loss 0.23729819059371948\n",
      "Train Accuracy 88.78133213667543 | Test Accuracy 88.47505796125944\n",
      "Epoch 110 | Train loss 0.2805485427379608\n",
      "Train Accuracy 89.16116417719084 | Test Accuracy 88.97240296163339\n",
      "Epoch 111 | Train loss 0.22701908648014069\n",
      "Train Accuracy 89.13712417462658 | Test Accuracy 88.94622690898213\n",
      "Epoch 112 | Train loss 0.2569715678691864\n",
      "Train Accuracy 89.05699083274568 | Test Accuracy 88.83030439009796\n",
      "Epoch 113 | Train loss 0.27438491582870483\n",
      "Train Accuracy 89.1483428424899 | Test Accuracy 88.97988183381946\n",
      "Epoch 114 | Train loss 0.32367977499961853\n",
      "Train Accuracy 89.1307135072761 | Test Accuracy 88.9237902924239\n",
      "Epoch 115 | Train loss 0.26848700642585754\n",
      "Train Accuracy 89.20443618180653 | Test Accuracy 89.02101563084287\n",
      "Epoch 116 | Train loss 0.3216283619403839\n",
      "Train Accuracy 89.16276684402847 | Test Accuracy 88.9948395781916\n",
      "Epoch 117 | Train loss 0.21274201571941376\n",
      "Train Accuracy 89.19642284761844 | Test Accuracy 89.00979732256376\n",
      "Epoch 118 | Train loss 0.19749489426612854\n",
      "Train Accuracy 89.19161484710558 | Test Accuracy 89.04719168349413\n",
      "Epoch 119 | Train loss 0.28887197375297546\n",
      "Train Accuracy 88.97525482402719 | Test Accuracy 88.73307905167901\n",
      "Epoch 120 | Train loss 0.286639541387558\n",
      "Train Accuracy 88.90954548368485 | Test Accuracy 88.70690299902775\n",
      "Epoch 121 | Train loss 0.22032564878463745\n",
      "Train Accuracy 89.10987883838708 | Test Accuracy 88.8826564954005\n",
      "Epoch 122 | Train loss 0.21570608019828796\n",
      "Train Accuracy 89.16917751137893 | Test Accuracy 89.00231845037769\n",
      "Epoch 123 | Train loss 0.20415553450584412\n",
      "Train Accuracy 88.61144945188795 | Test Accuracy 88.37409318674744\n",
      "Epoch 124 | Train loss 0.27267077565193176\n",
      "Train Accuracy 89.0041028271043 | Test Accuracy 88.78917059307456\n",
      "Epoch 125 | Train loss 0.22909054160118103\n",
      "Train Accuracy 89.09064683633567 | Test Accuracy 88.87517762321441\n",
      "Epoch 126 | Train loss 0.3068474233150482\n",
      "Train Accuracy 89.07462016795948 | Test Accuracy 88.86021987884227\n",
      "Epoch 127 | Train loss 0.23889540135860443\n",
      "Train Accuracy 89.210846849157 | Test Accuracy 88.94248747288908\n",
      "Epoch 128 | Train loss 0.24202823638916016\n",
      "Train Accuracy 89.10667350471184 | Test Accuracy 88.99110014209856\n",
      "Epoch 129 | Train loss 0.22878345847129822\n",
      "Train Accuracy 88.77652413616258 | Test Accuracy 88.54236781093411\n",
      "Epoch 130 | Train loss 0.27990853786468506\n",
      "Train Accuracy 89.20924418231938 | Test Accuracy 88.99857901428464\n",
      "Epoch 131 | Train loss 0.2706620693206787\n",
      "Train Accuracy 88.60503878453747 | Test Accuracy 88.31426220925884\n",
      "Epoch 132 | Train loss 0.19773465394973755\n",
      "Train Accuracy 89.13712417462658 | Test Accuracy 88.96866352554035\n",
      "Epoch 133 | Train loss 0.2979898750782013\n",
      "Train Accuracy 88.98967882556575 | Test Accuracy 88.72560017949294\n",
      "Epoch 134 | Train loss 0.2113301306962967\n",
      "Train Accuracy 89.04577216488237 | Test Accuracy 88.77047341260938\n",
      "Epoch 135 | Train loss 0.27526113390922546\n",
      "Train Accuracy 88.98487082505288 | Test Accuracy 88.7517762321442\n",
      "Epoch 136 | Train loss 0.21842479705810547\n",
      "Train Accuracy 89.19482018078082 | Test Accuracy 88.9537057811682\n",
      "Epoch 137 | Train loss 0.22523224353790283\n",
      "Train Accuracy 89.12590550676326 | Test Accuracy 88.87143818712137\n",
      "Epoch 138 | Train loss 0.1992880254983902\n",
      "Train Accuracy 89.19802551445606 | Test Accuracy 88.99857901428464\n",
      "Epoch 139 | Train loss 0.22470659017562866\n",
      "Train Accuracy 89.19001218026796 | Test Accuracy 89.00231845037769\n",
      "Epoch 140 | Train loss 0.3209075629711151\n",
      "Train Accuracy 89.1579588435156 | Test Accuracy 89.00979732256376\n",
      "Epoch 141 | Train loss 0.27706921100616455\n",
      "Train Accuracy 89.18520417975512 | Test Accuracy 88.98736070600553\n",
      "Epoch 142 | Train loss 0.30378273129463196\n",
      "Train Accuracy 89.1483428424899 | Test Accuracy 88.96492408944731\n",
      "Epoch 143 | Train loss 0.2891027629375458\n",
      "Train Accuracy 89.2204628501827 | Test Accuracy 88.98736070600553\n",
      "Epoch 144 | Train loss 0.31870919466018677\n",
      "Train Accuracy 89.09866017052374 | Test Accuracy 88.94996634507515\n",
      "Epoch 145 | Train loss 0.20671528577804565\n",
      "Train Accuracy 89.16917751137893 | Test Accuracy 88.93126916460997\n",
      "Epoch 146 | Train loss 0.2489253282546997\n",
      "Train Accuracy 89.12270017308802 | Test Accuracy 88.97614239772642\n",
      "Epoch 147 | Train loss 0.3152799606323242\n",
      "Train Accuracy 89.00250016026668 | Test Accuracy 88.82656495400494\n",
      "Epoch 148 | Train loss 0.2513166666030884\n",
      "Train Accuracy 89.1130841720623 | Test Accuracy 88.89761423977264\n",
      "Epoch 149 | Train loss 0.23611478507518768\n",
      "Train Accuracy 88.96403615616386 | Test Accuracy 88.68072694637648\n",
      "Epoch 150 | Train loss 0.3713968098163605\n",
      "Train Accuracy 89.30380152573882 | Test Accuracy 89.00231845037769\n",
      "Epoch 151 | Train loss 0.23294495046138763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 88.1482787358164 | Test Accuracy 87.82065664497793\n",
      "Epoch 152 | Train loss 0.31760892271995544\n",
      "Train Accuracy 89.10827617154946 | Test Accuracy 88.94622690898213\n",
      "Epoch 153 | Train loss 0.29565343260765076\n",
      "Train Accuracy 88.98807615872812 | Test Accuracy 88.8826564954005\n",
      "Epoch 154 | Train loss 0.3015795648097992\n",
      "Train Accuracy 88.93038015257389 | Test Accuracy 88.7929100291676\n",
      "Epoch 155 | Train loss 0.2243097424507141\n",
      "Train Accuracy 89.02493749599333 | Test Accuracy 88.87143818712137\n",
      "Epoch 156 | Train loss 0.28650742769241333\n",
      "Train Accuracy 89.26213218796076 | Test Accuracy 88.98736070600553\n",
      "Epoch 157 | Train loss 0.25676649808883667\n",
      "Train Accuracy 89.09866017052374 | Test Accuracy 88.92752972851694\n",
      "Epoch 158 | Train loss 0.24843788146972656\n",
      "Train Accuracy 89.2300788512084 | Test Accuracy 88.9537057811682\n",
      "Epoch 159 | Train loss 0.270255982875824\n",
      "Train Accuracy 89.07622283479711 | Test Accuracy 88.9537057811682\n",
      "Epoch 160 | Train loss 0.3020096719264984\n",
      "Train Accuracy 89.09705750368614 | Test Accuracy 88.98362126991249\n",
      "Epoch 161 | Train loss 0.3305579721927643\n",
      "Train Accuracy 88.66754279120457 | Test Accuracy 88.47505796125944\n",
      "Epoch 162 | Train loss 0.2730731666088104\n",
      "Train Accuracy 89.30700685941406 | Test Accuracy 89.00979732256376\n",
      "Epoch 163 | Train loss 0.25380295515060425\n",
      "Train Accuracy 89.26854285531124 | Test Accuracy 89.02849450302894\n",
      "Epoch 164 | Train loss 0.2848608195781708\n",
      "Train Accuracy 89.17398551189179 | Test Accuracy 89.00605788647073\n",
      "Epoch 165 | Train loss 0.2545749545097351\n",
      "Train Accuracy 89.25411885377268 | Test Accuracy 89.03597337521502\n",
      "Epoch 166 | Train loss 0.23315328359603882\n",
      "Train Accuracy 89.30540419257645 | Test Accuracy 89.03223393912198\n",
      "Epoch 167 | Train loss 0.2833970785140991\n",
      "Train Accuracy 89.30219885890122 | Test Accuracy 88.97240296163339\n",
      "Epoch 168 | Train loss 0.2604065239429474\n",
      "Train Accuracy 88.8951214821463 | Test Accuracy 88.68820581856257\n",
      "Epoch 169 | Train loss 0.30326515436172485\n",
      "Train Accuracy 88.72203346368357 | Test Accuracy 88.46383965298033\n",
      "Epoch 170 | Train loss 0.2355974018573761\n",
      "Train Accuracy 89.30380152573882 | Test Accuracy 89.05093111958716\n",
      "Epoch 171 | Train loss 0.1869690865278244\n",
      "Train Accuracy 89.26694018847363 | Test Accuracy 88.97988183381946\n",
      "Epoch 172 | Train loss 0.24965697526931763\n",
      "Train Accuracy 89.19161484710558 | Test Accuracy 89.04345224740109\n",
      "Epoch 173 | Train loss 0.23798149824142456\n",
      "Train Accuracy 88.74286813257261 | Test Accuracy 88.48627626953855\n",
      "Epoch 174 | Train loss 0.21124409139156342\n",
      "Train Accuracy 89.2925828578755 | Test Accuracy 89.10328322488968\n",
      "Epoch 175 | Train loss 0.1673153191804886\n",
      "Train Accuracy 88.82139880761586 | Test Accuracy 88.531149502655\n",
      "Epoch 176 | Train loss 0.20115453004837036\n",
      "Train Accuracy 89.29899352522598 | Test Accuracy 89.04719168349413\n",
      "Epoch 177 | Train loss 0.2518630623817444\n",
      "Train Accuracy 89.16917751137893 | Test Accuracy 89.00605788647073\n",
      "Epoch 178 | Train loss 0.23636257648468018\n",
      "Train Accuracy 89.29899352522598 | Test Accuracy 88.97240296163339\n",
      "Epoch 179 | Train loss 0.2082948237657547\n",
      "Train Accuracy 89.29418552471311 | Test Accuracy 89.04345224740109\n",
      "Epoch 180 | Train loss 0.2730688452720642\n",
      "Train Accuracy 89.30219885890122 | Test Accuracy 89.0845860444245\n",
      "Epoch 181 | Train loss 0.2659362554550171\n",
      "Train Accuracy 89.27174818898648 | Test Accuracy 89.14067758582006\n",
      "Epoch 182 | Train loss 0.20399071276187897\n",
      "Train Accuracy 89.23648951855888 | Test Accuracy 88.99857901428464\n",
      "Epoch 183 | Train loss 0.24718448519706726\n",
      "Train Accuracy 89.22206551702033 | Test Accuracy 89.04719168349413\n",
      "Epoch 184 | Train loss 0.31078481674194336\n",
      "Train Accuracy 89.30700685941406 | Test Accuracy 89.11076209707576\n",
      "Epoch 185 | Train loss 0.21571338176727295\n",
      "Train Accuracy 89.19962818129368 | Test Accuracy 89.07336773614539\n",
      "Epoch 186 | Train loss 0.28120189905166626\n",
      "Train Accuracy 89.34707353035452 | Test Accuracy 89.08832548051754\n",
      "Epoch 187 | Train loss 0.2647920846939087\n",
      "Train Accuracy 89.10987883838708 | Test Accuracy 88.93500860070301\n",
      "Epoch 188 | Train loss 0.26755520701408386\n",
      "Train Accuracy 89.24610551958459 | Test Accuracy 89.06214942786627\n",
      "Epoch 189 | Train loss 0.31056109070777893\n",
      "Train Accuracy 89.35989486505545 | Test Accuracy 89.09580435270361\n",
      "Epoch 190 | Train loss 0.2437044084072113\n",
      "Train Accuracy 89.31822552727739 | Test Accuracy 89.09580435270361\n",
      "Epoch 191 | Train loss 0.24801920354366302\n",
      "Train Accuracy 89.30219885890122 | Test Accuracy 89.08084660833147\n",
      "Epoch 192 | Train loss 0.30780234932899475\n",
      "Train Accuracy 89.23969485223412 | Test Accuracy 89.13693814972702\n",
      "Epoch 193 | Train loss 0.3061092793941498\n",
      "Train Accuracy 89.19642284761844 | Test Accuracy 89.08832548051754\n",
      "Epoch 194 | Train loss 0.2797495126724243\n",
      "Train Accuracy 89.35989486505545 | Test Accuracy 89.09206491661058\n",
      "Epoch 195 | Train loss 0.29015466570854187\n",
      "Train Accuracy 89.27815885633694 | Test Accuracy 89.15563533019221\n",
      "Epoch 196 | Train loss 0.19669018685817719\n",
      "Train Accuracy 89.25732418744792 | Test Accuracy 88.97988183381946\n",
      "Epoch 197 | Train loss 0.2852296233177185\n",
      "Train Accuracy 88.9399961535996 | Test Accuracy 88.75925510433026\n",
      "Epoch 198 | Train loss 0.23065662384033203\n",
      "Train Accuracy 88.762100134624 | Test Accuracy 88.57976217186449\n",
      "Epoch 199 | Train loss 0.19835171103477478\n",
      "Train Accuracy 89.37592153343164 | Test Accuracy 89.15937476628525\n",
      "Epoch 200 | Train loss 0.23779897391796112\n",
      "Train Accuracy 89.265337521636 | Test Accuracy 89.09954378879665\n",
      "Epoch 201 | Train loss 0.23671407997608185\n",
      "Train Accuracy 89.25251618693505 | Test Accuracy 89.0546705556802\n",
      "Epoch 202 | Train loss 0.24417707324028015\n",
      "Train Accuracy 89.319828194115 | Test Accuracy 89.17059307456435\n",
      "Epoch 203 | Train loss 0.23887543380260468\n",
      "Train Accuracy 88.92396948522341 | Test Accuracy 88.77795228479546\n",
      "Epoch 204 | Train loss 0.24603359401226044\n",
      "Train Accuracy 89.31822552727739 | Test Accuracy 89.12571984144792\n",
      "Epoch 205 | Train loss 0.2941798269748688\n",
      "Train Accuracy 89.33585486249117 | Test Accuracy 89.12571984144792\n",
      "Epoch 206 | Train loss 0.2747027575969696\n",
      "Train Accuracy 89.12109750625041 | Test Accuracy 88.9237902924239\n",
      "Epoch 207 | Train loss 0.28906548023223877\n",
      "Train Accuracy 89.09705750368614 | Test Accuracy 88.80786777353975\n",
      "Epoch 208 | Train loss 0.2834847569465637\n",
      "Train Accuracy 89.37912686710686 | Test Accuracy 89.21920574377384\n",
      "Epoch 209 | Train loss 0.18599095940589905\n",
      "Train Accuracy 89.28777485736265 | Test Accuracy 89.04345224740109\n",
      "Epoch 210 | Train loss 0.23918122053146362\n",
      "Train Accuracy 89.19161484710558 | Test Accuracy 89.02101563084287\n",
      "Epoch 211 | Train loss 0.231179341673851\n",
      "Train Accuracy 89.38072953394447 | Test Accuracy 88.98736070600553\n",
      "Epoch 212 | Train loss 0.2590792775154114\n",
      "Train Accuracy 89.14193217513943 | Test Accuracy 88.91631142023783\n",
      "Epoch 213 | Train loss 0.2680668234825134\n",
      "Train Accuracy 89.36149753189308 | Test Accuracy 89.10702266098272\n",
      "Epoch 214 | Train loss 0.2190128117799759\n",
      "Train Accuracy 89.27335085582409 | Test Accuracy 89.0546705556802\n",
      "Epoch 215 | Train loss 0.36311420798301697\n",
      "Train Accuracy 89.3823322007821 | Test Accuracy 89.1855508189365\n",
      "Epoch 216 | Train loss 0.2144201397895813\n",
      "Train Accuracy 89.38874286813258 | Test Accuracy 89.25286066861118\n",
      "Epoch 217 | Train loss 0.1905701607465744\n",
      "Train Accuracy 88.959228155651 | Test Accuracy 88.79664946526063\n",
      "Epoch 218 | Train loss 0.2634137272834778\n",
      "Train Accuracy 89.12109750625041 | Test Accuracy 88.89013536758657\n",
      "Epoch 219 | Train loss 0.23902882635593414\n",
      "Train Accuracy 89.17719084556703 | Test Accuracy 88.9537057811682\n",
      "Epoch 220 | Train loss 0.2771044671535492\n",
      "Train Accuracy 89.3102121930893 | Test Accuracy 89.13693814972702\n",
      "Epoch 221 | Train loss 0.28567662835121155\n",
      "Train Accuracy 89.31662286043978 | Test Accuracy 89.0845860444245\n",
      "Epoch 222 | Train loss 0.2226075679063797\n",
      "Train Accuracy 89.15154817616514 | Test Accuracy 88.97988183381946\n",
      "Epoch 223 | Train loss 0.3079470098018646\n",
      "Train Accuracy 89.36790819924354 | Test Accuracy 89.15563533019221\n",
      "Epoch 224 | Train loss 0.1887277066707611\n",
      "Train Accuracy 89.16436951086608 | Test Accuracy 88.90883254805175\n",
      "Epoch 225 | Train loss 0.23976927995681763\n",
      "Train Accuracy 89.12750817360087 | Test Accuracy 88.96492408944731\n",
      "Epoch 226 | Train loss 0.25184571743011475\n",
      "Train Accuracy 89.47368421052632 | Test Accuracy 89.20798743549473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227 | Train loss 0.32043540477752686\n",
      "Train Accuracy 89.34386819667928 | Test Accuracy 89.17059307456435\n",
      "Epoch 228 | Train loss 0.27003175020217896\n",
      "Train Accuracy 89.40316686967114 | Test Accuracy 89.234163488146\n",
      "Epoch 229 | Train loss 0.23010732233524323\n",
      "Train Accuracy 89.3647028655683 | Test Accuracy 89.20050856330866\n",
      "Epoch 230 | Train loss 0.2536255717277527\n",
      "Train Accuracy 89.02654016283094 | Test Accuracy 88.84152269837709\n",
      "Epoch 231 | Train loss 0.20968526601791382\n",
      "Train Accuracy 88.89031348163344 | Test Accuracy 88.72560017949294\n",
      "Epoch 232 | Train loss 0.24137452244758606\n",
      "Train Accuracy 89.48650554522726 | Test Accuracy 89.2154663076808\n",
      "Epoch 233 | Train loss 0.29955580830574036\n",
      "Train Accuracy 89.33585486249117 | Test Accuracy 89.16311420237828\n",
      "Epoch 234 | Train loss 0.30466845631599426\n",
      "Train Accuracy 89.38553753445734 | Test Accuracy 89.19302969112259\n",
      "Epoch 235 | Train loss 0.2652409076690674\n",
      "Train Accuracy 89.1307135072761 | Test Accuracy 88.99857901428464\n",
      "Epoch 236 | Train loss 0.20195338129997253\n",
      "Train Accuracy 89.35989486505545 | Test Accuracy 89.15563533019221\n",
      "Epoch 237 | Train loss 0.1989697962999344\n",
      "Train Accuracy 89.45605487531252 | Test Accuracy 89.21172687158776\n",
      "Epoch 238 | Train loss 0.236066535115242\n",
      "Train Accuracy 89.36951086608116 | Test Accuracy 89.24912123251814\n",
      "Epoch 239 | Train loss 0.2785487174987793\n",
      "Train Accuracy 89.01371882813001 | Test Accuracy 88.91631142023783\n",
      "Epoch 240 | Train loss 0.2798934578895569\n",
      "Train Accuracy 88.93358548624913 | Test Accuracy 88.80786777353975\n",
      "Epoch 241 | Train loss 0.24336376786231995\n",
      "Train Accuracy 89.2477081864222 | Test Accuracy 88.99857901428464\n",
      "Epoch 242 | Train loss 0.25342831015586853\n",
      "Train Accuracy 89.44964420796205 | Test Accuracy 89.28277615735547\n",
      "Epoch 243 | Train loss 0.25987890362739563\n",
      "Train Accuracy 88.91275081736009 | Test Accuracy 88.69942412684168\n",
      "Epoch 244 | Train loss 0.253150075674057\n",
      "Train Accuracy 89.3823322007821 | Test Accuracy 89.14815645800613\n",
      "Epoch 245 | Train loss 0.29033777117729187\n",
      "Train Accuracy 89.45765754215014 | Test Accuracy 89.21172687158776\n",
      "Epoch 246 | Train loss 0.22338591516017914\n",
      "Train Accuracy 89.14353484197704 | Test Accuracy 89.04345224740109\n",
      "Epoch 247 | Train loss 0.17989327013492584\n",
      "Train Accuracy 89.08744150266043 | Test Accuracy 88.90509311195872\n",
      "Epoch 248 | Train loss 0.2771666944026947\n",
      "Train Accuracy 89.49612154625297 | Test Accuracy 89.24912123251814\n",
      "Epoch 249 | Train loss 0.27843207120895386\n",
      "Train Accuracy 89.40316686967114 | Test Accuracy 89.26033954079725\n",
      "Epoch 250 | Train loss 0.2450992912054062\n",
      "Train Accuracy 89.4544522084749 | Test Accuracy 89.13319871363399\n",
      "Epoch 251 | Train loss 0.20650309324264526\n",
      "Train Accuracy 89.44323354061157 | Test Accuracy 89.2453817964251\n",
      "Epoch 252 | Train loss 0.22273078560829163\n",
      "Train Accuracy 89.12590550676326 | Test Accuracy 89.06214942786627\n",
      "Epoch 253 | Train loss 0.25755390524864197\n",
      "Train Accuracy 89.35829219821784 | Test Accuracy 89.17059307456435\n",
      "Epoch 254 | Train loss 0.2526431977748871\n",
      "Train Accuracy 89.20603884864414 | Test Accuracy 88.98736070600553\n",
      "Epoch 255 | Train loss 0.23322297632694244\n",
      "Train Accuracy 89.35989486505545 | Test Accuracy 89.06962830005234\n",
      "Epoch 256 | Train loss 0.23024341464042664\n",
      "Train Accuracy 89.51375088146676 | Test Accuracy 89.2752972851694\n",
      "Epoch 257 | Train loss 0.26467111706733704\n",
      "Train Accuracy 89.40476953650875 | Test Accuracy 89.20424799940169\n",
      "Epoch 258 | Train loss 0.2748272120952606\n",
      "Train Accuracy 88.96884415667671 | Test Accuracy 88.81908608181887\n",
      "Epoch 259 | Train loss 0.2521013915538788\n",
      "Train Accuracy 89.516956215142 | Test Accuracy 89.30147333782065\n",
      "Epoch 260 | Train loss 0.20488016307353973\n",
      "Train Accuracy 89.54259888454388 | Test Accuracy 89.2566001047042\n",
      "Epoch 261 | Train loss 0.32606813311576843\n",
      "Train Accuracy 89.5522148855696 | Test Accuracy 89.32017051828585\n",
      "Epoch 262 | Train loss 0.21676863729953766\n",
      "Train Accuracy 89.54259888454388 | Test Accuracy 89.3463465709371\n",
      "Epoch 263 | Train loss 0.25950464606285095\n",
      "Train Accuracy 89.4897108789025 | Test Accuracy 89.32017051828585\n",
      "Epoch 264 | Train loss 0.22737042605876923\n",
      "Train Accuracy 89.56984422078338 | Test Accuracy 89.33512826265799\n",
      "Epoch 265 | Train loss 0.21373556554317474\n",
      "Train Accuracy 89.54099621770627 | Test Accuracy 89.38748036796052\n",
      "Epoch 266 | Train loss 0.24243898689746857\n",
      "Train Accuracy 89.06981216744663 | Test Accuracy 88.79664946526063\n",
      "Epoch 267 | Train loss 0.24766215682029724\n",
      "Train Accuracy 89.10827617154946 | Test Accuracy 88.78169172088849\n",
      "Epoch 268 | Train loss 0.23130404949188232\n",
      "Train Accuracy 89.3278415283031 | Test Accuracy 89.11076209707576\n",
      "Epoch 269 | Train loss 0.16197170317173004\n",
      "Train Accuracy 88.9223668183858 | Test Accuracy 88.58350160795752\n",
      "Epoch 270 | Train loss 0.2420167177915573\n",
      "Train Accuracy 89.60189755753574 | Test Accuracy 89.36130431530925\n",
      "Epoch 271 | Train loss 0.2394847273826599\n",
      "Train Accuracy 89.56503622027053 | Test Accuracy 89.32764939047192\n",
      "Epoch 272 | Train loss 0.25032174587249756\n",
      "Train Accuracy 89.60510289121098 | Test Accuracy 89.31269164609978\n",
      "Epoch 273 | Train loss 0.22273342311382294\n",
      "Train Accuracy 89.58747355599718 | Test Accuracy 89.32764939047192\n",
      "Epoch 274 | Train loss 0.2431313693523407\n",
      "Train Accuracy 89.49772421309058 | Test Accuracy 89.36504375140228\n",
      "Epoch 275 | Train loss 0.2305479645729065\n",
      "Train Accuracy 89.5345855503558 | Test Accuracy 89.32764939047192\n",
      "Epoch 276 | Train loss 0.2760017514228821\n",
      "Train Accuracy 89.40156420283351 | Test Accuracy 89.15189589409917\n",
      "Epoch 277 | Train loss 0.19869230687618256\n",
      "Train Accuracy 89.60830822488622 | Test Accuracy 89.43235360107695\n",
      "Epoch 278 | Train loss 0.2237364798784256\n",
      "Train Accuracy 89.51214821462914 | Test Accuracy 89.24912123251814\n",
      "Epoch 279 | Train loss 0.2037491649389267\n",
      "Train Accuracy 89.53138021668056 | Test Accuracy 89.33886769875102\n",
      "Epoch 280 | Train loss 0.2720186114311218\n",
      "Train Accuracy 89.56663888710816 | Test Accuracy 89.3762620596814\n",
      "Epoch 281 | Train loss 0.24166415631771088\n",
      "Train Accuracy 89.462465542663 | Test Accuracy 89.23790292423902\n",
      "Epoch 282 | Train loss 0.24468210339546204\n",
      "Train Accuracy 89.36630553240592 | Test Accuracy 89.15189589409917\n",
      "Epoch 283 | Train loss 0.24053072929382324\n",
      "Train Accuracy 89.571446887621 | Test Accuracy 89.33886769875102\n",
      "Epoch 284 | Train loss 0.27069762349128723\n",
      "Train Accuracy 89.58426822232194 | Test Accuracy 89.39121980405355\n",
      "Epoch 285 | Train loss 0.27316606044769287\n",
      "Train Accuracy 89.43041220591064 | Test Accuracy 89.1743325106574\n",
      "Epoch 286 | Train loss 0.3140847980976105\n",
      "Train Accuracy 89.58426822232194 | Test Accuracy 89.42487472889088\n",
      "Epoch 287 | Train loss 0.3312951624393463\n",
      "Train Accuracy 89.60991089172383 | Test Accuracy 89.39495924014659\n",
      "Epoch 288 | Train loss 0.2632690370082855\n",
      "Train Accuracy 89.60991089172383 | Test Accuracy 89.43983247326304\n",
      "Epoch 289 | Train loss 0.22461380064487457\n",
      "Train Accuracy 89.47528687736394 | Test Accuracy 89.234163488146\n",
      "Epoch 290 | Train loss 0.22612527012825012\n",
      "Train Accuracy 89.52817488300532 | Test Accuracy 89.22294517986687\n",
      "Epoch 291 | Train loss 0.27715033292770386\n",
      "Train Accuracy 89.63715622796333 | Test Accuracy 89.39869867623962\n",
      "Epoch 292 | Train loss 0.21759289503097534\n",
      "Train Accuracy 89.60029489069812 | Test Accuracy 89.36130431530925\n",
      "Epoch 293 | Train loss 0.23670969903469086\n",
      "Train Accuracy 89.59548689018527 | Test Accuracy 89.31269164609978\n",
      "Epoch 294 | Train loss 0.2373238056898117\n",
      "Train Accuracy 89.58266555548433 | Test Accuracy 89.3463465709371\n",
      "Epoch 295 | Train loss 0.21254754066467285\n",
      "Train Accuracy 89.6163215590743 | Test Accuracy 89.36878318749532\n",
      "Epoch 296 | Train loss 0.22613218426704407\n",
      "Train Accuracy 89.156356176678 | Test Accuracy 88.84900157056316\n",
      "Epoch 297 | Train loss 0.266489177942276\n",
      "Train Accuracy 89.60991089172383 | Test Accuracy 89.3762620596814\n",
      "Epoch 298 | Train loss 0.2897724509239197\n",
      "Train Accuracy 89.62433489326239 | Test Accuracy 89.40991698451873\n",
      "Epoch 299 | Train loss 0.20488885045051575\n",
      "Train Accuracy 89.29418552471311 | Test Accuracy 88.95744521726124\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(300):\n",
    "    loss, _ = train(train_loader, [0, 1, 2, 3])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model, train_loader, [0, 1, 2, 3]), check_accuracy(model, test_loader, [0, 1, 2, 3])\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square\n",
    "import networkx as nx\n",
    "square = nx.Graph()\n",
    "square.add_edge(0, 1)\n",
    "square.add_edge(1, 3)\n",
    "square.add_edge(0, 2)\n",
    "square.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square with cross bar (rigid)\n",
    "import networkx as nx\n",
    "square_bar = nx.Graph()\n",
    "square_bar.add_edge(0, 1)\n",
    "square_bar.add_edge(1, 3)\n",
    "square_bar.add_edge(0, 2)\n",
    "square_bar.add_edge(2, 3)\n",
    "square_bar.add_edge(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle\n",
    "import networkx as nx\n",
    "triangle = nx.Graph()\n",
    "triangle.add_edge(0, 1)\n",
    "triangle.add_edge(0, 2)\n",
    "triangle.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentagon\n",
    "import networkx as nx\n",
    "pentagon = nx.Graph()\n",
    "pentagon.add_edge(0, 1)\n",
    "pentagon.add_edge(1, 3)\n",
    "pentagon.add_edge(3, 4)\n",
    "pentagon.add_edge(4, 2)\n",
    "pentagon.add_edge(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no triangle and rigid\n",
    "rigid = nx.Graph()\n",
    "rigid.add_edge(0, 1)\n",
    "rigid.add_edge(0, 2)\n",
    "rigid.add_edge(0, 4)\n",
    "rigid.add_edge(1, 2)\n",
    "rigid.add_edge(1, 5)\n",
    "rigid.add_edge(2, 3)\n",
    "rigid.add_edge(3, 4)\n",
    "rigid.add_edge(3, 5)\n",
    "rigid.add_edge(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (initial_conv): GCNConv(4, 10)\n",
       "  (out): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (out2): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "bestModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.8983]]), tensor([[2.1784]]))\n",
      "(tensor([[0.0891]]), tensor([[-2.3246]]))\n",
      "(tensor([[0.4025]]), tensor([[-0.3951]]))\n",
      "(tensor([[0.9303]]), tensor([[2.5917]]))\n",
      "(tensor([[0.0054]]), tensor([[-5.2084]]))\n"
     ]
    }
   ],
   "source": [
    "toy_problems = [square, square_bar, triangle, pentagon, rigid]\n",
    "labels = [1, 0, 0, 1, 0]\n",
    "\n",
    "for index, toy_problem in enumerate(toy_problems):\n",
    "    graph_as_data = from_networkx(toy_problem)\n",
    "    graph_as_data.x = generate_feature_vector(toy_problem)\n",
    "#     print(generate_feature_vector(toy_problem))\n",
    "#     graph_as_data.label = labels[index]\n",
    "    validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "    for batch in validation_set:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "#             print(batch.x[:, [0, 1, 2, 3]])\n",
    "#             print(\"******\")\n",
    "#             print(batch.edge_index)\n",
    "#             print(\"******\")\n",
    "#             print(batch.batch)\n",
    "#             print(\"******\")\n",
    "            pred = model(batch.x[:, [0, 1, 2, 3]], batch.edge_index, batch.batch)\n",
    "            print(pred)\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the bad examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_generate_bad_data = DataLoader(test_data, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_generate_bad_data = DataLoader(train_data, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26742\n"
     ]
    }
   ],
   "source": [
    "print(len(test_to_generate_bad_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.29418552471311"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(model, train_to_generate_bad_data, [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectly_predicted_flexible_graphs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectly_predicted_rigid_graphs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5360\n"
     ]
    }
   ],
   "source": [
    "print(len(incorrectly_predicted_flexible_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4275\n"
     ]
    }
   ],
   "source": [
    "print(len(incorrectly_predicted_rigid_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.95744521726124"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(model, test_to_generate_bad_data, [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"incorrectly-predicted.pkl.gz\"\n",
    "with gzip.open(output_file, 'wb') as f:\n",
    "    pickle.dump((incorrectly_predicted_rigid_graphs, incorrectly_predicted_flexible_graphs), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62396\n"
     ]
    }
   ],
   "source": [
    "print(len(train_to_generate_bad_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, features_to_use):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            y = batch.label\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            if not (predictions == y).sum():\n",
    "                graph = to_networkx(batch, to_undirected = True)\n",
    "                if y[0] == 0:\n",
    "                    incorrectly_predicted_rigid_graphs.append(graph)\n",
    "                elif y[0] == 1:\n",
    "                    incorrectly_predicted_flexible_graphs.append(graph)\n",
    "                \n",
    "            num_samples += 1\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.training)\n",
    "model.train()\n",
    "print(model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigid_data, not_rigid_data = [], []\n",
    "stats = {}\n",
    "stats_considered = {}\n",
    "prev_graphs = []\n",
    "\n",
    "stats_wrong = {}\n",
    "\n",
    "num_nodes = 30\n",
    "for p in np.arange(0.01, 0.3, 0.01):\n",
    "    stats[p] = 0\n",
    "    stats_wrong[p] = 0\n",
    "    for num_graphs in range(1000):\n",
    "        G = nx.erdos_renyi_graph(num_nodes, p)        \n",
    "        l = lattice()\n",
    "        num_edges = 0\n",
    "\n",
    "        for (u, v) in G.edges():\n",
    "            if l.add_bond(u, v):\n",
    "                num_edges += 1\n",
    "\n",
    "        label = 1\n",
    "        rigid = False\n",
    "        if num_edges >= (num_nodes * 2) - 3: # rigid \n",
    "            rigid = True\n",
    "            stats[p] += 1\n",
    "            label = 0\n",
    "\n",
    "        graph_as_data = from_networkx(G)\n",
    "        graph_as_data.x = generate_feature_vector(G)\n",
    "        validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "        for batch in validation_set:\n",
    "            pred = model(batch.x[:, [0]], batch.edge_index, batch.batch)\n",
    "            pred_label = 1\n",
    "            if (pred[0][0][0] < 0.5):\n",
    "                pred_label = 0\n",
    "                \n",
    "            if pred_label != label:\n",
    "                print(pred[0][0][0] , \" \", label)\n",
    "                stats_wrong[p] += 1\n",
    "                print(\"wrong: , with number of edges: \" , G.number_of_edges(), \" \", num_edges)\n",
    "                \n",
    "    print(stats[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(list(stats_wrong.keys()), stats_wrong.values(), color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(stats_wrong.values())) / (len(stats_wrong) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stats_wrong) * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_as_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigid_data, not_rigid_data = [], []\n",
    "stats = {}\n",
    "prev_graphs = []\n",
    "\n",
    "num_nodes = 30\n",
    "for p in np.arange(0.01, 0.3, 0.01):\n",
    "    stats[p] = 0\n",
    "    for num_graphs in range(1000):\n",
    "        G = nx.erdos_renyi_graph(num_nodes, p)\n",
    "        l = lattice()\n",
    "        num_edges = 0\n",
    "\n",
    "        for (u, v) in G.edges():\n",
    "            if l.add_bond(u, v):\n",
    "                num_edges += 1\n",
    "\n",
    "        rigid = False\n",
    "        if num_edges >= (num_nodes * 2) - 3: # rigid \n",
    "            rigid_data.append(G)\n",
    "            stats[p] += 1\n",
    "        else:\n",
    "            not_rigid_data.append(G)\n",
    "\n",
    "        prev_graphs.append(G)\n",
    "        \n",
    "    print(stats[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigid_data_1_wrong, not_rigid_data_1_wrong = [], []\n",
    "stats_wrong = {}\n",
    "stats_wrong_cum = {}\n",
    "prev_graphs = []\n",
    "\n",
    "num_nodes = 30\n",
    "for num_edges in range(57, 200):\n",
    "    model.eval()\n",
    "    stats_wrong[num_edges] = 0\n",
    "    for num_graphs in range(10):\n",
    "        G = generate_rigid_nodes_edges(num_nodes, num_edges)\n",
    "        \n",
    "#         G = nx.erdos_renyi_graph(num_nodes, p)\n",
    "#         generate_rigid_nodes_edges()\n",
    "        graph_as_data = from_networkx(G)\n",
    "        graph_as_data.x = generate_feature_vector(G)\n",
    "#         graph_as_data.label = labels[index]\n",
    "        validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "        for batch in validation_set:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch.x[:, [0, 1, 2, 3]], batch.edge_index, batch.batch)\n",
    "                if (pred[0][0][0] > 0.5):\n",
    "                    stats_wrong[num_edges] += 1\n",
    "                    print(\"WRONG\")\n",
    "                \n",
    "\n",
    "print(stats_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in validation_set:\n",
    "    pred = bestModel(batch.x, batch.edge_index, batch.batch)\n",
    "    print(pred[0])\n",
    "    print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanTestDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_test.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add functionality to support a test dataset\n",
    "TEST_DATA_PATH = \"../data-2d/data/test-dataset-30loc-5std.pkl.gz\"\n",
    "laman_test_set = LamanTestDataset(\"\", TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "laman_test_loader = DataLoader(laman_test_set, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_acc = check_accuracy(model, test_loader, [0, 1, 2, 3])\n",
    "print(f\"Accuracy {random_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the clustering coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(triangle, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square_bar, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate graph correlating clustering coefficient to rigidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_data:\n",
    "    item = to_networkx(item)\n",
    "    print(type(item))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric.utils.convert.to_networkx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work: Sahil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_laman_data = None\n",
    "with gzip.open(DATA_PATH, 'r') as f:\n",
    "    total_laman_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph = total_laman_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_data = from_networkx(sample_graph)\n",
    "from_data = to_networkx(to_data, to_undirected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_clustering_coefficient(G):\n",
    "    min_coefficient = 1\n",
    "    for node in G.nodes():\n",
    "        min_coefficient = min(min_coefficient, clustering_coefficient(G, node))\n",
    "        \n",
    "    return min_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sample_graph in enumerate(train_data):\n",
    "    label = sample_graph.label\n",
    "    networkx_sample_graph = to_networkx(sample_graph, to_undirected = True)\n",
    "    print(label, \" \", index, \" \", compute_min_clustering_coefficient(networkx_sample_graph))\n",
    "    \n",
    "    if index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_min_clustering_coefficient(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_min_clustering_coefficient(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_just_degree = GIN(num_features=1)\n",
    "print(model_just_degree)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, h = train(train_loader, [0, 1])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model_just_degree, train_loader), check_accuracy(model_just_degree, test_loader)\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "#     scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_feature_vector(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph.x[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen import generate_rigid_nodes_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/sahiljain/Documents/Fall 2022/Independent Work/reversible-inductive-construction/code/genric/laman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(triangle, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"gcn-model-filtered-data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coefficient(G, node):\n",
    "    ns = [n for n in G.neighbors(node)]\n",
    "    if len(ns) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = len(ns) * (len(ns) - 1) / 2\n",
    "    for i in range(0, len(ns)):\n",
    "        for j in range(i+1, len(ns)):\n",
    "            n1, n2 = ns[i], ns[j]\n",
    "            numerator += G.has_edge(n1, n2)\n",
    "    \n",
    "    return numerator / denominator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(G):\n",
    "    x = torch.randn(G.number_of_nodes(), 4)\n",
    "    ind = 0\n",
    "    for node in G.nodes():\n",
    "        x[ind][0] = 1 # uniform\n",
    "        x[ind][1] = G.degree[node] # node degree as a scalar \n",
    "        x[ind][2] = clustering_coefficient(G, node) # triangle counting?\n",
    "        x[ind][3] = ind # node ID features\n",
    "        ind += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        for ind, graph in enumerate(total_laman_data[0]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        for ind, graph in enumerate(total_laman_data[1]):\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/custom-generated.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 64], x=[15, 4], label=[1], num_nodes=15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laman_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.7, .3]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches:  27\n",
      "Number of test batches:  12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches: \", len(train_loader))\n",
    "print(\"Number of test batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 15082], x=[3840, 4], label=[256], num_nodes=3840, batch=[3840], ptr=[257])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gin.gin_k_layers import GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): GINConv(nn=Sequential(\n",
      "      (0): Linear(in_features=4, out_features=5, bias=True)\n",
      "      (1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (4): ReLU()\n",
      "    ))\n",
      "    (1): GINConv(nn=Sequential(\n",
      "      (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (4): ReLU()\n",
      "    ))\n",
      "  )\n",
      "  (lin1): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (lin2): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  1096\n"
     ]
    }
   ],
   "source": [
    "model = GIN(layers = 2, num_features=4, dim_h=5)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=0.001)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', min_lr=1e-6, verbose=True, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, features_to_use):\n",
    "    ind = 0\n",
    "    for batch in data:\n",
    "        optimizer.zero_grad()\n",
    "        pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "        pred = torch.squeeze(pred)\n",
    "        loss = loss_fn(pred.float(), batch.label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ind += 1\n",
    "\n",
    "    return loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, features_to_use):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            y = batch.label\n",
    "            batch.label = 0\n",
    "            pred, embedding = model(batch.x[:, features_to_use], batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Train loss 0.6849928498268127\n",
      "Train Accuracy 55.693950177935946 | Test Accuracy 55.482531995849186\n",
      "Epoch 1 | Train loss 0.6633871793746948\n",
      "Train Accuracy 55.693950177935946 | Test Accuracy 55.482531995849186\n",
      "Epoch 2 | Train loss 0.6894745826721191\n",
      "Train Accuracy 55.63463819691577 | Test Accuracy 55.55171221030785\n",
      "Epoch 3 | Train loss 0.6548170447349548\n",
      "Train Accuracy 57.23606168446026 | Test Accuracy 56.62400553441715\n",
      "Epoch 4 | Train loss 0.6661596894264221\n",
      "Train Accuracy 56.86536180308423 | Test Accuracy 57.6271186440678\n",
      "Epoch 5 | Train loss 0.676677942276001\n",
      "Train Accuracy 57.725385527876625 | Test Accuracy 57.59252853683846\n",
      "Epoch 6 | Train loss 0.6616142392158508\n",
      "Train Accuracy 57.87366548042705 | Test Accuracy 57.6271186440678\n",
      "Epoch 7 | Train loss 0.7219956517219543\n",
      "Train Accuracy 58.377817319098455 | Test Accuracy 58.42269111034244\n",
      "Epoch 8 | Train loss 0.6362115144729614\n",
      "Train Accuracy 59.14887307236062 | Test Accuracy 59.25285368384642\n",
      "Epoch 9 | Train loss 0.6748813986778259\n",
      "Train Accuracy 59.386120996441285 | Test Accuracy 59.28744379107576\n",
      "Epoch 10 | Train loss 0.6685258746147156\n",
      "Train Accuracy 61.95136417556346 | Test Accuracy 61.25907990314769\n",
      "Epoch 11 | Train loss 0.6401136517524719\n",
      "Train Accuracy 65.48042704626334 | Test Accuracy 65.61743341404357\n",
      "Epoch 12 | Train loss 0.5520475506782532\n",
      "Train Accuracy 72.07888493475683 | Test Accuracy 72.18955378761675\n",
      "Epoch 13 | Train loss 0.5011911392211914\n",
      "Train Accuracy 76.17141162514828 | Test Accuracy 76.34036665513662\n",
      "Epoch 14 | Train loss 0.47234079241752625\n",
      "Train Accuracy 79.0332147093713 | Test Accuracy 78.55413351781391\n",
      "Epoch 15 | Train loss 0.40020596981048584\n",
      "Train Accuracy 80.53084223013049 | Test Accuracy 79.48806641300588\n",
      "Epoch 16 | Train loss 0.44572046399116516\n",
      "Train Accuracy 81.88018979833926 | Test Accuracy 80.87167070217917\n",
      "Epoch 17 | Train loss 0.43661510944366455\n",
      "Train Accuracy 82.39916963226572 | Test Accuracy 81.63265306122449\n",
      "Epoch 18 | Train loss 0.4032532870769501\n",
      "Train Accuracy 82.7846975088968 | Test Accuracy 81.80560359737116\n",
      "Epoch 19 | Train loss 0.3161773681640625\n",
      "Train Accuracy 83.18505338078292 | Test Accuracy 82.3936354202698\n",
      "Epoch 20 | Train loss 0.37562692165374756\n",
      "Train Accuracy 83.19988137603796 | Test Accuracy 82.46281563472847\n",
      "Epoch 21 | Train loss 0.32622623443603516\n",
      "Train Accuracy 83.76334519572953 | Test Accuracy 82.84330681425112\n",
      "Epoch 22 | Train loss 0.28256461024284363\n",
      "Train Accuracy 83.926453143535 | Test Accuracy 82.98166724316846\n",
      "Epoch 23 | Train loss 0.3227125108242035\n",
      "Train Accuracy 84.1785290628707 | Test Accuracy 82.87789692148046\n",
      "Epoch 24 | Train loss 0.34390899538993835\n",
      "Train Accuracy 83.98576512455516 | Test Accuracy 82.87789692148046\n",
      "Epoch 25 | Train loss 0.3324829936027527\n",
      "Train Accuracy 84.4306049822064 | Test Accuracy 83.15461777931512\n",
      "Epoch 26 | Train loss 0.25960612297058105\n",
      "Train Accuracy 84.13404507710558 | Test Accuracy 83.39674852992044\n",
      "Epoch 27 | Train loss 0.28144967555999756\n",
      "Train Accuracy 84.47508896797153 | Test Accuracy 83.84641992390176\n",
      "Epoch 28 | Train loss 0.295877069234848\n",
      "Train Accuracy 84.31198102016607 | Test Accuracy 83.36215842269111\n",
      "Epoch 29 | Train loss 0.3163001835346222\n",
      "Train Accuracy 84.54922894424674 | Test Accuracy 83.50051885160845\n",
      "Epoch 30 | Train loss 0.38660457730293274\n",
      "Train Accuracy 85.14234875444839 | Test Accuracy 84.08855067450709\n",
      "Epoch 31 | Train loss 0.33548304438591003\n",
      "Train Accuracy 83.70403321470937 | Test Accuracy 82.94707713593911\n",
      "Epoch 32 | Train loss 0.39094850420951843\n",
      "Train Accuracy 84.38612099644128 | Test Accuracy 83.91560013836042\n",
      "Epoch 33 | Train loss 0.39839038252830505\n",
      "Train Accuracy 85.37959667852907 | Test Accuracy 84.36527153234175\n",
      "Epoch 34 | Train loss 0.38461560010910034\n",
      "Train Accuracy 84.77164887307237 | Test Accuracy 84.53822206848841\n",
      "Epoch 35 | Train loss 0.3405216932296753\n",
      "Train Accuracy 85.48339264531435 | Test Accuracy 84.46904185402974\n",
      "Epoch 36 | Train loss 0.42171356081962585\n",
      "Train Accuracy 85.61684460260973 | Test Accuracy 84.57281217571774\n",
      "Epoch 37 | Train loss 0.2910974621772766\n",
      "Train Accuracy 85.20166073546856 | Test Accuracy 84.08855067450709\n",
      "Epoch 38 | Train loss 0.37639138102531433\n",
      "Train Accuracy 85.00889679715303 | Test Accuracy 84.22691110342441\n",
      "Epoch 39 | Train loss 0.35281240940093994\n",
      "Train Accuracy 85.67615658362989 | Test Accuracy 84.57281217571774\n",
      "Epoch 40 | Train loss 0.3609669506549835\n",
      "Train Accuracy 85.80960854092527 | Test Accuracy 84.4344517468004\n",
      "Epoch 41 | Train loss 0.39647939801216125\n",
      "Train Accuracy 85.70581257413997 | Test Accuracy 84.46904185402974\n",
      "Epoch 42 | Train loss 0.3728874921798706\n",
      "Train Accuracy 85.95788849347569 | Test Accuracy 84.71117260463508\n",
      "Epoch 43 | Train loss 0.3239721953868866\n",
      "Train Accuracy 85.98754448398577 | Test Accuracy 85.4721549636804\n",
      "Epoch 44 | Train loss 0.3378868103027344\n",
      "Train Accuracy 86.07651245551602 | Test Accuracy 85.09166378415773\n",
      "Epoch 45 | Train loss 0.39880484342575073\n",
      "Train Accuracy 86.19513641755636 | Test Accuracy 85.12625389138707\n",
      "Epoch 46 | Train loss 0.3263256251811981\n",
      "Train Accuracy 86.1061684460261 | Test Accuracy 85.0570736769284\n",
      "Epoch 47 | Train loss 0.27489587664604187\n",
      "Train Accuracy 86.32858837485172 | Test Accuracy 85.61051539259772\n",
      "Epoch 48 | Train loss 0.30565783381462097\n",
      "Train Accuracy 86.06168446026096 | Test Accuracy 85.50674507090972\n",
      "Epoch 49 | Train loss 0.35734397172927856\n",
      "Train Accuracy 85.80960854092527 | Test Accuracy 84.36527153234175\n",
      "Epoch 50 | Train loss 0.21545912325382233\n",
      "Train Accuracy 86.43238434163702 | Test Accuracy 85.57592528536838\n",
      "Epoch 51 | Train loss 0.34517520666122437\n",
      "Train Accuracy 86.38790035587188 | Test Accuracy 85.54133517813905\n",
      "Epoch 52 | Train loss 0.2850815951824188\n",
      "Train Accuracy 86.52135231316726 | Test Accuracy 85.81805603597371\n",
      "Epoch 53 | Train loss 0.3991617262363434\n",
      "Train Accuracy 86.4620403321471 | Test Accuracy 85.85264614320305\n",
      "Epoch 54 | Train loss 0.2568340599536896\n",
      "Train Accuracy 85.89857651245552 | Test Accuracy 84.8495330335524\n",
      "Epoch 55 | Train loss 0.3879012167453766\n",
      "Train Accuracy 86.87722419928826 | Test Accuracy 85.57592528536838\n",
      "Epoch 56 | Train loss 0.3229958713054657\n",
      "Train Accuracy 86.56583629893238 | Test Accuracy 85.85264614320305\n",
      "Epoch 57 | Train loss 0.3019838035106659\n",
      "Train Accuracy 86.31376037959669 | Test Accuracy 85.29920442753372\n",
      "Epoch 58 | Train loss 0.4052610397338867\n",
      "Train Accuracy 86.81791221826809 | Test Accuracy 85.4721549636804\n",
      "Epoch 59 | Train loss 0.3194887638092041\n",
      "Train Accuracy 86.65480427046263 | Test Accuracy 85.74887582151504\n",
      "Epoch 60 | Train loss 0.20244917273521423\n",
      "Train Accuracy 86.72894424673784 | Test Accuracy 85.85264614320305\n",
      "Epoch 61 | Train loss 0.3167661726474762\n",
      "Train Accuracy 87.06998813760379 | Test Accuracy 86.1293670010377\n",
      "Epoch 62 | Train loss 0.20128512382507324\n",
      "Train Accuracy 86.92170818505338 | Test Accuracy 86.23313732272571\n",
      "Epoch 63 | Train loss 0.27327463030815125\n",
      "Train Accuracy 87.06998813760379 | Test Accuracy 86.26772742995503\n",
      "Epoch 64 | Train loss 0.2650033235549927\n",
      "Train Accuracy 87.21826809015421 | Test Accuracy 86.37149775164303\n",
      "Epoch 65 | Train loss 0.26866957545280457\n",
      "Train Accuracy 87.01067615658363 | Test Accuracy 85.95641646489103\n",
      "Epoch 66 | Train loss 0.31770628690719604\n",
      "Train Accuracy 86.98102016607353 | Test Accuracy 86.3369076444137\n",
      "Epoch 67 | Train loss 0.22878007590770721\n",
      "Train Accuracy 87.44068801897983 | Test Accuracy 86.6482186094777\n",
      "Epoch 68 | Train loss 0.2872190475463867\n",
      "Train Accuracy 86.09134045077106 | Test Accuracy 85.12625389138707\n",
      "Epoch 69 | Train loss 0.27810800075531006\n",
      "Train Accuracy 87.5 | Test Accuracy 86.71739882393635\n",
      "Epoch 70 | Train loss 0.30871036648750305\n",
      "Train Accuracy 87.144128113879 | Test Accuracy 85.85264614320305\n",
      "Epoch 71 | Train loss 0.21155604720115662\n",
      "Train Accuracy 87.6779359430605 | Test Accuracy 86.50985818056036\n",
      "Epoch 72 | Train loss 0.3830888867378235\n",
      "Train Accuracy 87.4258600237248 | Test Accuracy 86.50985818056036\n",
      "Epoch 73 | Train loss 0.27385562658309937\n",
      "Train Accuracy 87.44068801897983 | Test Accuracy 86.61362850224835\n",
      "Epoch 74 | Train loss 0.21176601946353912\n",
      "Train Accuracy 87.69276393831554 | Test Accuracy 87.23625043237634\n",
      "Epoch 75 | Train loss 0.395679771900177\n",
      "Train Accuracy 87.5 | Test Accuracy 87.06329989622968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train loss 0.2874738574028015\n",
      "Train Accuracy 87.5741399762752 | Test Accuracy 86.40608785887235\n",
      "Epoch 77 | Train loss 0.31146079301834106\n",
      "Train Accuracy 87.76690391459074 | Test Accuracy 87.23625043237634\n",
      "Epoch 78 | Train loss 0.30428311228752136\n",
      "Train Accuracy 87.79655990510084 | Test Accuracy 87.44379107575233\n",
      "Epoch 79 | Train loss 0.22341381013393402\n",
      "Train Accuracy 87.97449584816133 | Test Accuracy 86.99411968177101\n",
      "Epoch 80 | Train loss 0.30001357197761536\n",
      "Train Accuracy 87.95966785290629 | Test Accuracy 87.37461086129366\n",
      "Epoch 81 | Train loss 0.3173699378967285\n",
      "Train Accuracy 87.90035587188612 | Test Accuracy 87.40920096852301\n",
      "Epoch 82 | Train loss 0.2565793991088867\n",
      "Train Accuracy 88.1376037959668 | Test Accuracy 87.23625043237634\n",
      "Epoch 83 | Train loss 0.24362696707248688\n",
      "Train Accuracy 88.22657176749703 | Test Accuracy 87.47838118298166\n",
      "Epoch 84 | Train loss 0.2315070778131485\n",
      "Train Accuracy 88.5379596678529 | Test Accuracy 87.96264268419232\n",
      "Epoch 85 | Train loss 0.28670480847358704\n",
      "Train Accuracy 88.38967971530249 | Test Accuracy 87.65133171912834\n",
      "Epoch 86 | Train loss 0.22070366144180298\n",
      "Train Accuracy 88.07829181494662 | Test Accuracy 86.99411968177101\n",
      "Epoch 87 | Train loss 0.444886714220047\n",
      "Train Accuracy 88.43416370106762 | Test Accuracy 88.03182289865099\n",
      "Epoch 88 | Train loss 0.13575290143489838\n",
      "Train Accuracy 88.87900355871886 | Test Accuracy 88.20477343479764\n",
      "Epoch 89 | Train loss 0.25937649607658386\n",
      "Train Accuracy 88.41933570581257 | Test Accuracy 87.96264268419232\n",
      "Epoch 90 | Train loss 0.20533710718154907\n",
      "Train Accuracy 89.1755634638197 | Test Accuracy 88.86198547215496\n",
      "Epoch 91 | Train loss 0.31802311539649963\n",
      "Train Accuracy 89.10142348754448 | Test Accuracy 89.0003459010723\n",
      "Epoch 92 | Train loss 0.3755708634853363\n",
      "Train Accuracy 89.32384341637011 | Test Accuracy 88.72362504323763\n",
      "Epoch 93 | Train loss 0.28667882084846497\n",
      "Train Accuracy 89.24970344009489 | Test Accuracy 89.0003459010723\n",
      "Epoch 94 | Train loss 0.22894386947155\n",
      "Train Accuracy 89.47212336892052 | Test Accuracy 88.86198547215496\n",
      "Epoch 95 | Train loss 0.2656302750110626\n",
      "Train Accuracy 89.22004744958481 | Test Accuracy 89.17329643721895\n",
      "Epoch 96 | Train loss 0.35414615273475647\n",
      "Train Accuracy 89.4276393831554 | Test Accuracy 88.86198547215496\n",
      "Epoch 97 | Train loss 0.3258523941040039\n",
      "Train Accuracy 88.5379596678529 | Test Accuracy 88.75821515046697\n",
      "Epoch 98 | Train loss 0.2424541413784027\n",
      "Train Accuracy 89.36832740213522 | Test Accuracy 89.0003459010723\n",
      "Epoch 99 | Train loss 0.14219367504119873\n",
      "Train Accuracy 90.24317912218268 | Test Accuracy 89.72673815288827\n",
      "Epoch 100 | Train loss 0.2763103246688843\n",
      "Train Accuracy 90.1097271648873 | Test Accuracy 89.72673815288827\n",
      "Epoch 101 | Train loss 0.3345133662223816\n",
      "Train Accuracy 90.34697508896798 | Test Accuracy 90.00345901072293\n",
      "Epoch 102 | Train loss 0.21055841445922852\n",
      "Train Accuracy 90.30249110320284 | Test Accuracy 89.69214804565894\n",
      "Epoch 103 | Train loss 0.2130204141139984\n",
      "Train Accuracy 89.81316725978647 | Test Accuracy 89.72673815288827\n",
      "Epoch 104 | Train loss 0.2390052229166031\n",
      "Train Accuracy 90.40628706998814 | Test Accuracy 90.31476997578693\n",
      "Epoch 105 | Train loss 0.32012316584587097\n",
      "Train Accuracy 90.27283511269276 | Test Accuracy 89.58837772397095\n",
      "Epoch 106 | Train loss 0.29704028367996216\n",
      "Train Accuracy 90.58422301304864 | Test Accuracy 90.34936008301626\n",
      "Epoch 107 | Train loss 0.2450922131538391\n",
      "Train Accuracy 89.59074733096085 | Test Accuracy 89.17329643721895\n",
      "Epoch 108 | Train loss 0.1434425264596939\n",
      "Train Accuracy 90.49525504151839 | Test Accuracy 90.41854029747492\n",
      "Epoch 109 | Train loss 0.26874738931655884\n",
      "Train Accuracy 90.717674970344 | Test Accuracy 90.24558976132826\n",
      "Epoch 110 | Train loss 0.2223616987466812\n",
      "Train Accuracy 90.68801897983393 | Test Accuracy 89.89968868903495\n",
      "Epoch 111 | Train loss 0.27522507309913635\n",
      "Train Accuracy 90.73250296559905 | Test Accuracy 90.52231061916291\n",
      "Epoch 112 | Train loss 0.13205689191818237\n",
      "Train Accuracy 90.95492289442467 | Test Accuracy 90.59149083362158\n",
      "Epoch 113 | Train loss 0.14430660009384155\n",
      "Train Accuracy 90.5693950177936 | Test Accuracy 90.21099965409893\n",
      "Epoch 114 | Train loss 0.22517342865467072\n",
      "Train Accuracy 90.55456702253856 | Test Accuracy 89.51919750951228\n",
      "Epoch 115 | Train loss 0.13490094244480133\n",
      "Train Accuracy 90.25800711743773 | Test Accuracy 89.51919750951228\n",
      "Epoch 116 | Train loss 0.16397947072982788\n",
      "Train Accuracy 90.62870699881375 | Test Accuracy 89.9688689034936\n",
      "Epoch 117 | Train loss 0.23630648851394653\n",
      "Train Accuracy 90.55456702253856 | Test Accuracy 90.72985126253892\n",
      "Epoch 118 | Train loss 0.17636539041996002\n",
      "Train Accuracy 90.76215895610913 | Test Accuracy 90.38395019024559\n",
      "Epoch 119 | Train loss 0.18335680663585663\n",
      "Train Accuracy 90.91043890865956 | Test Accuracy 90.34936008301626\n",
      "Epoch 120 | Train loss 0.2267926186323166\n",
      "Train Accuracy 91.14768683274022 | Test Accuracy 90.34936008301626\n",
      "Epoch 121 | Train loss 0.21640676259994507\n",
      "Train Accuracy 90.89561091340451 | Test Accuracy 90.38395019024559\n",
      "Epoch 122 | Train loss 0.2186960130929947\n",
      "Train Accuracy 90.45077105575326 | Test Accuracy 89.93427879626427\n",
      "Epoch 123 | Train loss 0.18232010304927826\n",
      "Train Accuracy 91.19217081850533 | Test Accuracy 90.48772051193359\n",
      "Epoch 124 | Train loss 0.21897143125534058\n",
      "Train Accuracy 90.36180308422301 | Test Accuracy 89.27706675890695\n",
      "Epoch 125 | Train loss 0.2932586967945099\n",
      "Train Accuracy 91.29596678529063 | Test Accuracy 90.76444136976825\n",
      "Epoch 126 | Train loss 0.15903246402740479\n",
      "Train Accuracy 91.16251482799525 | Test Accuracy 90.72985126253892\n",
      "Epoch 127 | Train loss 0.25572827458381653\n",
      "Train Accuracy 90.98457888493475 | Test Accuracy 90.76444136976825\n",
      "Epoch 128 | Train loss 0.19122084975242615\n",
      "Train Accuracy 91.28113879003558 | Test Accuracy 90.66067104808025\n",
      "Epoch 129 | Train loss 0.1851729303598404\n",
      "Train Accuracy 90.83629893238434 | Test Accuracy 90.31476997578693\n",
      "Epoch 130 | Train loss 0.1281876415014267\n",
      "Train Accuracy 90.88078291814946 | Test Accuracy 90.2801798685576\n",
      "Epoch 131 | Train loss 0.24713096022605896\n",
      "Train Accuracy 91.34045077105574 | Test Accuracy 90.93739190591491\n",
      "Epoch 132 | Train loss 0.14484061300754547\n",
      "Train Accuracy 91.2514827995255 | Test Accuracy 90.86821169145625\n",
      "Epoch 133 | Train loss 0.24372531473636627\n",
      "Train Accuracy 91.2514827995255 | Test Accuracy 90.66067104808025\n",
      "Epoch 134 | Train loss 0.3127773106098175\n",
      "Train Accuracy 91.02906287069989 | Test Accuracy 90.66067104808025\n",
      "Epoch 135 | Train loss 0.20034241676330566\n",
      "Train Accuracy 90.73250296559905 | Test Accuracy 90.07263922518159\n",
      "Epoch 136 | Train loss 0.2152673751115799\n",
      "Train Accuracy 90.96975088967972 | Test Accuracy 90.10722933241094\n",
      "Epoch 137 | Train loss 0.20616202056407928\n",
      "Train Accuracy 91.02906287069989 | Test Accuracy 90.69526115530958\n",
      "Epoch 138 | Train loss 0.2456119954586029\n",
      "Train Accuracy 90.6435349940688 | Test Accuracy 89.93427879626427\n",
      "Epoch 139 | Train loss 0.23736706376075745\n",
      "Train Accuracy 91.3552787663108 | Test Accuracy 90.52231061916291\n",
      "Epoch 140 | Train loss 0.17867180705070496\n",
      "Train Accuracy 90.77698695136418 | Test Accuracy 90.17640954686959\n",
      "Epoch 141 | Train loss 0.1617899090051651\n",
      "Train Accuracy 91.66666666666666 | Test Accuracy 90.31476997578693\n",
      "Epoch 142 | Train loss 0.34415656328201294\n",
      "Train Accuracy 91.48873072360617 | Test Accuracy 90.8336215842269\n",
      "Epoch 143 | Train loss 0.2049865573644638\n",
      "Train Accuracy 91.39976275207592 | Test Accuracy 90.69526115530958\n",
      "Epoch 144 | Train loss 0.18780498206615448\n",
      "Train Accuracy 91.11803084223014 | Test Accuracy 90.48772051193359\n",
      "Epoch 145 | Train loss 0.20361541211605072\n",
      "Train Accuracy 91.44424673784104 | Test Accuracy 90.76444136976825\n",
      "Epoch 146 | Train loss 0.20427441596984863\n",
      "Train Accuracy 91.72597864768683 | Test Accuracy 90.76444136976825\n",
      "Epoch 147 | Train loss 0.23570193350315094\n",
      "Train Accuracy 91.38493475682088 | Test Accuracy 90.62608094085091\n",
      "Epoch 148 | Train loss 0.22349166870117188\n",
      "Train Accuracy 91.54804270462633 | Test Accuracy 90.93739190591491\n",
      "Epoch 149 | Train loss 0.2393394410610199\n",
      "Train Accuracy 91.45907473309609 | Test Accuracy 90.69526115530958\n",
      "Epoch 150 | Train loss 0.22980274260044098\n",
      "Train Accuracy 91.56287069988137 | Test Accuracy 91.0411622276029\n",
      "Epoch 151 | Train loss 0.22678838670253754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 91.51838671411625 | Test Accuracy 90.66067104808025\n",
      "Epoch 152 | Train loss 0.20587629079818726\n",
      "Train Accuracy 91.65183867141162 | Test Accuracy 90.52231061916291\n",
      "Epoch 153 | Train loss 0.28129324316978455\n",
      "Train Accuracy 91.57769869513642 | Test Accuracy 90.38395019024559\n",
      "Epoch 154 | Train loss 0.22043509781360626\n",
      "Train Accuracy 91.31079478054566 | Test Accuracy 90.2801798685576\n",
      "Epoch 155 | Train loss 0.1489722579717636\n",
      "Train Accuracy 91.1773428232503 | Test Accuracy 90.38395019024559\n",
      "Epoch 156 | Train loss 0.1918436884880066\n",
      "Train Accuracy 91.50355871886121 | Test Accuracy 90.48772051193359\n",
      "Epoch 157 | Train loss 0.1510874629020691\n",
      "Train Accuracy 91.34045077105574 | Test Accuracy 90.41854029747492\n",
      "Epoch 158 | Train loss 0.24050162732601166\n",
      "Train Accuracy 91.59252669039147 | Test Accuracy 90.62608094085091\n",
      "Epoch 159 | Train loss 0.14495502412319183\n",
      "Train Accuracy 91.32562277580071 | Test Accuracy 90.72985126253892\n",
      "Epoch 160 | Train loss 0.15313830971717834\n",
      "Train Accuracy 91.59252669039147 | Test Accuracy 90.72985126253892\n",
      "Epoch 161 | Train loss 0.18593277037143707\n",
      "Train Accuracy 91.50355871886121 | Test Accuracy 90.45313040470425\n",
      "Epoch 162 | Train loss 0.3139519691467285\n",
      "Train Accuracy 91.41459074733096 | Test Accuracy 90.45313040470425\n",
      "Epoch 163 | Train loss 0.1480719894170761\n",
      "Train Accuracy 91.41459074733096 | Test Accuracy 90.48772051193359\n",
      "Epoch 164 | Train loss 0.15675760805606842\n",
      "Train Accuracy 91.56287069988137 | Test Accuracy 90.45313040470425\n",
      "Epoch 165 | Train loss 0.25649863481521606\n",
      "Train Accuracy 91.56287069988137 | Test Accuracy 90.55690072639226\n",
      "Epoch 166 | Train loss 0.15602082014083862\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 90.8336215842269\n",
      "Epoch 167 | Train loss 0.21375399827957153\n",
      "Train Accuracy 91.66666666666666 | Test Accuracy 90.48772051193359\n",
      "Epoch 168 | Train loss 0.13172435760498047\n",
      "Train Accuracy 91.59252669039147 | Test Accuracy 90.66067104808025\n",
      "Epoch 169 | Train loss 0.1704566329717636\n",
      "Train Accuracy 91.65183867141162 | Test Accuracy 90.93739190591491\n",
      "Epoch 170 | Train loss 0.19208864867687225\n",
      "Train Accuracy 91.47390272835113 | Test Accuracy 90.72985126253892\n",
      "Epoch 171 | Train loss 0.2177615612745285\n",
      "Train Accuracy 91.69632265717675 | Test Accuracy 90.59149083362158\n",
      "Epoch 172 | Train loss 0.23892074823379517\n",
      "Train Accuracy 91.50355871886121 | Test Accuracy 90.62608094085091\n",
      "Epoch 173 | Train loss 0.1550755351781845\n",
      "Train Accuracy 91.57769869513642 | Test Accuracy 90.52231061916291\n",
      "Epoch 174 | Train loss 0.17531052231788635\n",
      "Train Accuracy 90.83629893238434 | Test Accuracy 90.34936008301626\n",
      "Epoch 175 | Train loss 0.24282997846603394\n",
      "Train Accuracy 91.69632265717675 | Test Accuracy 90.79903147699758\n",
      "Epoch 176 | Train loss 0.1492539495229721\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 90.41854029747492\n",
      "Epoch 177 | Train loss 0.16560877859592438\n",
      "Train Accuracy 91.26631079478055 | Test Accuracy 90.59149083362158\n",
      "Epoch 178 | Train loss 0.22398562729358673\n",
      "Train Accuracy 90.89561091340451 | Test Accuracy 90.48772051193359\n",
      "Epoch 179 | Train loss 0.19130147993564606\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 90.79903147699758\n",
      "Epoch 180 | Train loss 0.2367236465215683\n",
      "Train Accuracy 90.49525504151839 | Test Accuracy 89.72673815288827\n",
      "Epoch 181 | Train loss 0.22479277849197388\n",
      "Train Accuracy 91.87425860023724 | Test Accuracy 90.41854029747492\n",
      "Epoch 182 | Train loss 0.279281347990036\n",
      "Train Accuracy 91.82977461447213 | Test Accuracy 90.55690072639226\n",
      "Epoch 183 | Train loss 0.2790314853191376\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 90.38395019024559\n",
      "Epoch 184 | Train loss 0.1852404922246933\n",
      "Train Accuracy 91.05871886120997 | Test Accuracy 89.89968868903495\n",
      "Epoch 185 | Train loss 0.25139322876930237\n",
      "Train Accuracy 91.91874258600238 | Test Accuracy 90.62608094085091\n",
      "Epoch 186 | Train loss 0.21798205375671387\n",
      "Train Accuracy 91.34045077105574 | Test Accuracy 90.34936008301626\n",
      "Epoch 187 | Train loss 0.16325044631958008\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 91.07575233483225\n",
      "Epoch 188 | Train loss 0.36100059747695923\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.55690072639226\n",
      "Epoch 189 | Train loss 0.12402966618537903\n",
      "Train Accuracy 91.5332147093713 | Test Accuracy 90.21099965409893\n",
      "Epoch 190 | Train loss 0.21252727508544922\n",
      "Train Accuracy 91.19217081850533 | Test Accuracy 90.48772051193359\n",
      "Epoch 191 | Train loss 0.26681268215179443\n",
      "Train Accuracy 91.073546856465 | Test Accuracy 90.24558976132826\n",
      "Epoch 192 | Train loss 0.19237588346004486\n",
      "Train Accuracy 91.75563463819691 | Test Accuracy 90.55690072639226\n",
      "Epoch 193 | Train loss 0.1683024764060974\n",
      "Train Accuracy 91.47390272835113 | Test Accuracy 90.34936008301626\n",
      "Epoch 194 | Train loss 0.19588802754878998\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 90.93739190591491\n",
      "Epoch 195 | Train loss 0.24650068581104279\n",
      "Train Accuracy 91.82977461447213 | Test Accuracy 90.62608094085091\n",
      "Epoch 196 | Train loss 0.13697832822799683\n",
      "Train Accuracy 91.63701067615658 | Test Accuracy 90.69526115530958\n",
      "Epoch 197 | Train loss 0.1631729006767273\n",
      "Train Accuracy 91.74080664294188 | Test Accuracy 90.86821169145625\n",
      "Epoch 198 | Train loss 0.22510476410388947\n",
      "Train Accuracy 91.77046263345196 | Test Accuracy 90.38395019024559\n",
      "Epoch 199 | Train loss 0.20623038709163666\n",
      "Train Accuracy 91.87425860023724 | Test Accuracy 90.59149083362158\n",
      "Epoch 200 | Train loss 0.21044497191905975\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 90.41854029747492\n",
      "Epoch 201 | Train loss 0.25121772289276123\n",
      "Train Accuracy 90.5693950177936 | Test Accuracy 90.21099965409893\n",
      "Epoch 202 | Train loss 0.24259771406650543\n",
      "Train Accuracy 91.6814946619217 | Test Accuracy 90.2801798685576\n",
      "Epoch 203 | Train loss 0.22021354734897614\n",
      "Train Accuracy 91.39976275207592 | Test Accuracy 90.76444136976825\n",
      "Epoch 204 | Train loss 0.18991822004318237\n",
      "Train Accuracy 91.3552787663108 | Test Accuracy 90.2801798685576\n",
      "Epoch 205 | Train loss 0.2868758738040924\n",
      "Train Accuracy 91.75563463819691 | Test Accuracy 90.69526115530958\n",
      "Epoch 206 | Train loss 0.16554656624794006\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 90.69526115530958\n",
      "Epoch 207 | Train loss 0.22381223738193512\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.66067104808025\n",
      "Epoch 208 | Train loss 0.14610791206359863\n",
      "Train Accuracy 91.88908659549229 | Test Accuracy 90.79903147699758\n",
      "Epoch 209 | Train loss 0.0925331637263298\n",
      "Train Accuracy 91.82977461447213 | Test Accuracy 91.00657212037358\n",
      "Epoch 210 | Train loss 0.1447264701128006\n",
      "Train Accuracy 91.84460260972716 | Test Accuracy 90.41854029747492\n",
      "Epoch 211 | Train loss 0.15878871083259583\n",
      "Train Accuracy 91.51838671411625 | Test Accuracy 90.24558976132826\n",
      "Epoch 212 | Train loss 0.24120455980300903\n",
      "Train Accuracy 91.23665480427047 | Test Accuracy 90.8336215842269\n",
      "Epoch 213 | Train loss 0.18776574730873108\n",
      "Train Accuracy 91.6073546856465 | Test Accuracy 90.34936008301626\n",
      "Epoch 214 | Train loss 0.18422077596187592\n",
      "Train Accuracy 91.32562277580071 | Test Accuracy 89.93427879626427\n",
      "Epoch 215 | Train loss 0.2161739468574524\n",
      "Train Accuracy 91.48873072360617 | Test Accuracy 90.97198201314424\n",
      "Epoch 216 | Train loss 0.25735902786254883\n",
      "Train Accuracy 91.91874258600238 | Test Accuracy 90.45313040470425\n",
      "Epoch 217 | Train loss 0.23443573713302612\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 90.52231061916291\n",
      "Epoch 218 | Train loss 0.23392972350120544\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.72985126253892\n",
      "Epoch 219 | Train loss 0.16151593625545502\n",
      "Train Accuracy 92.00771055753262 | Test Accuracy 90.86821169145625\n",
      "Epoch 220 | Train loss 0.17044484615325928\n",
      "Train Accuracy 91.65183867141162 | Test Accuracy 90.90280179868557\n",
      "Epoch 221 | Train loss 0.17234764993190765\n",
      "Train Accuracy 91.94839857651246 | Test Accuracy 90.59149083362158\n",
      "Epoch 222 | Train loss 0.13599775731563568\n",
      "Train Accuracy 91.37010676156584 | Test Accuracy 90.10722933241094\n",
      "Epoch 223 | Train loss 0.26460030674934387\n",
      "Train Accuracy 91.51838671411625 | Test Accuracy 90.90280179868557\n",
      "Epoch 224 | Train loss 0.15656305849552155\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.66067104808025\n",
      "Epoch 225 | Train loss 0.21434515714645386\n",
      "Train Accuracy 91.74080664294188 | Test Accuracy 90.48772051193359\n",
      "Epoch 226 | Train loss 0.1543191820383072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 91.80011862396204 | Test Accuracy 90.55690072639226\n",
      "Epoch 227 | Train loss 0.16418956220149994\n",
      "Train Accuracy 91.63701067615658 | Test Accuracy 90.93739190591491\n",
      "Epoch 228 | Train loss 0.22120310366153717\n",
      "Train Accuracy 92.12633451957295 | Test Accuracy 90.97198201314424\n",
      "Epoch 229 | Train loss 0.20863653719425201\n",
      "Train Accuracy 91.77046263345196 | Test Accuracy 90.52231061916291\n",
      "Epoch 230 | Train loss 0.16627417504787445\n",
      "Train Accuracy 91.94839857651246 | Test Accuracy 90.76444136976825\n",
      "Epoch 231 | Train loss 0.19830092787742615\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 90.55690072639226\n",
      "Epoch 232 | Train loss 0.1661868691444397\n",
      "Train Accuracy 91.45907473309609 | Test Accuracy 90.97198201314424\n",
      "Epoch 233 | Train loss 0.1576758474111557\n",
      "Train Accuracy 91.85943060498221 | Test Accuracy 90.55690072639226\n",
      "Epoch 234 | Train loss 0.16058875620365143\n",
      "Train Accuracy 91.63701067615658 | Test Accuracy 90.79903147699758\n",
      "Epoch 235 | Train loss 0.17483459413051605\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 90.59149083362158\n",
      "Epoch 236 | Train loss 0.29156187176704407\n",
      "Train Accuracy 91.81494661921708 | Test Accuracy 90.41854029747492\n",
      "Epoch 237 | Train loss 0.1664305031299591\n",
      "Train Accuracy 92.06702253855279 | Test Accuracy 90.66067104808025\n",
      "Epoch 238 | Train loss 0.2027990221977234\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 90.52231061916291\n",
      "Epoch 239 | Train loss 0.20452341437339783\n",
      "Train Accuracy 92.2153024911032 | Test Accuracy 90.72985126253892\n",
      "Epoch 240 | Train loss 0.18227659165859222\n",
      "Train Accuracy 92.09667852906287 | Test Accuracy 90.55690072639226\n",
      "Epoch 241 | Train loss 0.27285659313201904\n",
      "Train Accuracy 92.00771055753262 | Test Accuracy 90.52231061916291\n",
      "Epoch 242 | Train loss 0.15585416555404663\n",
      "Train Accuracy 91.93357058125741 | Test Accuracy 91.0411622276029\n",
      "Epoch 243 | Train loss 0.24612568318843842\n",
      "Train Accuracy 91.02906287069989 | Test Accuracy 90.59149083362158\n",
      "Epoch 244 | Train loss 0.21626953780651093\n",
      "Train Accuracy 92.00771055753262 | Test Accuracy 90.38395019024559\n",
      "Epoch 245 | Train loss 0.24352194368839264\n",
      "Train Accuracy 92.1115065243179 | Test Accuracy 90.8336215842269\n",
      "Epoch 246 | Train loss 0.3519822657108307\n",
      "Train Accuracy 91.96322657176749 | Test Accuracy 90.59149083362158\n",
      "Epoch 247 | Train loss 0.20328940451145172\n",
      "Train Accuracy 91.90391459074732 | Test Accuracy 90.76444136976825\n",
      "Epoch 248 | Train loss 0.19990892708301544\n",
      "Train Accuracy 91.84460260972716 | Test Accuracy 90.48772051193359\n",
      "Epoch 249 | Train loss 0.14822567999362946\n",
      "Train Accuracy 91.85943060498221 | Test Accuracy 91.07575233483225\n",
      "Epoch 250 | Train loss 0.13938277959823608\n",
      "Train Accuracy 92.06702253855279 | Test Accuracy 90.69526115530958\n",
      "Epoch 251 | Train loss 0.1578165888786316\n",
      "Train Accuracy 92.15599051008304 | Test Accuracy 90.69526115530958\n",
      "Epoch 252 | Train loss 0.09482559561729431\n",
      "Train Accuracy 92.09667852906287 | Test Accuracy 90.76444136976825\n",
      "Epoch 253 | Train loss 0.21280856430530548\n",
      "Train Accuracy 91.5332147093713 | Test Accuracy 90.76444136976825\n",
      "Epoch 254 | Train loss 0.23247526586055756\n",
      "Train Accuracy 92.141162514828 | Test Accuracy 90.41854029747492\n",
      "Epoch 255 | Train loss 0.20731301605701447\n",
      "Train Accuracy 92.09667852906287 | Test Accuracy 90.48772051193359\n",
      "Epoch 256 | Train loss 0.24727778136730194\n",
      "Train Accuracy 91.88908659549229 | Test Accuracy 90.97198201314424\n",
      "Epoch 257 | Train loss 0.19381675124168396\n",
      "Train Accuracy 92.05219454329774 | Test Accuracy 90.76444136976825\n",
      "Epoch 258 | Train loss 0.2966144382953644\n",
      "Train Accuracy 92.09667852906287 | Test Accuracy 90.76444136976825\n",
      "Epoch 259 | Train loss 0.10957541316747665\n",
      "Train Accuracy 92.06702253855279 | Test Accuracy 90.90280179868557\n",
      "Epoch 260 | Train loss 0.2863154709339142\n",
      "Train Accuracy 91.65183867141162 | Test Accuracy 90.48772051193359\n",
      "Epoch 261 | Train loss 0.0998004674911499\n",
      "Train Accuracy 91.5332147093713 | Test Accuracy 90.76444136976825\n",
      "Epoch 262 | Train loss 0.1991460770368576\n",
      "Train Accuracy 92.02253855278767 | Test Accuracy 90.38395019024559\n",
      "Epoch 263 | Train loss 0.2151971459388733\n",
      "Train Accuracy 91.87425860023724 | Test Accuracy 90.90280179868557\n",
      "Epoch 264 | Train loss 0.13602600991725922\n",
      "Train Accuracy 92.20047449584816 | Test Accuracy 90.79903147699758\n",
      "Epoch 265 | Train loss 0.20357750356197357\n",
      "Train Accuracy 91.62218268090155 | Test Accuracy 91.0411622276029\n",
      "Epoch 266 | Train loss 0.26281407475471497\n",
      "Train Accuracy 91.81494661921708 | Test Accuracy 90.34936008301626\n",
      "Epoch 267 | Train loss 0.22719021141529083\n",
      "Train Accuracy 91.84460260972716 | Test Accuracy 90.38395019024559\n",
      "Epoch 268 | Train loss 0.19805699586868286\n",
      "Train Accuracy 91.90391459074732 | Test Accuracy 91.11034244206157\n",
      "Epoch 269 | Train loss 0.1733621209859848\n",
      "Train Accuracy 92.27461447212337 | Test Accuracy 90.8336215842269\n",
      "Epoch 270 | Train loss 0.13343100249767303\n",
      "Train Accuracy 91.91874258600238 | Test Accuracy 90.17640954686959\n",
      "Epoch 271 | Train loss 0.162057027220726\n",
      "Train Accuracy 91.01423487544484 | Test Accuracy 90.34936008301626\n",
      "Epoch 272 | Train loss 0.21660453081130981\n",
      "Train Accuracy 92.17081850533808 | Test Accuracy 90.79903147699758\n",
      "Epoch 273 | Train loss 0.2536570429801941\n",
      "Train Accuracy 91.59252669039147 | Test Accuracy 90.17640954686959\n",
      "Epoch 274 | Train loss 0.2547822892665863\n",
      "Train Accuracy 92.25978647686833 | Test Accuracy 90.93739190591491\n",
      "Epoch 275 | Train loss 0.18533402681350708\n",
      "Train Accuracy 92.24495848161328 | Test Accuracy 90.76444136976825\n",
      "Epoch 276 | Train loss 0.13366971909999847\n",
      "Train Accuracy 91.90391459074732 | Test Accuracy 90.97198201314424\n",
      "Epoch 277 | Train loss 0.14970532059669495\n",
      "Train Accuracy 92.18564650059312 | Test Accuracy 90.76444136976825\n",
      "Epoch 278 | Train loss 0.26601240038871765\n",
      "Train Accuracy 91.50355871886121 | Test Accuracy 90.90280179868557\n",
      "Epoch 279 | Train loss 0.2513185739517212\n",
      "Train Accuracy 92.27461447212337 | Test Accuracy 90.86821169145625\n",
      "Epoch 280 | Train loss 0.24766696989536285\n",
      "Train Accuracy 91.78529062870699 | Test Accuracy 91.17952265652023\n",
      "Epoch 281 | Train loss 0.24047483503818512\n",
      "Train Accuracy 91.85943060498221 | Test Accuracy 90.8336215842269\n",
      "Epoch 282 | Train loss 0.155173197388649\n",
      "Train Accuracy 92.05219454329774 | Test Accuracy 91.28329297820824\n",
      "Epoch 283 | Train loss 0.21466656029224396\n",
      "Train Accuracy 92.23013048635823 | Test Accuracy 90.97198201314424\n",
      "Epoch 284 | Train loss 0.12426202744245529\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 90.90280179868557\n",
      "Epoch 285 | Train loss 0.1667679250240326\n",
      "Train Accuracy 92.18564650059312 | Test Accuracy 90.69526115530958\n",
      "Epoch 286 | Train loss 0.19306860864162445\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 90.8336215842269\n",
      "Epoch 287 | Train loss 0.17406928539276123\n",
      "Train Accuracy 92.2153024911032 | Test Accuracy 90.90280179868557\n",
      "Epoch 288 | Train loss 0.1757623702287674\n",
      "Train Accuracy 92.09667852906287 | Test Accuracy 91.00657212037358\n",
      "Epoch 289 | Train loss 0.13213883340358734\n",
      "Train Accuracy 92.1115065243179 | Test Accuracy 90.69526115530958\n",
      "Epoch 290 | Train loss 0.1617855578660965\n",
      "Train Accuracy 92.18564650059312 | Test Accuracy 90.59149083362158\n",
      "Epoch 291 | Train loss 0.18103934824466705\n",
      "Train Accuracy 91.7111506524318 | Test Accuracy 91.07575233483225\n",
      "Epoch 292 | Train loss 0.22934311628341675\n",
      "Train Accuracy 92.02253855278767 | Test Accuracy 90.66067104808025\n",
      "Epoch 293 | Train loss 0.18343688547611237\n",
      "Train Accuracy 91.93357058125741 | Test Accuracy 91.00657212037358\n",
      "Epoch 294 | Train loss 0.1735960841178894\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 90.86821169145625\n",
      "Epoch 295 | Train loss 0.1716993749141693\n",
      "Train Accuracy 90.76215895610913 | Test Accuracy 90.10722933241094\n",
      "Epoch 296 | Train loss 0.20232070982456207\n",
      "Train Accuracy 92.20047449584816 | Test Accuracy 90.72985126253892\n",
      "Epoch 297 | Train loss 0.2553431987762451\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 90.8336215842269\n",
      "Epoch 298 | Train loss 0.1632663607597351\n",
      "Train Accuracy 92.08185053380782 | Test Accuracy 90.93739190591491\n",
      "Epoch 299 | Train loss 0.14491243660449982\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 90.8336215842269\n",
      "Epoch 300 | Train loss 0.15526582300662994\n",
      "Train Accuracy 92.20047449584816 | Test Accuracy 90.79903147699758\n",
      "Epoch 301 | Train loss 0.2774311602115631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 92.1115065243179 | Test Accuracy 91.00657212037358\n",
      "Epoch 302 | Train loss 0.1544271856546402\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 91.21411276374957\n",
      "Epoch 303 | Train loss 0.1717686802148819\n",
      "Train Accuracy 92.06702253855279 | Test Accuracy 90.79903147699758\n",
      "Epoch 304 | Train loss 0.1569875329732895\n",
      "Train Accuracy 91.84460260972716 | Test Accuracy 91.0411622276029\n",
      "Epoch 305 | Train loss 0.13106434047222137\n",
      "Train Accuracy 92.3932384341637 | Test Accuracy 90.90280179868557\n",
      "Epoch 306 | Train loss 0.19394582509994507\n",
      "Train Accuracy 92.05219454329774 | Test Accuracy 90.69526115530958\n",
      "Epoch 307 | Train loss 0.21828192472457886\n",
      "Train Accuracy 91.69632265717675 | Test Accuracy 90.86821169145625\n",
      "Epoch 308 | Train loss 0.16645920276641846\n",
      "Train Accuracy 92.17081850533808 | Test Accuracy 90.59149083362158\n",
      "Epoch 309 | Train loss 0.17578567564487457\n",
      "Train Accuracy 92.141162514828 | Test Accuracy 90.79903147699758\n",
      "Epoch 310 | Train loss 0.14454589784145355\n",
      "Train Accuracy 91.93357058125741 | Test Accuracy 91.11034244206157\n",
      "Epoch 311 | Train loss 0.2393297255039215\n",
      "Train Accuracy 92.30427046263345 | Test Accuracy 90.86821169145625\n",
      "Epoch 312 | Train loss 0.1774120181798935\n",
      "Train Accuracy 92.40806642941874 | Test Accuracy 90.66067104808025\n",
      "Epoch 313 | Train loss 0.25499725341796875\n",
      "Train Accuracy 92.28944246737841 | Test Accuracy 90.76444136976825\n",
      "Epoch 314 | Train loss 0.20371127128601074\n",
      "Train Accuracy 92.3932384341637 | Test Accuracy 90.69526115530958\n",
      "Epoch 315 | Train loss 0.16897238790988922\n",
      "Train Accuracy 91.66666666666666 | Test Accuracy 90.79903147699758\n",
      "Epoch 316 | Train loss 0.14109909534454346\n",
      "Train Accuracy 91.90391459074732 | Test Accuracy 90.55690072639226\n",
      "Epoch 317 | Train loss 0.21954987943172455\n",
      "Train Accuracy 92.40806642941874 | Test Accuracy 90.97198201314424\n",
      "Epoch 318 | Train loss 0.18912643194198608\n",
      "Train Accuracy 92.1115065243179 | Test Accuracy 90.97198201314424\n",
      "Epoch 319 | Train loss 0.1496596783399582\n",
      "Train Accuracy 92.17081850533808 | Test Accuracy 91.2487028709789\n",
      "Epoch 320 | Train loss 0.2327338606119156\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 90.76444136976825\n",
      "Epoch 321 | Train loss 0.17981669306755066\n",
      "Train Accuracy 92.46737841043891 | Test Accuracy 91.07575233483225\n",
      "Epoch 322 | Train loss 0.1412690281867981\n",
      "Train Accuracy 92.20047449584816 | Test Accuracy 91.0411622276029\n",
      "Epoch 323 | Train loss 0.1315767616033554\n",
      "Train Accuracy 91.37010676156584 | Test Accuracy 90.17640954686959\n",
      "Epoch 324 | Train loss 0.257069855928421\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 90.41854029747492\n",
      "Epoch 325 | Train loss 0.2237098067998886\n",
      "Train Accuracy 92.36358244365361 | Test Accuracy 90.48772051193359\n",
      "Epoch 326 | Train loss 0.16461043059825897\n",
      "Train Accuracy 92.40806642941874 | Test Accuracy 91.1449325492909\n",
      "Epoch 327 | Train loss 0.1893197000026703\n",
      "Train Accuracy 92.40806642941874 | Test Accuracy 90.8336215842269\n",
      "Epoch 328 | Train loss 0.16343341767787933\n",
      "Train Accuracy 92.2153024911032 | Test Accuracy 91.21411276374957\n",
      "Epoch 329 | Train loss 0.2953701615333557\n",
      "Train Accuracy 92.52669039145907 | Test Accuracy 90.97198201314424\n",
      "Epoch 330 | Train loss 0.13554158806800842\n",
      "Train Accuracy 92.06702253855279 | Test Accuracy 91.35247319266689\n",
      "Epoch 331 | Train loss 0.20858898758888245\n",
      "Train Accuracy 92.31909845788849 | Test Accuracy 90.93739190591491\n",
      "Epoch 332 | Train loss 0.08101451396942139\n",
      "Train Accuracy 92.17081850533808 | Test Accuracy 90.93739190591491\n",
      "Epoch 333 | Train loss 0.20174477994441986\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 90.8336215842269\n",
      "Epoch 334 | Train loss 0.08606212586164474\n",
      "Train Accuracy 92.24495848161328 | Test Accuracy 91.2487028709789\n",
      "Epoch 335 | Train loss 0.1201050728559494\n",
      "Train Accuracy 92.28944246737841 | Test Accuracy 90.79903147699758\n",
      "Epoch 336 | Train loss 0.24046780169010162\n",
      "Train Accuracy 92.141162514828 | Test Accuracy 90.52231061916291\n",
      "Epoch 337 | Train loss 0.13356922566890717\n",
      "Train Accuracy 92.43772241992883 | Test Accuracy 91.07575233483225\n",
      "Epoch 338 | Train loss 0.21104808151721954\n",
      "Train Accuracy 92.42289442467379 | Test Accuracy 91.31788308543757\n",
      "Epoch 339 | Train loss 0.1761777400970459\n",
      "Train Accuracy 92.43772241992883 | Test Accuracy 91.07575233483225\n",
      "Epoch 340 | Train loss 0.17442940175533295\n",
      "Train Accuracy 92.3932384341637 | Test Accuracy 91.11034244206157\n",
      "Epoch 341 | Train loss 0.1877988874912262\n",
      "Train Accuracy 92.48220640569394 | Test Accuracy 91.31788308543757\n",
      "Epoch 342 | Train loss 0.15090392529964447\n",
      "Train Accuracy 92.48220640569394 | Test Accuracy 90.72985126253892\n",
      "Epoch 343 | Train loss 0.1694791316986084\n",
      "Train Accuracy 92.00771055753262 | Test Accuracy 91.1449325492909\n",
      "Epoch 344 | Train loss 0.21451912820339203\n",
      "Train Accuracy 92.36358244365361 | Test Accuracy 90.97198201314424\n",
      "Epoch 345 | Train loss 0.22590979933738708\n",
      "Train Accuracy 92.45255041518386 | Test Accuracy 91.11034244206157\n",
      "Epoch 346 | Train loss 0.19305185973644257\n",
      "Train Accuracy 92.40806642941874 | Test Accuracy 90.97198201314424\n",
      "Epoch 347 | Train loss 0.22941561043262482\n",
      "Train Accuracy 92.20047449584816 | Test Accuracy 90.72985126253892\n",
      "Epoch 348 | Train loss 0.12796145677566528\n",
      "Train Accuracy 92.40806642941874 | Test Accuracy 91.17952265652023\n",
      "Epoch 349 | Train loss 0.09149176627397537\n",
      "Train Accuracy 92.40806642941874 | Test Accuracy 90.8336215842269\n",
      "Epoch 350 | Train loss 0.24592703580856323\n",
      "Train Accuracy 92.40806642941874 | Test Accuracy 90.8336215842269\n",
      "Epoch 351 | Train loss 0.1416887640953064\n",
      "Train Accuracy 91.74080664294188 | Test Accuracy 90.10722933241094\n",
      "Epoch 352 | Train loss 0.19419290125370026\n",
      "Train Accuracy 91.99288256227757 | Test Accuracy 91.28329297820824\n",
      "Epoch 353 | Train loss 0.2101583033800125\n",
      "Train Accuracy 92.45255041518386 | Test Accuracy 91.07575233483225\n",
      "Epoch 354 | Train loss 0.16031736135482788\n",
      "Train Accuracy 92.33392645314353 | Test Accuracy 90.97198201314424\n",
      "Epoch 355 | Train loss 0.23974522948265076\n",
      "Train Accuracy 92.46737841043891 | Test Accuracy 91.07575233483225\n",
      "Epoch 356 | Train loss 0.17514753341674805\n",
      "Train Accuracy 92.25978647686833 | Test Accuracy 91.0411622276029\n",
      "Epoch 357 | Train loss 0.17750698328018188\n",
      "Train Accuracy 92.24495848161328 | Test Accuracy 90.79903147699758\n",
      "Epoch 358 | Train loss 0.17533868551254272\n",
      "Train Accuracy 92.09667852906287 | Test Accuracy 90.69526115530958\n",
      "Epoch 359 | Train loss 0.16694360971450806\n",
      "Train Accuracy 92.60083036773428 | Test Accuracy 91.2487028709789\n",
      "Epoch 360 | Train loss 0.18315158784389496\n",
      "Train Accuracy 92.33392645314353 | Test Accuracy 91.42165340712556\n",
      "Epoch 361 | Train loss 0.1530568152666092\n",
      "Train Accuracy 92.49703440094899 | Test Accuracy 91.00657212037358\n",
      "Epoch 362 | Train loss 0.17030173540115356\n",
      "Train Accuracy 92.46737841043891 | Test Accuracy 91.31788308543757\n",
      "Epoch 363 | Train loss 0.15660220384597778\n",
      "Train Accuracy 92.33392645314353 | Test Accuracy 91.2487028709789\n",
      "Epoch 364 | Train loss 0.18041305243968964\n",
      "Train Accuracy 91.94839857651246 | Test Accuracy 90.45313040470425\n",
      "Epoch 365 | Train loss 0.21100692451000214\n",
      "Train Accuracy 92.45255041518386 | Test Accuracy 91.28329297820824\n",
      "Epoch 366 | Train loss 0.19663316011428833\n",
      "Train Accuracy 92.28944246737841 | Test Accuracy 90.69526115530958\n",
      "Epoch 367 | Train loss 0.2022145390510559\n",
      "Train Accuracy 91.38493475682088 | Test Accuracy 90.76444136976825\n",
      "Epoch 368 | Train loss 0.1287200003862381\n",
      "Train Accuracy 92.00771055753262 | Test Accuracy 91.38706329989623\n",
      "Epoch 369 | Train loss 0.24640417098999023\n",
      "Train Accuracy 92.36358244365361 | Test Accuracy 90.86821169145625\n",
      "Epoch 370 | Train loss 0.13569961488246918\n",
      "Train Accuracy 92.28944246737841 | Test Accuracy 90.62608094085091\n",
      "Epoch 371 | Train loss 0.16550606489181519\n",
      "Train Accuracy 92.54151838671412 | Test Accuracy 91.11034244206157\n",
      "Epoch 372 | Train loss 0.18376611173152924\n",
      "Train Accuracy 92.5711743772242 | Test Accuracy 91.1449325492909\n",
      "Epoch 373 | Train loss 0.24123534560203552\n",
      "Train Accuracy 92.61565836298932 | Test Accuracy 91.17952265652023\n",
      "Epoch 374 | Train loss 0.21934503316879272\n",
      "Train Accuracy 92.66014234875445 | Test Accuracy 91.59460394327222\n",
      "Epoch 375 | Train loss 0.19260863959789276\n",
      "Train Accuracy 92.55634638196916 | Test Accuracy 90.90280179868557\n",
      "Epoch 376 | Train loss 0.1652369648218155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 92.3932384341637 | Test Accuracy 91.38706329989623\n",
      "Epoch 377 | Train loss 0.0814720094203949\n",
      "Train Accuracy 92.55634638196916 | Test Accuracy 91.17952265652023\n",
      "Epoch 378 | Train loss 0.19921168684959412\n",
      "Train Accuracy 92.25978647686833 | Test Accuracy 91.07575233483225\n",
      "Epoch 379 | Train loss 0.3053039610385895\n",
      "Train Accuracy 92.55634638196916 | Test Accuracy 90.79903147699758\n",
      "Epoch 380 | Train loss 0.0845760777592659\n",
      "Train Accuracy 92.79359430604983 | Test Accuracy 91.17952265652023\n",
      "Epoch 381 | Train loss 0.16635902225971222\n",
      "Train Accuracy 91.81494661921708 | Test Accuracy 91.31788308543757\n",
      "Epoch 382 | Train loss 0.20674891769886017\n",
      "Train Accuracy 92.63048635824437 | Test Accuracy 91.21411276374957\n",
      "Epoch 383 | Train loss 0.1711438000202179\n",
      "Train Accuracy 92.45255041518386 | Test Accuracy 91.07575233483225\n",
      "Epoch 384 | Train loss 0.20942236483097076\n",
      "Train Accuracy 92.45255041518386 | Test Accuracy 91.11034244206157\n",
      "Epoch 385 | Train loss 0.2638065814971924\n",
      "Train Accuracy 92.05219454329774 | Test Accuracy 91.5600138360429\n",
      "Epoch 386 | Train loss 0.2732202112674713\n",
      "Train Accuracy 92.48220640569394 | Test Accuracy 91.28329297820824\n",
      "Epoch 387 | Train loss 0.2242886871099472\n",
      "Train Accuracy 92.31909845788849 | Test Accuracy 90.66067104808025\n",
      "Epoch 388 | Train loss 0.16027027368545532\n",
      "Train Accuracy 92.70462633451957 | Test Accuracy 91.21411276374957\n",
      "Epoch 389 | Train loss 0.20531810820102692\n",
      "Train Accuracy 92.61565836298932 | Test Accuracy 91.1449325492909\n",
      "Epoch 390 | Train loss 0.2682100832462311\n",
      "Train Accuracy 92.63048635824437 | Test Accuracy 91.1449325492909\n",
      "Epoch 391 | Train loss 0.17530804872512817\n",
      "Train Accuracy 92.60083036773428 | Test Accuracy 91.21411276374957\n",
      "Epoch 392 | Train loss 0.21033431589603424\n",
      "Train Accuracy 92.5711743772242 | Test Accuracy 91.17952265652023\n",
      "Epoch 393 | Train loss 0.20624184608459473\n",
      "Train Accuracy 92.27461447212337 | Test Accuracy 90.62608094085091\n",
      "Epoch 394 | Train loss 0.1789262443780899\n",
      "Train Accuracy 92.28944246737841 | Test Accuracy 90.59149083362158\n",
      "Epoch 395 | Train loss 0.2220989167690277\n",
      "Train Accuracy 92.30427046263345 | Test Accuracy 91.38706329989623\n",
      "Epoch 396 | Train loss 0.22693690657615662\n",
      "Train Accuracy 92.71945432977462 | Test Accuracy 90.86821169145625\n",
      "Epoch 397 | Train loss 0.21823741495609283\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 90.93739190591491\n",
      "Epoch 398 | Train loss 0.21679116785526276\n",
      "Train Accuracy 92.6453143534994 | Test Accuracy 91.52542372881356\n",
      "Epoch 399 | Train loss 0.24691246449947357\n",
      "Train Accuracy 92.54151838671412 | Test Accuracy 91.07575233483225\n",
      "Epoch 400 | Train loss 0.19796952605247498\n",
      "Train Accuracy 92.34875444839858 | Test Accuracy 91.52542372881356\n",
      "Epoch 401 | Train loss 0.20315566658973694\n",
      "Train Accuracy 92.70462633451957 | Test Accuracy 91.07575233483225\n",
      "Epoch 402 | Train loss 0.22459854185581207\n",
      "Train Accuracy 92.12633451957295 | Test Accuracy 90.86821169145625\n",
      "Epoch 403 | Train loss 0.19766761362552643\n",
      "Train Accuracy 92.42289442467379 | Test Accuracy 91.66378415773089\n",
      "Epoch 404 | Train loss 0.19201278686523438\n",
      "Train Accuracy 92.03736654804271 | Test Accuracy 90.52231061916291\n",
      "Epoch 405 | Train loss 0.11155106872320175\n",
      "Train Accuracy 91.94839857651246 | Test Accuracy 90.48772051193359\n",
      "Epoch 406 | Train loss 0.13616864383220673\n",
      "Train Accuracy 92.49703440094899 | Test Accuracy 91.31788308543757\n",
      "Epoch 407 | Train loss 0.1348886936903\n",
      "Train Accuracy 92.5711743772242 | Test Accuracy 90.90280179868557\n",
      "Epoch 408 | Train loss 0.21055816113948822\n",
      "Train Accuracy 92.49703440094899 | Test Accuracy 90.79903147699758\n",
      "Epoch 409 | Train loss 0.17858324944972992\n",
      "Train Accuracy 92.80842230130486 | Test Accuracy 91.31788308543757\n",
      "Epoch 410 | Train loss 0.21710744500160217\n",
      "Train Accuracy 92.54151838671412 | Test Accuracy 91.21411276374957\n",
      "Epoch 411 | Train loss 0.2241637259721756\n",
      "Train Accuracy 92.58600237247924 | Test Accuracy 90.97198201314424\n",
      "Epoch 412 | Train loss 0.20848236978054047\n",
      "Train Accuracy 92.25978647686833 | Test Accuracy 90.62608094085091\n",
      "Epoch 413 | Train loss 0.21975187957286835\n",
      "Train Accuracy 92.45255041518386 | Test Accuracy 91.21411276374957\n",
      "Epoch 414 | Train loss 0.10783684253692627\n",
      "Train Accuracy 92.05219454329774 | Test Accuracy 91.69837426496022\n",
      "Epoch 415 | Train loss 0.23951703310012817\n",
      "Train Accuracy 92.31909845788849 | Test Accuracy 91.4562435143549\n",
      "Epoch 416 | Train loss 0.2791200876235962\n",
      "Train Accuracy 92.60083036773428 | Test Accuracy 90.97198201314424\n",
      "Epoch 417 | Train loss 0.16745097935199738\n",
      "Train Accuracy 92.63048635824437 | Test Accuracy 90.90280179868557\n",
      "Epoch 418 | Train loss 0.07341190427541733\n",
      "Train Accuracy 92.8232502965599 | Test Accuracy 91.42165340712556\n",
      "Epoch 419 | Train loss 0.2675025761127472\n",
      "Train Accuracy 91.26631079478055 | Test Accuracy 90.24558976132826\n",
      "Epoch 420 | Train loss 0.17448729276657104\n",
      "Train Accuracy 92.25978647686833 | Test Accuracy 90.93739190591491\n",
      "Epoch 421 | Train loss 0.2263156920671463\n",
      "Train Accuracy 92.73428232502965 | Test Accuracy 91.76755447941889\n",
      "Epoch 422 | Train loss 0.27891895174980164\n",
      "Train Accuracy 92.8232502965599 | Test Accuracy 91.38706329989623\n",
      "Epoch 423 | Train loss 0.1349668949842453\n",
      "Train Accuracy 92.71945432977462 | Test Accuracy 91.0411622276029\n",
      "Epoch 424 | Train loss 0.17484022676944733\n",
      "Train Accuracy 92.55634638196916 | Test Accuracy 91.76755447941889\n",
      "Epoch 425 | Train loss 0.25858327746391296\n",
      "Train Accuracy 92.6453143534994 | Test Accuracy 91.4562435143549\n",
      "Epoch 426 | Train loss 0.18037773668766022\n",
      "Train Accuracy 92.6453143534994 | Test Accuracy 91.4562435143549\n",
      "Epoch 427 | Train loss 0.18615280091762543\n",
      "Train Accuracy 92.7491103202847 | Test Accuracy 91.69837426496022\n",
      "Epoch 428 | Train loss 0.1727144569158554\n",
      "Train Accuracy 92.46737841043891 | Test Accuracy 90.93739190591491\n",
      "Epoch 429 | Train loss 0.22281599044799805\n",
      "Train Accuracy 92.76393831553975 | Test Accuracy 91.66378415773089\n",
      "Epoch 430 | Train loss 0.19027090072631836\n",
      "Train Accuracy 92.49703440094899 | Test Accuracy 91.76755447941889\n",
      "Epoch 431 | Train loss 0.14890244603157043\n",
      "Train Accuracy 92.60083036773428 | Test Accuracy 91.5600138360429\n",
      "Epoch 432 | Train loss 0.12025735527276993\n",
      "Train Accuracy 93.00118623962041 | Test Accuracy 91.2487028709789\n",
      "Epoch 433 | Train loss 0.1641308218240738\n",
      "Train Accuracy 92.61565836298932 | Test Accuracy 91.1449325492909\n",
      "Epoch 434 | Train loss 0.18738049268722534\n",
      "Train Accuracy 92.34875444839858 | Test Accuracy 91.2487028709789\n",
      "Epoch 435 | Train loss 0.18685020506381989\n",
      "Train Accuracy 92.85290628707 | Test Accuracy 91.0411622276029\n",
      "Epoch 436 | Train loss 0.17507816851139069\n",
      "Train Accuracy 92.83807829181495 | Test Accuracy 91.35247319266689\n",
      "Epoch 437 | Train loss 0.13777203857898712\n",
      "Train Accuracy 92.6453143534994 | Test Accuracy 91.00657212037358\n",
      "Epoch 438 | Train loss 0.2223351150751114\n",
      "Train Accuracy 92.30427046263345 | Test Accuracy 91.80214458664821\n",
      "Epoch 439 | Train loss 0.15615259110927582\n",
      "Train Accuracy 92.141162514828 | Test Accuracy 90.48772051193359\n",
      "Epoch 440 | Train loss 0.16769342124462128\n",
      "Train Accuracy 92.80842230130486 | Test Accuracy 91.38706329989623\n",
      "Epoch 441 | Train loss 0.11751537770032883\n",
      "Train Accuracy 92.55634638196916 | Test Accuracy 90.76444136976825\n",
      "Epoch 442 | Train loss 0.13159939646720886\n",
      "Train Accuracy 92.55634638196916 | Test Accuracy 90.93739190591491\n",
      "Epoch 443 | Train loss 0.17348966002464294\n",
      "Train Accuracy 92.54151838671412 | Test Accuracy 91.69837426496022\n",
      "Epoch 444 | Train loss 0.17010796070098877\n",
      "Train Accuracy 92.63048635824437 | Test Accuracy 90.90280179868557\n",
      "Epoch 445 | Train loss 0.1568140834569931\n",
      "Train Accuracy 92.83807829181495 | Test Accuracy 91.17952265652023\n",
      "Epoch 446 | Train loss 0.2040237933397293\n",
      "Train Accuracy 91.56287069988137 | Test Accuracy 90.86821169145625\n",
      "Epoch 447 | Train loss 0.13354110717773438\n",
      "Train Accuracy 92.6453143534994 | Test Accuracy 90.8336215842269\n",
      "Epoch 448 | Train loss 0.16455064713954926\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 91.52542372881356\n",
      "Epoch 449 | Train loss 0.17046837508678436\n",
      "Train Accuracy 92.43772241992883 | Test Accuracy 90.76444136976825\n",
      "Epoch 450 | Train loss 0.2305077612400055\n",
      "Train Accuracy 92.55634638196916 | Test Accuracy 90.69526115530958\n",
      "Epoch 451 | Train loss 0.28247764706611633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 92.40806642941874 | Test Accuracy 90.69526115530958\n",
      "Epoch 452 | Train loss 0.14048776030540466\n",
      "Train Accuracy 93.1049822064057 | Test Accuracy 91.4562435143549\n",
      "Epoch 453 | Train loss 0.15309278666973114\n",
      "Train Accuracy 91.63701067615658 | Test Accuracy 91.52542372881356\n",
      "Epoch 454 | Train loss 0.14068597555160522\n",
      "Train Accuracy 92.92704626334519 | Test Accuracy 91.59460394327222\n",
      "Epoch 455 | Train loss 0.3331622779369354\n",
      "Train Accuracy 92.97153024911033 | Test Accuracy 91.07575233483225\n",
      "Epoch 456 | Train loss 0.2148721069097519\n",
      "Train Accuracy 92.85290628707 | Test Accuracy 91.42165340712556\n",
      "Epoch 457 | Train loss 0.18261800706386566\n",
      "Train Accuracy 92.95670225385528 | Test Accuracy 91.66378415773089\n",
      "Epoch 458 | Train loss 0.19351452589035034\n",
      "Train Accuracy 92.24495848161328 | Test Accuracy 91.80214458664821\n",
      "Epoch 459 | Train loss 0.1667046695947647\n",
      "Train Accuracy 92.77876631079478 | Test Accuracy 90.76444136976825\n",
      "Epoch 460 | Train loss 0.15803708136081696\n",
      "Train Accuracy 92.7491103202847 | Test Accuracy 91.76755447941889\n",
      "Epoch 461 | Train loss 0.1941959708929062\n",
      "Train Accuracy 91.80011862396204 | Test Accuracy 91.28329297820824\n",
      "Epoch 462 | Train loss 0.2450065165758133\n",
      "Train Accuracy 91.90391459074732 | Test Accuracy 91.42165340712556\n",
      "Epoch 463 | Train loss 0.1827770620584488\n",
      "Train Accuracy 93.04567022538552 | Test Accuracy 91.4562435143549\n",
      "Epoch 464 | Train loss 0.2705267369747162\n",
      "Train Accuracy 92.86773428232503 | Test Accuracy 90.93739190591491\n",
      "Epoch 465 | Train loss 0.24048691987991333\n",
      "Train Accuracy 92.94187425860024 | Test Accuracy 91.59460394327222\n",
      "Epoch 466 | Train loss 0.11251527816057205\n",
      "Train Accuracy 92.91221826809016 | Test Accuracy 91.69837426496022\n",
      "Epoch 467 | Train loss 0.11758428066968918\n",
      "Train Accuracy 92.58600237247924 | Test Accuracy 91.94050501556555\n",
      "Epoch 468 | Train loss 0.22737064957618713\n",
      "Train Accuracy 92.80842230130486 | Test Accuracy 91.21411276374957\n",
      "Epoch 469 | Train loss 0.1825183928012848\n",
      "Train Accuracy 92.24495848161328 | Test Accuracy 91.59460394327222\n",
      "Epoch 470 | Train loss 0.1664617508649826\n",
      "Train Accuracy 92.37841043890866 | Test Accuracy 91.83673469387756\n",
      "Epoch 471 | Train loss 0.25942036509513855\n",
      "Train Accuracy 92.51186239620404 | Test Accuracy 92.28640608785888\n",
      "Epoch 472 | Train loss 0.21572595834732056\n",
      "Train Accuracy 92.6453143534994 | Test Accuracy 91.38706329989623\n",
      "Epoch 473 | Train loss 0.10901089012622833\n",
      "Train Accuracy 92.83807829181495 | Test Accuracy 91.1449325492909\n",
      "Epoch 474 | Train loss 0.19402827322483063\n",
      "Train Accuracy 90.65836298932385 | Test Accuracy 90.14181943964026\n",
      "Epoch 475 | Train loss 0.18318957090377808\n",
      "Train Accuracy 93.19395017793595 | Test Accuracy 91.4562435143549\n",
      "Epoch 476 | Train loss 0.13197824358940125\n",
      "Train Accuracy 92.92704626334519 | Test Accuracy 91.69837426496022\n",
      "Epoch 477 | Train loss 0.1231328547000885\n",
      "Train Accuracy 92.94187425860024 | Test Accuracy 91.21411276374957\n",
      "Epoch 478 | Train loss 0.2288852334022522\n",
      "Train Accuracy 90.99940688018981 | Test Accuracy 91.00657212037358\n",
      "Epoch 479 | Train loss 0.2003289759159088\n",
      "Train Accuracy 93.2532621589561 | Test Accuracy 91.42165340712556\n",
      "Epoch 480 | Train loss 0.14831872284412384\n",
      "Train Accuracy 92.85290628707 | Test Accuracy 91.49083362158422\n",
      "Epoch 481 | Train loss 0.15552718937397003\n",
      "Train Accuracy 93.01601423487544 | Test Accuracy 91.4562435143549\n",
      "Epoch 482 | Train loss 0.23183956742286682\n",
      "Train Accuracy 92.80842230130486 | Test Accuracy 91.38706329989623\n",
      "Epoch 483 | Train loss 0.12363804131746292\n",
      "Train Accuracy 92.63048635824437 | Test Accuracy 91.76755447941889\n",
      "Epoch 484 | Train loss 0.18012796342372894\n",
      "Train Accuracy 92.2153024911032 | Test Accuracy 90.72985126253892\n",
      "Epoch 485 | Train loss 0.1599312424659729\n",
      "Train Accuracy 93.31257413997628 | Test Accuracy 92.04427533725354\n",
      "Epoch 486 | Train loss 0.07820229232311249\n",
      "Train Accuracy 92.79359430604983 | Test Accuracy 91.5600138360429\n",
      "Epoch 487 | Train loss 0.13197319209575653\n",
      "Train Accuracy 92.68979833926453 | Test Accuracy 91.59460394327222\n",
      "Epoch 488 | Train loss 0.246904656291008\n",
      "Train Accuracy 92.49703440094899 | Test Accuracy 91.94050501556555\n",
      "Epoch 489 | Train loss 0.09555060416460037\n",
      "Train Accuracy 92.31909845788849 | Test Accuracy 91.42165340712556\n",
      "Epoch 490 | Train loss 0.11282603442668915\n",
      "Train Accuracy 91.63701067615658 | Test Accuracy 91.38706329989623\n",
      "Epoch 491 | Train loss 0.2262612283229828\n",
      "Train Accuracy 92.80842230130486 | Test Accuracy 90.90280179868557\n",
      "Epoch 492 | Train loss 0.14623497426509857\n",
      "Train Accuracy 93.06049822064057 | Test Accuracy 91.97509512279488\n",
      "Epoch 493 | Train loss 0.21866750717163086\n",
      "Train Accuracy 92.79359430604983 | Test Accuracy 92.04427533725354\n",
      "Epoch 494 | Train loss 0.2170073390007019\n",
      "Train Accuracy 92.94187425860024 | Test Accuracy 91.31788308543757\n",
      "Epoch 495 | Train loss 0.15512715280056\n",
      "Train Accuracy 92.77876631079478 | Test Accuracy 92.04427533725354\n",
      "Epoch 496 | Train loss 0.2038935273885727\n",
      "Train Accuracy 93.38671411625148 | Test Accuracy 91.76755447941889\n",
      "Epoch 497 | Train loss 0.18116267025470734\n",
      "Train Accuracy 93.06049822064057 | Test Accuracy 91.11034244206157\n",
      "Epoch 498 | Train loss 0.0976102277636528\n",
      "Train Accuracy 93.17912218268091 | Test Accuracy 91.94050501556555\n",
      "Epoch 499 | Train loss 0.1372653692960739\n",
      "Train Accuracy 92.46737841043891 | Test Accuracy 91.73296437218956\n",
      "Epoch 500 | Train loss 0.17541533708572388\n",
      "Train Accuracy 92.83807829181495 | Test Accuracy 91.1449325492909\n",
      "Epoch 501 | Train loss 0.24070048332214355\n",
      "Train Accuracy 92.141162514828 | Test Accuracy 91.59460394327222\n",
      "Epoch 502 | Train loss 0.2712830901145935\n",
      "Train Accuracy 92.18564650059312 | Test Accuracy 91.76755447941889\n",
      "Epoch 503 | Train loss 0.1342037469148636\n",
      "Train Accuracy 92.73428232502965 | Test Accuracy 91.97509512279488\n",
      "Epoch 504 | Train loss 0.27899569272994995\n",
      "Train Accuracy 93.16429418742585 | Test Accuracy 91.94050501556555\n",
      "Epoch 505 | Train loss 0.2669895887374878\n",
      "Train Accuracy 93.13463819691577 | Test Accuracy 91.76755447941889\n",
      "Epoch 506 | Train loss 0.13831907510757446\n",
      "Train Accuracy 92.97153024911033 | Test Accuracy 92.18263576617088\n",
      "Epoch 507 | Train loss 0.20594030618667603\n",
      "Train Accuracy 93.32740213523132 | Test Accuracy 91.90591490833621\n",
      "Epoch 508 | Train loss 0.17664207518100739\n",
      "Train Accuracy 93.1049822064057 | Test Accuracy 92.1134555517122\n",
      "Epoch 509 | Train loss 0.20849265158176422\n",
      "Train Accuracy 92.86773428232503 | Test Accuracy 91.94050501556555\n",
      "Epoch 510 | Train loss 0.1457117646932602\n",
      "Train Accuracy 93.22360616844603 | Test Accuracy 91.69837426496022\n",
      "Epoch 511 | Train loss 0.19461902976036072\n",
      "Train Accuracy 93.03084223013049 | Test Accuracy 91.2487028709789\n",
      "Epoch 512 | Train loss 0.2054375559091568\n",
      "Train Accuracy 93.23843416370107 | Test Accuracy 91.76755447941889\n",
      "Epoch 513 | Train loss 0.19788488745689392\n",
      "Train Accuracy 92.95670225385528 | Test Accuracy 92.45935662400554\n",
      "Epoch 514 | Train loss 0.12110283225774765\n",
      "Train Accuracy 92.88256227758008 | Test Accuracy 91.83673469387756\n",
      "Epoch 515 | Train loss 0.1727907806634903\n",
      "Train Accuracy 92.46737841043891 | Test Accuracy 91.21411276374957\n",
      "Epoch 516 | Train loss 0.13415592908859253\n",
      "Train Accuracy 93.22360616844603 | Test Accuracy 91.83673469387756\n",
      "Epoch 517 | Train loss 0.16016580164432526\n",
      "Train Accuracy 93.38671411625148 | Test Accuracy 91.5600138360429\n",
      "Epoch 518 | Train loss 0.203565314412117\n",
      "Train Accuracy 93.22360616844603 | Test Accuracy 91.76755447941889\n",
      "Epoch 519 | Train loss 0.22203078866004944\n",
      "Train Accuracy 92.77876631079478 | Test Accuracy 91.0411622276029\n",
      "Epoch 520 | Train loss 0.12698672711849213\n",
      "Train Accuracy 93.03084223013049 | Test Accuracy 91.17952265652023\n",
      "Epoch 521 | Train loss 0.09775643795728683\n",
      "Train Accuracy 93.26809015421115 | Test Accuracy 92.00968523002422\n",
      "Epoch 522 | Train loss 0.1665489673614502\n",
      "Train Accuracy 92.6453143534994 | Test Accuracy 91.35247319266689\n",
      "Epoch 523 | Train loss 0.24966326355934143\n",
      "Train Accuracy 92.76393831553975 | Test Accuracy 91.90591490833621\n",
      "Epoch 524 | Train loss 0.1659330278635025\n",
      "Train Accuracy 93.04567022538552 | Test Accuracy 91.5600138360429\n",
      "Epoch 525 | Train loss 0.1917271465063095\n",
      "Train Accuracy 92.88256227758008 | Test Accuracy 92.21722587340021\n",
      "Epoch 526 | Train loss 0.24489058554172516\n",
      "Train Accuracy 92.33392645314353 | Test Accuracy 91.4562435143549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 527 | Train loss 0.20936451852321625\n",
      "Train Accuracy 92.51186239620404 | Test Accuracy 91.52542372881356\n",
      "Epoch 528 | Train loss 0.07347115874290466\n",
      "Train Accuracy 92.46737841043891 | Test Accuracy 92.00968523002422\n",
      "Epoch 529 | Train loss 0.13435935974121094\n",
      "Train Accuracy 93.11981020166074 | Test Accuracy 92.3209961950882\n",
      "Epoch 530 | Train loss 0.28512224555015564\n",
      "Train Accuracy 93.19395017793595 | Test Accuracy 91.87132480110688\n",
      "Epoch 531 | Train loss 0.205437570810318\n",
      "Train Accuracy 93.09015421115066 | Test Accuracy 91.52542372881356\n",
      "Epoch 532 | Train loss 0.2000083029270172\n",
      "Train Accuracy 93.16429418742585 | Test Accuracy 92.4247665167762\n",
      "Epoch 533 | Train loss 0.21063293516635895\n",
      "Train Accuracy 93.04567022538552 | Test Accuracy 92.07886544448289\n",
      "Epoch 534 | Train loss 0.12363051623106003\n",
      "Train Accuracy 93.29774614472124 | Test Accuracy 91.90591490833621\n",
      "Epoch 535 | Train loss 0.30521324276924133\n",
      "Train Accuracy 92.88256227758008 | Test Accuracy 91.38706329989623\n",
      "Epoch 536 | Train loss 0.20029239356517792\n",
      "Train Accuracy 92.6749703440095 | Test Accuracy 91.94050501556555\n",
      "Epoch 537 | Train loss 0.19255684316158295\n",
      "Train Accuracy 91.47390272835113 | Test Accuracy 90.38395019024559\n",
      "Epoch 538 | Train loss 0.16955305635929108\n",
      "Train Accuracy 93.29774614472124 | Test Accuracy 92.04427533725354\n",
      "Epoch 539 | Train loss 0.1417788565158844\n",
      "Train Accuracy 93.20877817319099 | Test Accuracy 92.3209961950882\n",
      "Epoch 540 | Train loss 0.0989430695772171\n",
      "Train Accuracy 92.73428232502965 | Test Accuracy 91.4562435143549\n",
      "Epoch 541 | Train loss 0.10447108745574951\n",
      "Train Accuracy 93.3570581257414 | Test Accuracy 92.00968523002422\n",
      "Epoch 542 | Train loss 0.22343659400939941\n",
      "Train Accuracy 92.2153024911032 | Test Accuracy 91.66378415773089\n",
      "Epoch 543 | Train loss 0.12533240020275116\n",
      "Train Accuracy 93.29774614472124 | Test Accuracy 91.83673469387756\n",
      "Epoch 544 | Train loss 0.22699111700057983\n",
      "Train Accuracy 93.17912218268091 | Test Accuracy 91.73296437218956\n",
      "Epoch 545 | Train loss 0.15844608843326569\n",
      "Train Accuracy 93.49051008303677 | Test Accuracy 91.97509512279488\n",
      "Epoch 546 | Train loss 0.12625457346439362\n",
      "Train Accuracy 93.37188612099644 | Test Accuracy 91.90591490833621\n",
      "Epoch 547 | Train loss 0.26573237776756287\n",
      "Train Accuracy 92.2153024911032 | Test Accuracy 91.49083362158422\n",
      "Epoch 548 | Train loss 0.2715441882610321\n",
      "Train Accuracy 92.80842230130486 | Test Accuracy 91.42165340712556\n",
      "Epoch 549 | Train loss 0.13860347867012024\n",
      "Train Accuracy 93.07532621589561 | Test Accuracy 92.35558630231753\n",
      "Epoch 550 | Train loss 0.18047915399074554\n",
      "Train Accuracy 93.14946619217082 | Test Accuracy 91.87132480110688\n",
      "Epoch 551 | Train loss 0.15483984351158142\n",
      "Train Accuracy 93.2532621589561 | Test Accuracy 91.52542372881356\n",
      "Epoch 552 | Train loss 0.22965583205223083\n",
      "Train Accuracy 93.3570581257414 | Test Accuracy 92.04427533725354\n",
      "Epoch 553 | Train loss 0.18689996004104614\n",
      "Train Accuracy 93.13463819691577 | Test Accuracy 92.3209961950882\n",
      "Epoch 554 | Train loss 0.1164279654622078\n",
      "Train Accuracy 93.37188612099644 | Test Accuracy 92.14804565894154\n",
      "Epoch 555 | Train loss 0.21082530915737152\n",
      "Train Accuracy 93.22360616844603 | Test Accuracy 92.07886544448289\n",
      "Epoch 556 | Train loss 0.19382213056087494\n",
      "Train Accuracy 92.94187425860024 | Test Accuracy 91.90591490833621\n",
      "Epoch 557 | Train loss 0.12042052298784256\n",
      "Train Accuracy 93.29774614472124 | Test Accuracy 92.14804565894154\n",
      "Epoch 558 | Train loss 0.21474504470825195\n",
      "Train Accuracy 93.29774614472124 | Test Accuracy 91.69837426496022\n",
      "Epoch 559 | Train loss 0.13231967389583588\n",
      "Train Accuracy 93.31257413997628 | Test Accuracy 92.25181598062953\n",
      "Epoch 560 | Train loss 0.19219709932804108\n",
      "Train Accuracy 92.61565836298932 | Test Accuracy 91.90591490833621\n",
      "Epoch 561 | Train loss 0.08927685767412186\n",
      "Train Accuracy 93.14946619217082 | Test Accuracy 91.90591490833621\n",
      "Epoch 562 | Train loss 0.1577339768409729\n",
      "Train Accuracy 92.68979833926453 | Test Accuracy 91.17952265652023\n",
      "Epoch 563 | Train loss 0.20136131346225739\n",
      "Train Accuracy 92.83807829181495 | Test Accuracy 91.31788308543757\n",
      "Epoch 564 | Train loss 0.11238005012273788\n",
      "Train Accuracy 92.28944246737841 | Test Accuracy 91.94050501556555\n",
      "Epoch 565 | Train loss 0.2009296417236328\n",
      "Train Accuracy 93.3570581257414 | Test Accuracy 92.25181598062953\n",
      "Epoch 566 | Train loss 0.12959133088588715\n",
      "Train Accuracy 93.23843416370107 | Test Accuracy 91.42165340712556\n",
      "Epoch 567 | Train loss 0.11029934138059616\n",
      "Train Accuracy 93.32740213523132 | Test Accuracy 91.87132480110688\n",
      "Epoch 568 | Train loss 0.1312699019908905\n",
      "Train Accuracy 92.73428232502965 | Test Accuracy 91.21411276374957\n",
      "Epoch 569 | Train loss 0.16693836450576782\n",
      "Train Accuracy 93.31257413997628 | Test Accuracy 91.80214458664821\n",
      "Epoch 570 | Train loss 0.15053950250148773\n",
      "Train Accuracy 93.3570581257414 | Test Accuracy 92.18263576617088\n",
      "Epoch 571 | Train loss 0.17008571326732635\n",
      "Train Accuracy 93.23843416370107 | Test Accuracy 91.76755447941889\n",
      "Epoch 572 | Train loss 0.18660607933998108\n",
      "Train Accuracy 93.07532621589561 | Test Accuracy 92.07886544448289\n",
      "Epoch 573 | Train loss 0.12377358227968216\n",
      "Train Accuracy 93.19395017793595 | Test Accuracy 91.94050501556555\n",
      "Epoch 574 | Train loss 0.2130814492702484\n",
      "Train Accuracy 93.19395017793595 | Test Accuracy 91.76755447941889\n",
      "Epoch 575 | Train loss 0.20564185082912445\n",
      "Train Accuracy 93.53499406880191 | Test Accuracy 92.14804565894154\n",
      "Epoch 576 | Train loss 0.13461868464946747\n",
      "Train Accuracy 92.8232502965599 | Test Accuracy 91.62919405050157\n",
      "Epoch 577 | Train loss 0.18594108521938324\n",
      "Train Accuracy 93.38671411625148 | Test Accuracy 91.90591490833621\n",
      "Epoch 578 | Train loss 0.21671129763126373\n",
      "Train Accuracy 93.23843416370107 | Test Accuracy 91.87132480110688\n",
      "Epoch 579 | Train loss 0.158966526389122\n",
      "Train Accuracy 93.23843416370107 | Test Accuracy 92.00968523002422\n",
      "Epoch 580 | Train loss 0.07944192737340927\n",
      "Train Accuracy 93.37188612099644 | Test Accuracy 91.90591490833621\n",
      "Epoch 581 | Train loss 0.13161025941371918\n",
      "Train Accuracy 93.41637010676158 | Test Accuracy 91.87132480110688\n",
      "Epoch 582 | Train loss 0.14740602672100067\n",
      "Train Accuracy 92.97153024911033 | Test Accuracy 91.42165340712556\n",
      "Epoch 583 | Train loss 0.296049565076828\n",
      "Train Accuracy 93.16429418742585 | Test Accuracy 92.39017640954687\n",
      "Epoch 584 | Train loss 0.18631106615066528\n",
      "Train Accuracy 93.3570581257414 | Test Accuracy 92.00968523002422\n",
      "Epoch 585 | Train loss 0.08086037635803223\n",
      "Train Accuracy 93.26809015421115 | Test Accuracy 92.04427533725354\n",
      "Epoch 586 | Train loss 0.25254660844802856\n",
      "Train Accuracy 93.00118623962041 | Test Accuracy 91.83673469387756\n",
      "Epoch 587 | Train loss 0.12175962328910828\n",
      "Train Accuracy 93.29774614472124 | Test Accuracy 91.97509512279488\n",
      "Epoch 588 | Train loss 0.16022823750972748\n",
      "Train Accuracy 93.07532621589561 | Test Accuracy 92.00968523002422\n",
      "Epoch 589 | Train loss 0.1499687284231186\n",
      "Train Accuracy 93.3570581257414 | Test Accuracy 92.07886544448289\n",
      "Epoch 590 | Train loss 0.16052235662937164\n",
      "Train Accuracy 92.73428232502965 | Test Accuracy 91.49083362158422\n",
      "Epoch 591 | Train loss 0.11454284191131592\n",
      "Train Accuracy 93.11981020166074 | Test Accuracy 91.5600138360429\n",
      "Epoch 592 | Train loss 0.10045041888952255\n",
      "Train Accuracy 93.23843416370107 | Test Accuracy 91.87132480110688\n",
      "Epoch 593 | Train loss 0.047490108758211136\n",
      "Train Accuracy 92.92704626334519 | Test Accuracy 91.31788308543757\n",
      "Epoch 594 | Train loss 0.15278762578964233\n",
      "Train Accuracy 92.92704626334519 | Test Accuracy 91.42165340712556\n",
      "Epoch 595 | Train loss 0.23934349417686462\n",
      "Train Accuracy 93.29774614472124 | Test Accuracy 91.94050501556555\n",
      "Epoch 596 | Train loss 0.15287557244300842\n",
      "Train Accuracy 93.41637010676158 | Test Accuracy 92.00968523002422\n",
      "Epoch 597 | Train loss 0.1897011697292328\n",
      "Train Accuracy 93.2532621589561 | Test Accuracy 91.76755447941889\n",
      "Epoch 598 | Train loss 0.17374342679977417\n",
      "Train Accuracy 93.29774614472124 | Test Accuracy 91.87132480110688\n",
      "Epoch 599 | Train loss 0.16036958992481232\n",
      "Train Accuracy 93.09015421115066 | Test Accuracy 91.42165340712556\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(600):\n",
    "    loss, model = train(model, train_loader, [0, 1, 2, 3])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model, train_loader, [0, 1, 2, 3]), check_accuracy(model, test_loader, [0, 1, 2, 3])\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a twenty node graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fully connected 11-node graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an 20-node graph\n",
    "n = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 30):\n",
    "    j = (np.random.randint(0, 30))\n",
    "    while j == i:\n",
    "        j = (np.random.randint(0, 30))\n",
    "        \n",
    "    print(j == i)\n",
    "    g.add_edge(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_edges = set()\n",
    "for i in range(0, 30):\n",
    "    for j in range(i+1, 30):\n",
    "        if not g.has_edge(i, j):\n",
    "            all_possible_edges.add((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_possible_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "non_edges_sample_order = random.sample(all_possible_edges, 57 - 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (u,v) in non_edges_sample_order:\n",
    "    g.add_edge(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    graph_as_data = from_networkx(g)\n",
    "    graph_as_data.x = generate_feature_vector(g)\n",
    "    validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "    for batch in validation_set:\n",
    "        pred = model(batch.x[:, [0]], batch.edge_index, batch.batch)\n",
    "        print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(model, test_loader, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(model, train_loader, [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square\n",
    "import networkx as nx\n",
    "square = nx.Graph()\n",
    "square.add_edge(0, 1)\n",
    "square.add_edge(1, 3)\n",
    "square.add_edge(0, 2)\n",
    "square.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square with cross bar (rigid)\n",
    "import networkx as nx\n",
    "square_bar = nx.Graph()\n",
    "square_bar.add_edge(0, 1)\n",
    "square_bar.add_edge(1, 3)\n",
    "square_bar.add_edge(0, 2)\n",
    "square_bar.add_edge(2, 3)\n",
    "square_bar.add_edge(0, 3)\n",
    "square_bar.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle\n",
    "import networkx as nx\n",
    "triangle = nx.Graph()\n",
    "triangle.add_edge(0, 1)\n",
    "triangle.add_edge(0, 2)\n",
    "triangle.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentagon\n",
    "import networkx as nx\n",
    "pentagon = nx.Graph()\n",
    "pentagon.add_edge(0, 1)\n",
    "pentagon.add_edge(1, 3)\n",
    "pentagon.add_edge(3, 4)\n",
    "pentagon.add_edge(4, 2)\n",
    "pentagon.add_edge(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_problems = [square, square_bar, triangle, pentagon]\n",
    "labels = [1, 0, 0, 1]\n",
    "\n",
    "for index, toy_problem in enumerate(toy_problems):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        graph_as_data = from_networkx(toy_problem)\n",
    "        graph_as_data.x = generate_feature_vector(toy_problem)\n",
    "#         graph_as_data.label = labels[index]\n",
    "        validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)\n",
    "        for batch in validation_set:\n",
    "            pred = model(batch.x[:, [0, 1, 2, 3]], batch.edge_index, batch.batch)\n",
    "            print(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_as_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in validation_set:\n",
    "    pred = bestModel(batch.x, batch.edge_index, batch.batch)\n",
    "    print(pred[0])\n",
    "    print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanTestDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_test.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add functionality to support a test dataset\n",
    "TEST_DATA_PATH = \"../data-2d/data/test-dataset-30loc-5std.pkl.gz\"\n",
    "laman_test_set = LamanTestDataset(\"\", TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "laman_test_loader = DataLoader(laman_test_set, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_acc = check_accuracy(bestModel, laman_test_loader)\n",
    "print(f\"Accuracy {random_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the clustering coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(triangle, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient(square_bar, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate graph correlating clustering coefficient to rigidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_data:\n",
    "    item = to_networkx(item)\n",
    "    print(type(item))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric.utils.convert.to_networkx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work: Sahil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_laman_data = None\n",
    "with gzip.open(DATA_PATH, 'r') as f:\n",
    "    total_laman_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph = total_laman_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_data = from_networkx(sample_graph)\n",
    "from_data = to_networkx(to_data, to_undirected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_clustering_coefficient(G):\n",
    "    min_coefficient = 1\n",
    "    for node in G.nodes():\n",
    "        min_coefficient = min(min_coefficient, clustering_coefficient(G, node))\n",
    "        \n",
    "    return min_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sample_graph in enumerate(train_data):\n",
    "    label = sample_graph.label\n",
    "    networkx_sample_graph = to_networkx(sample_graph, to_undirected = True)\n",
    "    print(label, \" \", index, \" \", compute_min_clustering_coefficient(networkx_sample_graph))\n",
    "    \n",
    "    if index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_min_clustering_coefficient(from_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_min_clustering_coefficient(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if instead of training a gnn – you just trained on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the degrees of the nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on just the triangle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a binary classifier on the triangle features and the degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a network with just degree of the node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_just_degree = GIN(num_features=1)\n",
    "print(model_just_degree)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "bestModel, highestAcc = None, 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, h = train(train_loader, [0])\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model_just_degree, train_loader), check_accuracy(model_just_degree, test_loader)\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "#     scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > highestAcc:\n",
    "        highestAcc = test_acc\n",
    "        bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_feature_vector(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph.x[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

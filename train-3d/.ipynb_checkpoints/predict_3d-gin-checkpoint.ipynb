{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(G):\n",
    "    x = torch.randn(G.number_of_nodes(), 1)\n",
    "    ind = 0\n",
    "    for node in G.nodes():\n",
    "        x[ind][0] = G.degree[node]\n",
    "        ind += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/test.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "laman_data = LamanDataset(\"\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "proportions = [.6, .4]\n",
    "lengths = [int(p * len(laman_data)) for p in proportions]\n",
    "lengths[-1] = len(laman_data) - sum(lengths[:-1])\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = random_split(laman_data, lengths, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size = 32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches:  19\n",
      "Number of test batches:  13\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train batches: \", len(train_loader))\n",
    "print(\"Number of test batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 11436], x=[1970, 1], label=[32], num_nodes=1970, batch=[1970], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gin.gin import GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv2): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv3): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv4): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv5): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv6): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (conv7): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      "  (lin1): Linear(in_features=112, out_features=112, bias=True)\n",
      "  (lin2): Linear(in_features=112, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  16561\n"
     ]
    }
   ],
   "source": [
    "model = GIN(num_features=1)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    ind = 0\n",
    "    for batch in data:\n",
    "        optimizer.zero_grad()\n",
    "        pred, embedding = model(batch.x, batch.edge_index, batch.batch)\n",
    "        pred = torch.squeeze(pred)\n",
    "        loss = loss_fn(pred.float(), batch.label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ind += 1\n",
    "\n",
    "    return loss, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            pred, embedding = model(batch.x, batch.edge_index, batch.batch)\n",
    "            pred = torch.squeeze(pred)\n",
    "            y = batch.label\n",
    "            predictions = (pred > 0.5).long() \n",
    "            num_correct += (predictions == y).sum() \n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    return float(num_correct)/float(num_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Train loss 0.3661311864852905\n",
      "Train Accuracy 51.83333333333333 | Test Accuracy 50.74999999999999\n",
      "Epoch 1 | Train loss 0.2061307430267334\n",
      "Train Accuracy 86.0 | Test Accuracy 82.75\n",
      "Epoch 2 | Train loss 0.38811448216438293\n",
      "Train Accuracy 85.5 | Test Accuracy 82.5\n",
      "Epoch 3 | Train loss 0.32280781865119934\n",
      "Train Accuracy 89.33333333333333 | Test Accuracy 85.5\n",
      "Epoch 4 | Train loss 0.1549537628889084\n",
      "Train Accuracy 89.33333333333333 | Test Accuracy 84.0\n",
      "Epoch 5 | Train loss 0.12899388372898102\n",
      "Train Accuracy 88.16666666666667 | Test Accuracy 86.0\n",
      "Epoch 6 | Train loss 0.141525998711586\n",
      "Train Accuracy 92.0 | Test Accuracy 86.75\n",
      "Epoch 7 | Train loss 0.3509482145309448\n",
      "Train Accuracy 92.0 | Test Accuracy 86.25\n",
      "Epoch 8 | Train loss 0.32756471633911133\n",
      "Train Accuracy 87.5 | Test Accuracy 85.25\n",
      "Epoch 9 | Train loss 0.7060820460319519\n",
      "Train Accuracy 92.16666666666666 | Test Accuracy 86.25\n",
      "Epoch 10 | Train loss 0.3477994203567505\n",
      "Train Accuracy 80.16666666666666 | Test Accuracy 76.5\n",
      "Epoch 11 | Train loss 0.4527060091495514\n",
      "Train Accuracy 89.66666666666666 | Test Accuracy 84.75\n",
      "Epoch 12 | Train loss 0.19967913627624512\n",
      "Train Accuracy 89.16666666666667 | Test Accuracy 87.25\n",
      "Epoch 13 | Train loss 0.28057241439819336\n",
      "Train Accuracy 87.5 | Test Accuracy 83.5\n",
      "Epoch 14 | Train loss 0.05671114847064018\n",
      "Train Accuracy 93.83333333333333 | Test Accuracy 91.0\n",
      "Epoch 15 | Train loss 0.11817041039466858\n",
      "Train Accuracy 92.5 | Test Accuracy 86.75\n",
      "Epoch 16 | Train loss 0.2032502442598343\n",
      "Train Accuracy 90.5 | Test Accuracy 86.0\n",
      "Epoch 17 | Train loss 0.19274300336837769\n",
      "Train Accuracy 94.66666666666667 | Test Accuracy 90.75\n",
      "Epoch 18 | Train loss 0.13723650574684143\n",
      "Train Accuracy 95.16666666666667 | Test Accuracy 92.75\n",
      "Epoch 19 | Train loss 0.07867375761270523\n",
      "Train Accuracy 93.66666666666667 | Test Accuracy 88.25\n",
      "Epoch 20 | Train loss 0.03643620014190674\n",
      "Train Accuracy 95.0 | Test Accuracy 89.75\n",
      "Epoch 21 | Train loss 0.04444688558578491\n",
      "Train Accuracy 94.5 | Test Accuracy 89.0\n",
      "Epoch 22 | Train loss 0.22353751957416534\n",
      "Train Accuracy 87.16666666666667 | Test Accuracy 85.5\n",
      "Epoch 23 | Train loss 0.07482520490884781\n",
      "Train Accuracy 95.16666666666667 | Test Accuracy 89.5\n",
      "Epoch 24 | Train loss 0.04519610479474068\n",
      "Train Accuracy 87.66666666666667 | Test Accuracy 85.5\n",
      "Epoch 25 | Train loss 0.1819126158952713\n",
      "Train Accuracy 97.0 | Test Accuracy 93.0\n",
      "Epoch 26 | Train loss 0.16044653952121735\n",
      "Train Accuracy 92.83333333333333 | Test Accuracy 90.25\n",
      "Epoch 27 | Train loss 0.08601456135511398\n",
      "Train Accuracy 74.33333333333333 | Test Accuracy 72.5\n",
      "Epoch 28 | Train loss 0.10629593580961227\n",
      "Train Accuracy 97.66666666666667 | Test Accuracy 93.75\n",
      "Epoch 29 | Train loss 0.07241874188184738\n",
      "Train Accuracy 97.33333333333334 | Test Accuracy 93.25\n",
      "Epoch 30 | Train loss 0.21718890964984894\n",
      "Train Accuracy 95.83333333333334 | Test Accuracy 93.25\n",
      "Epoch 31 | Train loss 0.12355319410562515\n",
      "Train Accuracy 96.16666666666667 | Test Accuracy 93.0\n",
      "Epoch 32 | Train loss 0.032060518860816956\n",
      "Train Accuracy 97.83333333333334 | Test Accuracy 94.75\n",
      "Epoch 33 | Train loss 0.29380470514297485\n",
      "Train Accuracy 97.66666666666667 | Test Accuracy 94.5\n",
      "Epoch 34 | Train loss 0.04229538142681122\n",
      "Train Accuracy 98.16666666666667 | Test Accuracy 96.0\n",
      "Epoch 35 | Train loss 0.19195283949375153\n",
      "Train Accuracy 98.16666666666667 | Test Accuracy 96.0\n",
      "Epoch 36 | Train loss 0.24424605071544647\n",
      "Train Accuracy 93.83333333333333 | Test Accuracy 92.75\n",
      "Epoch 37 | Train loss 0.06548993289470673\n",
      "Train Accuracy 95.33333333333334 | Test Accuracy 94.5\n",
      "Epoch 38 | Train loss 0.03652940317988396\n",
      "Train Accuracy 95.0 | Test Accuracy 93.5\n",
      "Epoch 39 | Train loss 0.08007366210222244\n",
      "Train Accuracy 96.83333333333334 | Test Accuracy 95.25\n",
      "Epoch 40 | Train loss 1.025370478630066\n",
      "Train Accuracy 98.5 | Test Accuracy 96.25\n",
      "Epoch 41 | Train loss 0.09426309913396835\n",
      "Train Accuracy 95.0 | Test Accuracy 91.5\n",
      "Epoch 42 | Train loss 0.10779083520174026\n",
      "Train Accuracy 91.33333333333333 | Test Accuracy 89.25\n",
      "Epoch 43 | Train loss 0.10039157420396805\n",
      "Train Accuracy 92.83333333333333 | Test Accuracy 91.75\n",
      "Epoch 44 | Train loss 0.0837436318397522\n",
      "Train Accuracy 97.16666666666667 | Test Accuracy 96.25\n",
      "Epoch 45 | Train loss 0.12147844582796097\n",
      "Train Accuracy 99.0 | Test Accuracy 96.75\n",
      "Epoch 46 | Train loss 0.02983708679676056\n",
      "Train Accuracy 98.0 | Test Accuracy 96.0\n",
      "Epoch 47 | Train loss 0.010100298561155796\n",
      "Train Accuracy 98.83333333333333 | Test Accuracy 97.0\n",
      "Epoch 48 | Train loss 0.011000484228134155\n",
      "Train Accuracy 99.16666666666667 | Test Accuracy 97.75\n",
      "Epoch 49 | Train loss 0.03460441157221794\n",
      "Train Accuracy 99.16666666666667 | Test Accuracy 97.75\n",
      "Epoch 50 | Train loss 0.0656166821718216\n",
      "Train Accuracy 99.16666666666667 | Test Accuracy 97.75\n",
      "Epoch 51 | Train loss 0.003834908828139305\n",
      "Train Accuracy 99.16666666666667 | Test Accuracy 97.5\n",
      "Epoch 52 | Train loss 0.08249234408140182\n",
      "Train Accuracy 99.33333333333333 | Test Accuracy 98.0\n",
      "Epoch 53 | Train loss 0.00309509108774364\n",
      "Train Accuracy 99.5 | Test Accuracy 97.75\n",
      "Epoch 54 | Train loss 0.029586253687739372\n",
      "Train Accuracy 99.33333333333333 | Test Accuracy 97.75\n",
      "Epoch 55 | Train loss 0.007367035374045372\n",
      "Train Accuracy 99.66666666666667 | Test Accuracy 98.5\n",
      "Epoch 56 | Train loss 0.0399700403213501\n",
      "Train Accuracy 99.33333333333333 | Test Accuracy 97.5\n",
      "Epoch 57 | Train loss 0.005416391883045435\n",
      "Train Accuracy 99.66666666666667 | Test Accuracy 98.5\n",
      "Epoch 58 | Train loss 0.011882711201906204\n",
      "Train Accuracy 99.5 | Test Accuracy 98.5\n",
      "Epoch 59 | Train loss 0.0031409927178174257\n",
      "Train Accuracy 99.83333333333333 | Test Accuracy 98.75\n",
      "Epoch 60 | Train loss 0.007610452827066183\n",
      "Train Accuracy 99.33333333333333 | Test Accuracy 98.0\n",
      "Epoch 61 | Train loss 0.01287797186523676\n",
      "Train Accuracy 99.83333333333333 | Test Accuracy 98.5\n",
      "Epoch 62 | Train loss 0.03671858832240105\n",
      "Train Accuracy 100.0 | Test Accuracy 98.5\n",
      "Epoch 63 | Train loss 0.0043045091442763805\n",
      "Train Accuracy 100.0 | Test Accuracy 98.75\n",
      "Epoch 64 | Train loss 0.003514565760269761\n",
      "Train Accuracy 99.33333333333333 | Test Accuracy 97.5\n",
      "Epoch 65 | Train loss 0.019809283316135406\n",
      "Train Accuracy 99.5 | Test Accuracy 99.0\n",
      "Epoch 66 | Train loss 0.0008600340224802494\n",
      "Train Accuracy 100.0 | Test Accuracy 99.0\n",
      "Epoch 67 | Train loss 0.0015432946383953094\n",
      "Train Accuracy 100.0 | Test Accuracy 99.25\n",
      "Epoch 68 | Train loss 0.0007618030067533255\n",
      "Train Accuracy 100.0 | Test Accuracy 99.25\n",
      "Epoch 69 | Train loss 0.021290680393576622\n",
      "Train Accuracy 100.0 | Test Accuracy 99.25\n",
      "Epoch 70 | Train loss 0.0013680903939530253\n",
      "Train Accuracy 100.0 | Test Accuracy 99.0\n",
      "Epoch 71 | Train loss 0.019721709191799164\n",
      "Train Accuracy 100.0 | Test Accuracy 99.0\n",
      "Epoch 72 | Train loss 0.0009032809175550938\n",
      "Train Accuracy 100.0 | Test Accuracy 98.75\n",
      "Epoch 73 | Train loss 0.0012358619133010507\n",
      "Train Accuracy 99.83333333333333 | Test Accuracy 98.75\n",
      "Epoch 74 | Train loss 0.003151484066620469\n",
      "Train Accuracy 99.83333333333333 | Test Accuracy 99.25\n",
      "Epoch 75 | Train loss 0.00020653731189668179\n",
      "Train Accuracy 100.0 | Test Accuracy 99.25\n",
      "Epoch 76 | Train loss 0.00012959989544469863\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 77 | Train loss 0.004691496957093477\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 78 | Train loss 0.0010762909660115838\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 79 | Train loss 0.000773022708017379\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 80 | Train loss 0.00044014572631567717\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 81 | Train loss 0.0001711113000055775\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 82 | Train loss 0.0007100932416506112\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 83 | Train loss 1.289736701437505e-05\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 84 | Train loss 0.0003361382696311921\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 85 | Train loss 0.00039135548286139965\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 86 | Train loss 0.000987752340734005\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 87 | Train loss 0.0003900433948729187\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 88 | Train loss 0.0008532173815183342\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 89 | Train loss 9.109826351050287e-06\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Train loss 0.00016014835273381323\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 91 | Train loss 8.137839176924899e-05\n",
      "Train Accuracy 100.0 | Test Accuracy 99.5\n",
      "Epoch 92 | Train loss 0.00028231399483047426\n",
      "Train Accuracy 100.0 | Test Accuracy 99.75\n",
      "Epoch 93 | Train loss 2.0917725123581477e-05\n",
      "Train Accuracy 100.0 | Test Accuracy 99.75\n",
      "Epoch 94 | Train loss 0.0006714263581670821\n",
      "Train Accuracy 100.0 | Test Accuracy 99.75\n",
      "Epoch 95 | Train loss 0.0004757727438118309\n",
      "Train Accuracy 100.0 | Test Accuracy 99.75\n",
      "Epoch 96 | Train loss 4.836927109863609e-05\n",
      "Train Accuracy 100.0 | Test Accuracy 99.75\n",
      "Epoch 97 | Train loss 6.879428110551089e-05\n",
      "Train Accuracy 100.0 | Test Accuracy 99.75\n",
      "Epoch 98 | Train loss 0.0001671647041803226\n",
      "Train Accuracy 100.0 | Test Accuracy 99.75\n",
      "Epoch 99 | Train loss 0.0001823274214984849\n",
      "Train Accuracy 100.0 | Test Accuracy 99.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss, h = train(train_loader)\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch} | Train loss {loss}\")\n",
    "    train_acc, test_acc = check_accuracy(model, train_loader), check_accuracy(model, test_loader)\n",
    "    print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square\n",
    "import networkx as nx\n",
    "square = nx.Graph()\n",
    "square.add_edge(0, 1)\n",
    "square.add_edge(1, 3)\n",
    "square.add_edge(0, 2)\n",
    "square.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square with cross bar (rigid)\n",
    "import networkx as nx\n",
    "square_bar = nx.Graph()\n",
    "square_bar.add_edge(0, 1)\n",
    "square_bar.add_edge(1, 3)\n",
    "square_bar.add_edge(0, 2)\n",
    "square_bar.add_edge(2, 3)\n",
    "square_bar.add_edge(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle\n",
    "import networkx as nx\n",
    "triangle = nx.Graph()\n",
    "triangle.add_edge(0, 1)\n",
    "triangle.add_edge(0, 2)\n",
    "triangle.add_edge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentagon\n",
    "import networkx as nx\n",
    "pentagon = nx.Graph()\n",
    "pentagon.add_edge(0, 1)\n",
    "pentagon.add_edge(1, 3)\n",
    "pentagon.add_edge(3, 4)\n",
    "pentagon.add_edge(4, 2)\n",
    "pentagon.add_edge(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_as_data = from_networkx(square_bar)\n",
    "graph_as_data.x = generate_feature_vector(square_bar)\n",
    "graph_as_data.label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10], num_nodes=4, x=[4, 1], label=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_as_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = DataLoader([graph_as_data], batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3060]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[-0.8189]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in validation_set:\n",
    "    pred = model(batch.x, batch.edge_index, batch.batch)\n",
    "    print(pred[0])\n",
    "    print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 99.18599918599918 | Test Accuracy 99.14582062233069\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = check_accuracy(model, train_loader), check_accuracy(model, test_loader)\n",
    "print(f\"Train Accuracy {train_acc} | Test Accuracy {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LamanTestDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_dir, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_test.pt']\n",
    "        \n",
    "    def process(self):\n",
    "        # processing code here\n",
    "        total_laman_data = None\n",
    "        with gzip.open(self.data_dir, 'r') as f:\n",
    "            total_laman_data = pickle.load(f)\n",
    "            \n",
    "        data_list = []\n",
    "        ind = 0\n",
    "        # convert from graph to Data object\n",
    "        for graph in total_laman_data[0]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 1)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 0\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        ind = 0\n",
    "        for graph in total_laman_data[1]:\n",
    "#             print(ind)\n",
    "            ind += 1\n",
    "            num_nodes = nx.number_of_nodes(graph)\n",
    "#             x = torch.randn(num_nodes, 64)\n",
    "            x = generate_feature_vector(graph)\n",
    "            graph_as_data = from_networkx(graph)\n",
    "            graph_as_data.x = x\n",
    "            graph_as_data.label = 1\n",
    "            data_list.append(graph_as_data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# add functionality to support a test dataset\n",
    "TEST_DATA_PATH = \"../data-2d/data/test-dataset-30loc-5std.pkl.gz\"\n",
    "laman_test_set = LamanTestDataset(\"\", TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "laman_test_loader = DataLoader(laman_test_set, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 94.3359375\n"
     ]
    }
   ],
   "source": [
    "random_test_acc = check_accuracy(model, laman_test_loader)\n",
    "print(f\"Accuracy {random_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play around with hyperparameters\n",
    "    # hyper-opt: bayesian optimization\n",
    "    # optimize learning rate\n",
    "    # don't regularize \n",
    "# add non-minimally rigid graphs (test that hypothesis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
